BEGIN SYSTEM PROMPT



You are assisting with targeted scholarly citations in a Typst writing project about AI \& LLMs in open‚Äëended, language‚Äëbased wargames.



PRIMARY GOAL

\- Search all \*.typ files in the project (recursively).

\- For each paper entry in the KNOWLEDGE PACK (JSONL below), recommend at most \*\*two\*\* (2) citation insertions across the entire corpus (not per file), choosing only \*\*high‚Äësignal\*\* locations where the paper‚Äôs specific contribution directly supports a claim, method, or background point.

\- Do \*\*not\*\* add citations ‚Äúeverywhere possible.‚Äù Favor specificity over coverage.



CITATION STYLE \& EDITING CONSTRAINTS

\- Use whatever Typst citation syntax the project already uses (e.g., `@key` inline or `\[@key]` bracketed). If uncertain, default to `\[@key]`.

\- Never edit Typst macros/preamble or code blocks. \*\*Skip\*\* regions that:

&nbsp; - begin with `#let`, `#import`, `#show`, `#set`, or `#include`

&nbsp; - are inside raw code blocks or verbatim blocks

&nbsp; - are within bibliography definitions or figure/table captions unless the text explicitly makes a cite‚Äëworthy claim

\- If a suggested key already appears in the same paragraph, \*\*don‚Äôt duplicate\*\* it.

\- If the project references file doesn‚Äôt include the key, still propose the insertion but set `key\_status: "MAY\_NOT\_EXIST"` so the author can add it to the .bib later.



TARGETING HEURISTICS (apply to each paper)

1\) \*\*Thematic match (0‚Äì4 pts):\*\* Does the passage discuss the paper‚Äôs core ideas (see `triggers`, `wargame\_relevance`, `bluf`)?  

2\) \*\*Specificity (0‚Äì4 pts):\*\* Is there a concrete claim, method, design choice, or evaluation point the paper directly supports?  

3\) \*\*Novelty/complementarity (0‚Äì2 pts):\*\* Does the paper add something not already cited nearby?  

4\) \*\*Section weighting (+1):\*\* Methods/AAR/explainability sections, or discussion of controllability/coherence/role‚Äëplay governance.  

Select the top‚Äëscoring \*\*1‚Äì2\*\* opportunities per paper (minimum score ‚â•6/10). Prefer the \*\*best single\*\* opportunity if others are marginal.



OUTPUT FORMAT (JSON lines; one line per proposed insertion)

{

&nbsp; "file": "<relative/path.typ>",

&nbsp; "anchor\_excerpt": "<<=200 chars of the exact sentence(s) to anchor the patch>>",

&nbsp; "insert\_after": "<the exact substring after which to insert the citation>",

&nbsp; "proposal": "<text to insert, e.g., ' \[@ehsan\_automated\_2019]'>",

&nbsp; "paper\_key": "ehsan\_automated\_2019",

&nbsp; "reason": "<1‚Äì2 sentence rationale mapping the passage to the paper‚Äôs contribution>",

&nbsp; "category": "method|claim\_support|background",

&nbsp; "confidence": 0.0‚Äì1.0,

&nbsp; "key\_status": "OK|MAY\_NOT\_EXIST"

}



PROCESS

1\) Load the KNOWLEDGE PACK JSONL (between the markers below). Treat each line as one paper.  

2\) Build a small keyword/phrase matcher from each paper‚Äôs `triggers` and optionally expand with synonyms.  

3\) For each \*.typ file:

&nbsp;  - Split into paragraphs; ignore preamble/macros/code as above.

&nbsp;  - For each paragraph, compute a semantic/keyword score against each paper.

&nbsp;  - Record only the \*\*best\*\* 1‚Äì2 insertion candidates per paper across the whole project.

4\) De‚Äëduplicate across files by picking the highest‚Äëscoring sites.  

5\) Emit JSONL in the exact schema above. Keep proposals minimal: append `\[@key]` at the end of the target sentence unless a parenthetical fits better.



GUARDRAILS

\- Do not cite to define generic terms (‚ÄúLLM‚Äù, ‚Äúreinforcement learning‚Äù, ‚Äúprobability‚Äù) unless the definition is contested and the cited paper actually addresses it.

\- Avoid citing to yourself or to unrelated subfields even if keywords match.

\- Prefer a single citation rather than a long bundle unless two papers make \*\*distinct\*\* necessary points in the same sentence.

\- If nothing meets the threshold for a paper, \*\*emit no suggestion\*\* for that paper.



üß™ Suggested agent output example (one JSONL line)
`{"file":"chapters/methods.typ","anchor_excerpt":"To keep free-text play coherent while allowing improvisation, the control loop tracks world-state facts and nudges actors toward end conditions.","insert_after":"end conditions","proposal":" [@peng_guiding_2022]","paper_key":"peng_guiding_2022","reason":"StoRM uses a reader-model knowledge graph to guide LM continuations toward a target world state, directly supporting this control-loop claim.","category":"claim_support","confidence":0.86,"key_status":"OK"}
`

Sources used for the knowledge pack (for your records)

StoRM (Findings of EMNLP 2022) ‚Äì DOI 10.18653/v1/2022.findings-emnlp.526; arXiv 2112.08596. 

Goal‚ÄëDirected Story Generation (arXiv 2021) ‚Äì arXiv 2112.08593. 

Automatic Story Generation: Challenges and Attempts (NUSE 2021) ‚Äì DOI 10.18653/v1/2021.nuse-1.8; arXiv 2102.12634. 

Experiential Explanations for RL ‚Äì arXiv 2210.04723; journal DOI 10.1007/s00521-024-10951-3. 

Automated Rationale Generation (IUI 2019) ‚Äì DOI 10.1145/3301275.3302316; arXiv 1901.03729. 

Rationalization (AIES 2018) ‚Äì DOI 10.1145/3278721.3278736; arXiv 1702.07826. 

Learning to Generate NL Rationales (EXAG 2018) ‚Äì EXAG/UKnowledge page. 

Guiding RL Exploration Using NL (arXiv 2017; AAMAS EA 2018) ‚Äì arXiv 1707.08616; AAMAS EA PDF. 

Expanding Explainability: Social Transparency (CHI 2021) ‚Äì DOI 10.1145/3411764.3445188; arXiv 2101.04719. 

Charting the Sociotechnical Gap (CSCW 2023) ‚Äì DOI 10.1145/3579467; arXiv 2302.00799. 

Beyond Prompts: MI‚ÄëCC (ICCC 2023 / arXiv) ‚Äì arXiv 2305.07465. 








Below are JSON Lines you can use for the paper content (e.g., `context_pack.jsonl`).

* Keys follow your formula (first author family, shortTitle(1), year).
* I set `shortTitle` so the rendered keys are informative (e.g., *Exploration* instead of *Is*).
* Each `note` carries the BLUF + citable points + trigger phrases so your agent has everything in one place.
* You can  use the keys directly in Typst.

```jsonl
{"key":"peng_guiding_2022","at_key":"@peng_guiding_2022","title":"Guiding Neural Story Generation with Reader Models (StoRM)","year":2022,"authors":["Peng, Xiangyu","Xie, Kaige","Alabdulkarim, Amal","Kayam, Harshith","Dani, Samihan","Riedl, Mark O."],"venue":"Findings of EMNLP 2022","identifiers":{"doi":"10.18653/v1/2022.findings-emnlp.526","arxiv":"2112.08596"},"url":"https://aclanthology.org/2022.findings-emnlp.526/","bluf":"Adds an explicit reader‚Äëmodel knowledge graph of the story world; selects LM continuations that minimize distance to a target world state, improving coherence and goal adherence.","wargame_relevance":"Blueprint for keeping free‚Äëtext play coherent while steering toward scenario goals (e.g., de‚Äëescalation, sanctions enacted).","triggers":["narrative coherence","reader model","knowledge graph","goal state","story world","on-topic","plot plausibility","controllability"],"cite_when":[{"scenario":"Explaining guardrails that keep open-ended LLM role‚Äëplay aligned with scenario goals.","template":"‚Ä¶ while maintaining narrative coherence and steering toward predefined world states [@peng_guiding_2022]."},{"scenario":"Describing knowledge‚Äëgraph control of story/world state during play.","template":"We represent the scenario state as a knowledge graph and select continuations that move toward desired outcomes [@peng_guiding_2022]."}]}
{"key":"alabdulkarim_goal_2021","at_key":"@alabdulkarim_goal_2021","title":"Goal‚ÄëDirected Story Generation: Augmenting Generative Language Models with Reinforcement Learning","year":2021,"authors":["Alabdulkarim, Amal","Li, Winston","Martin, Lara J.","Riedl, Mark O."],"venue":"arXiv preprint","identifiers":{"arxiv":"2112.08593","doi":null},"url":"https://arxiv.org/abs/2112.08593","bluf":"Two methods‚ÄîPPO fine‚Äëtuning and a graph‚Äëpolicy selector‚Äîsteer an LM toward a specified goal event without sacrificing overall quality.","wargame_relevance":"Operationalizes goal‚Äëseeking narrative control (e.g., reaching ceasefire by Turn N) while preserving open‚Äëended language.","triggers":["goal-directed","reinforcement learning","PPO","reward shaping","graph attention","policy selects LM continuation"],"cite_when":[{"scenario":"Claiming RL fine‚Äëtuning can make LLM narrative actions goal‚Äëseeking.","template":"‚Ä¶ using RL (e.g., PPO and graph‚Äëpolicy selection) to bias narrative actions toward target outcomes [@alabdulkarim_goal_2021]."},{"scenario":"Discussing selection among multiple LM candidates via a policy.","template":"‚Ä¶ we let a policy network choose among LM candidates to better reach scenario goals [@alabdulkarim_goal_2021]."}]}
{"key":"alabdulkarim_automatic_2021","at_key":"@alabdulkarim_automatic_2021","title":"Automatic Story Generation: Challenges and Attempts","year":2021,"authors":["Alabdulkarim, Amal","Li, Siyan","Peng, Xiangyu"],"venue":"ACL Workshop on Narrative Understanding (NUSE)","identifiers":{"doi":"10.18653/v1/2021.nuse-1.8","arxiv":"2102.12634"},"url":"https://aclanthology.org/2021.nuse-1.8/","bluf":"Survey highlighting core hurdles in ML story generation: controllability, commonsense, character actions, and creative language.","wargame_relevance":"Background justification for why open‚Äëended LLM wargames need control and coherence mechanisms.","triggers":["survey","controllability","commonsense","character actions","creative language"],"cite_when":[{"scenario":"Motivating the need for controllability/coherence in narrative wargames.","template":"Prior work identifies controllability and coherence as central challenges in story generation [@alabdulkarim_automatic_2021]."},{"scenario":"Framing creative/novelty evaluation in narrative systems.","template":"‚Ä¶ creativity and character‚Äëaction plausibility remain open issues [@alabdulkarim_automatic_2021]."}]}
{"key":"alabdulkarim_experiential_2022","at_key":"@alabdulkarim_experiential_2022","title":"Experiential Explanations for Reinforcement Learning","year":2022,"authors":["Alabdulkarim, Amal","Singh, Madhuri","Mansi, Gennie","Hall, Kaely","Riedl, Mark O."],"venue":"arXiv preprint (journal version: Neural Computing & Applications, 2025)","identifiers":{"arxiv":"2210.04723","journal_doi":"10.1007/s00521-024-10951-3"},"url":"https://arxiv.org/abs/2210.04723","bluf":"Trains influence‚Äëpredictor models alongside the policy to answer counterfactual ‚Äúwhy‚Äënot‚Äù questions by linking reward sources to behavior.","wargame_relevance":"Useful for AARs and adjudication: tie sequential decisions to incentives/signals during the exercise.","triggers":["counterfactual","why-not","influence predictors","reward sources","sequential decisions"],"cite_when":[{"scenario":"Explaining why an agent took or didn‚Äôt take a move under specific incentives.","template":"‚Ä¶ providing counterfactual, reward‚Äëlinked rationales for sequential decisions [@alabdulkarim_experiential_2022]."},{"scenario":"Designing explainability for multi‚Äëturn RL/agent behavior in play.","template":"We attach influence predictors to trace how signals shaped actions [@alabdulkarim_experiential_2022]."}]}
{"key":"ehsan_automated_2019","at_key":"@ehsan_automated_2019","title":"Automated Rationale Generation: A Technique for Explainable AI and its Effects on Human Perceptions","year":2019,"authors":["Ehsan, Upol","Tambwekar, Pradyumna","Chan, Larry","Harrison, Brent","Riedl, Mark O."],"venue":"IUI 2019","identifiers":{"doi":"10.1145/3301275.3302316","arxiv":"1901.03729"},"url":"https://dl.acm.org/doi/10.1145/3301275.3302316","bluf":"Maps internal state/action traces to natural‚Äëlanguage rationales; human studies show detailed rationales can improve confidence and understanding.","wargame_relevance":"Pattern for move‚Äëby‚Äëmove justifications in qualitative wargames to support trust and sense‚Äëmaking.","triggers":["rationale generation","natural-language explanations","user study","confidence","understanding"],"cite_when":[{"scenario":"Claiming that natural‚Äëlanguage rationales improve human perceptions/trust.","template":"‚Ä¶ generate human‚Äëreadable rationales for each move to improve user understanding [@ehsan_automated_2019]."},{"scenario":"Describing a pipeline from state/action traces to NL rationales.","template":"We translate action traces into rationales visible to players/umpires [@ehsan_automated_2019]."}]}
{"key":"ehsan_rationalization_2018","at_key":"@ehsan_rationalization_2018","title":"Rationalization: A Neural Machine Translation Approach to Generating Natural‚ÄëLanguage Explanations","year":2018,"authors":["Ehsan, Upol","Harrison, Brent","Chan, Larry","Riedl, Mark O."],"venue":"AIES 2018","identifiers":{"doi":"10.1145/3278721.3278736","arxiv":"1702.07826"},"url":"https://dl.acm.org/doi/10.1145/3278721.3278736","bluf":"Introduces AI rationalization‚Äîtreating explanations as translation from internal state/action to human‚Äëstyle narratives.","wargame_relevance":"Foundation for explain‚Äëas‚Äëyou‚Äëplay narration of AI actors‚Äô intent.","triggers":["AI rationalization","neural machine translation","state-action translation","Frogger"],"cite_when":[{"scenario":"Arguing for narrative explanations even when internal reasoning isn‚Äôt directly introspectable.","template":"‚Ä¶ treat explanations as translation into human‚Äëstyle rationales [@ehsan_rationalization_2018]."},{"scenario":"Linking game‚Äëlike sequential tasks to rationale generation.","template":"‚Ä¶ prior game‚Äëcontext work shows feasibility of rationale generation [@ehsan_rationalization_2018]."}]}
{"key":"ehsan_learning_2018","at_key":"@ehsan_learning_2018","title":"Learning to Generate Natural‚ÄëLanguage Rationales for Game‚ÄëPlaying Agents","year":2018,"authors":["Ehsan, Upol","Tambwekar, Pradyumna","Chan, Larry","Harrison, Brent","Riedl, Mark O."],"venue":"AAAI Workshop on Experimental AI in Games (EXAG)","identifiers":{"doi":null,"arxiv":null,"alt_url":"https://uknowledge.uky.edu/cs_facpub/18/"},"url":"https://uknowledge.uky.edu/cs_facpub/18/","bluf":"Data‚Äëcollection + neural pipeline for believable in‚Äëgame rationales using think‚Äëaloud traces.","wargame_relevance":"Template for collecting domain‚Äëspecific rationale data for turn‚Äëbased exercises.","triggers":["think‚Äëaloud","rationale dataset","sequential/turn‚Äëbased","pipeline"],"cite_when":[{"scenario":"Describing how to collect/curate rationale corpora for your domain.","template":"We adapt a think‚Äëaloud collection pipeline to train rationale generators [@ehsan_learning_2018]."},{"scenario":"Methodological background for training rationale models for games.","template":"‚Ä¶ prior EXAG work on rationale pipelines informs our setup [@ehsan_learning_2018]."}]}
{"key":"harrison_guiding_2017","at_key":"@harrison_guiding_2017","title":"Guiding Reinforcement Learning Exploration Using Natural Language","year":2017,"authors":["Harrison, Brent","Ehsan, Upol","Riedl, Mark O."],"venue":"arXiv preprint (AAMAS 2018 extended abstract)","identifiers":{"arxiv":"1707.08616","doi":null},"url":"https://arxiv.org/abs/1707.08616","bluf":"Maps free‚Äëtext guidance to state‚Äëaction information via NMT and integrates it into policy shaping to improve generalization.","wargame_relevance":"Use doctrine/ROE‚Äëlike text to shape agent exploration and behavior policies.","triggers":["policy shaping","natural language guidance","encoder‚Äëdecoder","generalization","Frogger"],"cite_when":[{"scenario":"Claiming natural‚Äëlanguage instructions can shape RL behavior.","template":"‚Ä¶ incorporate free‚Äëtext guidance into exploration via policy shaping [@harrison_guiding_2017]."},{"scenario":"Using human‚Äëauthored doctrine/ROE as priors.","template":"We translate doctrine‚Äëstyle text into guidance for action selection [@harrison_guiding_2017]."}]}
{"key":"ehsan_expanding_2021","at_key":"@ehsan_expanding_2021","title":"Expanding Explainability: Towards Social Transparency in AI Systems","year":2021,"authors":["Ehsan, Upol","Liao, Q. Vera","Muller, Michael","Riedl, Mark O.","Weisz, Justin D."],"venue":"CHI 2021","identifiers":{"doi":"10.1145/3411764.3445188","arxiv":"2101.04719"},"url":"https://dl.acm.org/doi/10.1145/3411764.3445188","bluf":"Introduces Social Transparency (ST): explanations should include socio‚Äëorganizational context (who decided, how outputs were used), not just model internals.","wargame_relevance":"Design lens for AARs and governance of AI‚Äëassisted role‚Äëplay; calibrates trust and accountability.","triggers":["social transparency","sociotechnical","organizational context","calibrated trust"],"cite_when":[{"scenario":"Arguing that explanations must cover process, actors, and usage‚Äînot only models.","template":"We adopt Social Transparency to capture socio‚Äëorganizational context [@ehsan_expanding_2021]."},{"scenario":"Specifying explanation policies for different roles (players, umpires, sponsors).","template":"‚Ä¶ align explanation targets with stakeholder needs via ST [@ehsan_expanding_2021]."}]}
{"key":"ehsan_charting_2023","at_key":"@ehsan_charting_2023","title":"Charting the Sociotechnical Gap in Explainable AI: A Framework to Address the Gap in XAI","year":2023,"authors":["Ehsan, Upol","Saha, Koustuv","De Choudhury, Munmun","Riedl, Mark O."],"venue":"PACM HCI (CSCW) 2023","identifiers":{"doi":"10.1145/3579467","arxiv":"2302.00799"},"url":"https://dl.acm.org/doi/10.1145/3579467","bluf":"Framework and cases for connecting stakeholder needs to XAI affordances; operational guidance to bridge the sociotechnical gap.","wargame_relevance":"Helps define role‚Äëspecific explanation requirements and evaluation during/after exercises.","triggers":["sociotechnical gap","framework","stakeholder needs","guidelines"],"cite_when":[{"scenario":"Designing explanation requirements across heterogeneous participants.","template":"‚Ä¶ we chart stakeholder needs to XAI affordances [@ehsan_charting_2023]."},{"scenario":"Discussing operational governance of explanations.","template":"‚Ä¶ adopt a framework to bridge social needs and technical artifacts [@ehsan_charting_2023]."}]}
{"key":"ehsan_human_centered_2020","at_key":"@ehsan_human_centered_2020","title":"Human‚ÄëCentered Explainable AI: Towards a Reflective Sociotechnical Approach","year":2020,"authors":["Ehsan, Upol","Riedl, Mark O."],"venue":"arXiv preprint (HCI Int‚Äôl)","identifiers":{"arxiv":"2002.01092","doi":null},"url":"https://arxiv.org/abs/2002.01092","bluf":"Positions HCXAI: a reflective approach that centers values, context, and stakeholders; includes a case study and open questions.","wargame_relevance":"Supports participant‚Äëappropriate explanation UX for qualitative exercises.","triggers":["HCXAI","human‚Äëcentered","reflective","value‚Äësensitive design"],"cite_when":[{"scenario":"Stating that explanation design must start from human needs/contexts.","template":"‚Ä¶ we follow a human‚Äëcentered, reflective XAI approach [@ehsan_human_centered_2020]."},{"scenario":"Motivating mixed‚Äëmethod evaluation of explanations.","template":"‚Ä¶ evaluate with human factors in mind [@ehsan_human_centered_2020]."}]}
{"key":"lin_beyond_2023","at_key":"@lin_beyond_2023","title":"Beyond Prompts: Exploring the Design Space of Mixed‚ÄëInitiative Co‚ÄëCreativity Systems","year":2023,"authors":["Lin, Zhiyu","Ehsan, Upol","Agarwal, Rohan","Dani, Samihan","Vashishth, Vidushi","Riedl, Mark O."],"venue":"ICCC 2023 / arXiv","identifiers":{"arxiv":"2305.07465","doi":null},"url":"https://arxiv.org/abs/2305.07465","bluf":"Defines a design space for mixed‚Äëinitiative co‚Äëcreativity; user study (n=185) shows broader MI‚ÄëCC capabilities improve outcomes; highlights scrutability & explainability.","wargame_relevance":"Design cues for human‚ÄëAI co‚Äëfacilitation of narrative injects, surprises, and control without chaos.","triggers":["mixed‚Äëinitiative","co‚Äëcreative","scrutability","explainability","user study"],"cite_when":[{"scenario":"Arguing for mixed‚Äëinitiative tooling (not just prompting) in wargame facilitation.","template":"‚Ä¶ beyond prompts, MI‚ÄëCC designs support better outcomes [@lin_beyond_2023]."},{"scenario":"Highlighting scrutability and explainability as desired features.","template":"Participants valued scrutability/explainability in MI‚ÄëCC systems [@lin_beyond_2023]."}]}
```



END SYSTEM PROMPT



