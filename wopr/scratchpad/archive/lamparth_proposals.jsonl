{"paper_id":"shrivastava_inconsistency_2024","file":"main.typ","paragraph_heading":"Recommendations","line_start":226,"insert_after_sentence_idx":0,"insertion":" @shrivastava_inconsistency_2024","rationale":"Supports claim about measuring output stability and inconsistency in free-form wargame responses.","evidence":"Sentence discusses paraphrases/structure changes surfacing inconsistent strategic reasoning; paper introduces a semantic inconsistency metric showing prompt-sensitive instability.","inject_bibtex":"@inproceedings{shrivastava_inconsistency_2024, title={Measuring Free-Form Decision-Making Inconsistency of Language Models in Military Crisis Simulations}, author={Aryan Shrivastava and Jessica Hullman and Max Lamparth}, booktitle={NeurIPS 2024 Workshop on Socially Responsible Language Modeling Research (SoLaR)}, year={2024}, note={poster; see arXiv:2410.13204}, url={https://openreview.net/forum?id=qZ2CeIaYSu}}"}
{"paper_id":"lamparth_human_vs_machine_2024","file":"main.typ","paragraph_heading":"Known LM simulation vulnerabilities","line_start":210,"insert_after_sentence_idx":0,"insertion":" @lamparth_human_2024","rationale":"Backs the claim that LM simulations can lack diversity of behavior and realistic team dynamics.","evidence":"Paper finds LLM-simulated teams lack intra-team disagreement/dynamics compared to experts; paragraph cites bias/diversity issues in LM simulations."}
{"paper_id":"rivera_escalation_2024","file":"content/1_introduction.typ","paragraph_heading":"Introduction","line_start":13,"insert_after_sentence_idx":3,"insertion":" @rivera_escalation_2024","rationale":"Anchors the safety-risk claim about open-ended LM-enabled wargames to empirical escalation findings.","evidence":"Sentence asserts safety risk from open-endedness; paper shows LLM agents can exhibit escalatory dynamics in multi-agent simulations (including rare high-consequence outcomes)."}
{"paper_id":"hammond_multi_agent_2025","file":"main.typ","paragraph_heading":"Economics and Finance","line_start":197,"insert_after_sentence_idx":3,"insertion":" @hammond_multi_agent_2025","rationale":"Supports mention of collusion and multi-agent strategic dynamics in simulated markets.","evidence":"Sentence discusses observing strategies of collusion and predatory expansion under dynamic conditions; paper surveys multi-agent failure modes including miscoordination and collusion in open-ended settings.","inject_bibtex":"@techreport{hammond_multi_agent_2025, title={Multi-Agent Risks from Advanced AI}, author={Lewis Hammond and Alan Chan and Jesse Clifton and Jason Hoelscher-Obermaier and Akbir Khan and Euan McLean and Chandler Smith and Wolfram Barfuss and Jakob Foerster and Tomáš Gavenčiak and The Anh Han and Edward Hughes and Vojtěch Kovařík and Jan Kulveit and Joel Z. Leibo and Caspar Oesterheld and Christian Schroeder de Witt and Nisarg Shah and Michael Wellman and Max Lamparth and others}, institution={Cooperative AI Foundation}, year={2025}, note={Technical Report #1; arXiv:2502.14143}, url={https://arxiv.org/abs/2502.14143}}"}
