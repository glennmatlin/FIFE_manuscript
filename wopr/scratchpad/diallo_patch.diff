diff --git a/content/08_recommendations.typ b/content/08_recommendations.typ
index 3a3b2c1..7e5f9ab 100644
--- a/content/08_recommendations.typ
+++ b/content/08_recommendations.typ
@@ -7,7 +7,9 @@
 *Robustness testing.* To measure output stability and, by proxy, LM reliability, running inference across paraphrased inputs, synonym substitutes, and varied prompt structures may surface inconsistent strategic reasoning @nalbandyan_score_2025 @shrivastava_inconsistency_2024. Testing both surface-level, syntactic robustness and semantic equivalence can largely be automated through use of auxiliary and smaller LMs, and integrated into deployed workflows to inform user confidence in outputs.
 
-
+*Task-specific competence.* Evaluate LM agents on crisis-response benchmarks with time-sensitive actions (e.g., RESPONSE) to surface domain gaps before high-stakes use @diallo_response_2025.
+
 *Calibration assessment.* Well-calibrated models, those which are correct as much as their expressed confidence predicts, help minimize overconfidence in flawed strategic assessments or under-confidence in sound reasoning, providing an important auditing mechanism for understanding LM decisions; measurements of LM calibration allow external stakeholders of wargames to understand systematic flaws in LM decision-making. Additionally, requiring LMs to quantify uncertainty is likely to improve agent performance and make human review of key actions more efficient, particularly in high-stakes situations @liu_uncertainty_2025. 
