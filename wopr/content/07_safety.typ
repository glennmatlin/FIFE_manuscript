#import "@preview/tracl:0.6.1": *
#import "../config.typ":num_papers
= Safety Considerations

The results of wargames often directly inform organizational policy, discussions, and institutional decision-making, including in sensitive policy and defensive contexts @uk_ministry_of_defence_influence_2023. Because the design and interpretation of wargames usually assume human players and adjudicators with meaningfully different behavior patterns than LMs, the incorporation of LMs in wargaming necessitates reevaluation of traditional wargaming methodology and interpretation when LMs are involved @downes-martin_adjudication_2013. The following is a non-exhaustive list of safety considerations:
- *Escalation dynamics:* LMs show escalatory tendencies in diplomatic and military contexts @rivera_escalation_2024, requiring mitigation techniques @elbaum_managing_2025 for wargaming applications.
- *Unfaithful reasoning:* LMs exhibit unfaithful Chain-of-Thought (CoT) reasoning @turpin_language_2023 @lanham_measuring_2023, potentially misattributing decision factors in wargaming contexts.
- *Implicit bias*: Pre-training noise creates systematic errors @taubenfeld_systematic_2024 leading to implicit world state preferences @mazeika_utility_2025, causing blind spots in adversarial modeling.
- *Long context incoherence:* LMs struggle to maintain cohesion over long contexts @liu_lost_2023. Effective wargaming requires strategic continuity and long horizon simulations may challenge the effective attention @modarressi_nolima_2025. 
- *Prompt sensitivity:* The behavior of LMs can be heavily influenced by the system prompt, e.g., including "helpful assistant" or "skeptical critic" can significantly change the LM's behavior and can be exploited to generated desired outcomes undermine the insights gained from the game. 
- *Sycophancy*: Post-training creates emergent sycophancy @sharma_towards_2025, which may mask strategic vulnerabilities and incorrectly validate operator assumptions in red-team exercises. Because post-training encourages helpfulness, harmlessness, and honesty @askell_general_2021 the way the LM is rewarded during training can affect its ability to adopt personas that do not have these qualities, such as in the case of an adversary.
// Mark: because sycophancy and recursive personas fall out of the same cause, I've combined them. I think my description of "recursive personas" is a bit more general at the risk of not having the "soldier" example to make it concrete. Anyway I think "adversaries trying to be helpful" should be alarming enough for people to pay attention.
// Parv: was tryign to get above across in "recusrive persona.." and "robustness" discussions in the following sections. if unclear, let me know! 
// I am very okay with removing it. Note I didn't add prompt sensitivty, and would rather remove that because recursive is built upon later in the work (specifically future work)
// Mark: So the above looks like a minimalistic description of the below. I wonder if below is necessary.
// - *Recursive persona misgeneralization*: LMs can draw from fictionalized accounts when attempting to simulate different personas. 

// to simulate a target distribution of text. These characters can be recursive; if, for instance, the model context instructs it to play a solider in a wargame, it will seek not to simulate the solider but instead a wargame's portrayal of a solider, drawing on text data from fictional portrayals and stylized military communications. Because instruction-tuned models are trained to adopt a helpful assistant persona, it may in fact simulate an assistant portraying a wargamer who is in turn portraying a solider. Each level of simulation is brittle to subtle prompting and contextual changes, and may produce unique artifacts from that context's conventions @lore_strategic_2024 @lutz_prompt_2025. Sophisticated-seeming responses may not reflect domain expertise, creating overconfidence in out-of-distribution scenarios where the model's training data provides poor guidance @taubenfeld_systematic_2024.
// // These safety implications, and others, are discussed in greater detail in Appendix @app:safety-details: