// ===== Table of Selected AI in Wargames Papers =====

== Table of Selected AI in Wargames Papers

// Auto-generated table - DO NOT EDIT MANUALLY
// To regenerate: run the Python script with updated Excel file

#table(
  columns: (auto, 2fr, auto, auto, auto, auto),
  align: (center, left, center, center, center, center),
  
  // Header row
  [*Year*], [*Paper Title*], [*Citation*], [*Quadrant*], [*Player \ Creativity*], [*Adjudicator \ Creativity*],
  
  // === Quadrant I ===
  table.cell(colspan: 6)[*_Quadrant I_*],
  
  [2025],
  [Adaptive Command: Real-Time Policy Adjustment via Language Models in StarCraft II],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2025],
  [Exploration of Wargaming and AI Applications in Military Decision-Making],
  [10.1109/ICMT652...],
  [*I*],
  [LOW],
  [LOW],
  
  [2025],
  [Game Reasoning Arena: A Framework and Benchmark for Assessing Reasoning Capabilites of Large Language Models via Game...],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2025],
  [Leveraging Generative AI to Create Lightweight Simulations for Far-Future Autonomous Teammates],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2025],
  [SC2Arena and StarEvolve: Benchmark and Self-Improvement Framework for LLMs in Complex Decision-Making Tasks],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2025],
  [Strategy-Augmented Planning for Large Language Models via Opponent Exploitation],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2025],
  [Tracing LLM Reasoning Processes with Strategic Games: A Framework for Planning, Revision, and Resource-Constrained De...],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [A Land-Based War-Gaming Simulation Method Based on Multi-Agent Proximal Policy Optimization],
  [10.1109/QRS-C63...],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [BattleAgentBench: A Benchmark for Evaluating Cooperation and Competition Capabilities of Language Models in Multi-Age...],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [Can Large Language Models Play Games? A Case Study of A Self-Play Approach],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [Game Theory Approach to Identifying Deception in Large Language Models],
  [10.36227/techrx...],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [Game-Theoretic LLM: Agent Workflow for Negotiation Games],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [Harnessing Language for Coordination: A Framework and Benchmark for LLM-Driven Multi-Agent Control],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [Maia-2: A Unified Model for Human-AI Alignment in Chess],
  [2409.20553],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [Mastering the Digital Art of War: Developing Intelligent Combat Simulation Agents for Wargaming Using Hierarchical Re...],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [PokeLLMon: A Human-Parity Agent for Pokemon Battles with Large Language Models],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [Project Sid: Many-agent simulations toward AI civilization],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [SC-Phi2: A Fine-tuned Small Language Model for StarCraft II Macromanagement Tasks],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [Strategic behavior of large language models and the role of game structure versus contextual framing],
  [DOI:10.1038/s41...],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [SwarmBrain: Embodied agent for realâ€‘time strategy game StarCraft II via large language models.],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2024],
  [The Automated but Risky Game: Modeling Agent-to-Agent Negotiations and Transactions in Consumer Markets],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2023],
  [ChessGPT: Bridging Policy Learning and Language Modeling],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2023],
  [Diversifying AI: Towards Creative Chess with AlphaZero],
  [2308.09175],
  [*I*],
  [LOW],
  [LOW],
  
  [2023],
  [LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2023],
  [Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2023],
  [Large Language Models on the Chessboard: A Study on ChatGPT's Formal Language Comprehension and Complex Reasoning Skills],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2023],
  [Playing Games With GPT: What Can We Learn About a Large Language Model From Canonical Strategic Games?],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2023],
  [Research on Wargame Decision-Making Method Based on Multi-Agent Deep Deterministic Policy Gradient],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2023],
  [Self Generated Wargame AI: Double Layer Agent Task Planning Based on Large Language Model],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2023],
  [Welfare Diplomacy: Benchmarking Language Model Cooperation],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2022],
  [Ares: A System-Oriented Wargame Framework for Adversarial ML],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2022],
  [Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2022],
  [Mastering the Game of Stratego with Model-Free Multiagent Reinforcement Learning],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2021],
  [Chess AI: Competing Paradigms for Machine Intelligence],
  [2109.11602],
  [*I*],
  [LOW],
  [LOW],
  
  [2021],
  [Hierarchical control of multi-agent reinforcement learning team in real-time strategy (RTS) games],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2021],
  [The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2020],
  [Learning to Play No-Press Diplomacy with Best Response Policy Iteration],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2020],
  [No Press Diplomacy: Modeling Multi-Agent Gameplay],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  [2020],
  [Playing a Strategy Game with Knowledge-Based Reinforcement Learning],
  [Link],
  [*I*],
  [LOW],
  [LOW],
  
  // === Quadrant II ===
  table.cell(colspan: 6)[*_Quadrant II_*],
  
  [2024],
  [BattleAgent: Multi-modal Dynamic Emulation on Historical Battles to Complement Historical Analysis],
  [Link],
  [*II*],
  [LOW],
  [LOW],
  
  [2024],
  [Escalation Risks from Language Models in Military and Diplomatic Decision-Making],
  [Link],
  [*II*],
  [HIGH],
  [LOW],
  
  [2023],
  [War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars],
  [Link],
  [*II*],
  [HIGH],
  [LOW],
  
  [2020],
  [Experimental wargames to address the complexity: scarcity gap],
  [Link],
  [*II*],
  [LOW],
  [HIGH],
  
  // === Quadrant III ===
  table.cell(colspan: 6)[*_Quadrant III_*],
  
  [2025],
  [Advancing AI Negotiations: New Theory and Evidence from an International AI Negotiation Competition],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [Agent Exchange: Shaping the Future of AI Agent Economics],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [Agents of Change: Self-Evolving LLM Agents for Strategic Planning],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [DSGBench: A Diverse Strategic Game Benchmark for Evaluating LLM-based Agents in Complex Decision-Making Environments],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [Debt Collection Negotiations with Large Language Models],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [Digital Player: Evaluating Large Language Models based Human-like Agent in Games],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [Evaluating LLM Agent Collusion in Double Auctions],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [FishBargain: An LLM-Empowered Bargaining Agent for Online Flea-Market Platform Sellers],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [HARBOR: Exploring Persona Dynamics in Multi-Agent Competition],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [Learning from Synthetic Labs: Language Models as Experimental Subjects in Auctions],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [MultiMind: Enhancing Werewolf Agents with Multimodal Memory],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [Playing repeated games with large language models],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [SPIN-Bench:  How Well Do LLMs Plan Strategically and Reason Socially?],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [Should I Trust You? Detecting Deception in Negotiations using Counterfactual RL],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [Super-additive Cooperation in Language Model Agents],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2025],
  [The Traitors: Deception and Trust in Multi-Agent Language Systems],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2024],
  [AMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2024],
  [Battlefield information and tactics engine (BITE): a multimodal large language model approach for battlespace management],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2024],
  [Collaboration and Confrontation in Avalon Gameplay],
  [10.18653/v1/202...],
  [*III*],
  [HIGH],
  [LOW],
  
  [2024],
  [EAI: Emotional Decision-Making of LLMs in Strategic Games and Ethical Dilemmas],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2024],
  [Finding deceivers in social context with large language models: the case of the Mafia game],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2024],
  [Human vs. Machine: Behavioral Differences Between Expert Humans and Language Models in Wargame Simulations],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2024],
  [LLMs of Catan: Exploring Pragmatic Capabilities of Generative Chatbots],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2024],
  [Measuring Free-Form Decision-Making Inconsistency of Language Models in Military Crisis Simulations],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2024],
  [Microscopic Analysis on LLM Players via Social Deduction Game],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2024],
  [More Victories, Less Cooperation: Assessing Cicero's Diplomacy Play],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2024],
  [Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2023],
  [AvalonBench: Evaluating LLMs Playing the Game of Avalon],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2023],
  [Human-level play in the game of Diplomacy by combining language models with strategic reasoning],
  [DOI: 10.1126/sc...],
  [*III*],
  [HIGH],
  [LOW],
  
  [2023],
  [It Takes Two to Negotiate: Modeling Social Exchange in Online Multiplayer Games],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2022],
  [Dungeons and Dragons as a Dialogue Challenge for Artificial Intelligence],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  [2022],
  [Negotiation and honesty in artificial intelligence methods for the board game of Diplomacy],
  [Link],
  [*III*],
  [HIGH],
  [LOW],
  
  // === Quadrant IV ===
  table.cell(colspan: 6)[*_Quadrant IV_*],
  
  [2025],
  [Managing Escalation in Off-the-Shelf Large Language Models],
  [Link],
  [*IV*],
  [HIGH],
  [HIGH],
  
  [2025],
  [When Two LLMs Debate, Both Think They'll Win],
  [Link],
  [*IV*],
  [HIGH],
  [HIGH],
  
  [2024],
  [Large Language Models in Wargaming: Methodology, Application, and Robustness],
  [10.1109/CVPRW63...],
  [*IV*],
  [HIGH],
  [HIGH],
  
  [2024],
  [Open-Ended Wargames with Large Language Models],
  [Link],
  [*IV*],
  [HIGH],
  [HIGH],
  
  [2024],
  [Outwit, Outplay, Out-Generate: A Framework for Designing Strategic Generative Agents in Competitive Environments],
  [Link],
  [*IV*],
  [HIGH],
  [HIGH],
  
  [2024],
  [Scaling Laws For Scalable Oversight],
  [Link],
  [*IV*],
  [HIGH],
  [HIGH],
  
  [2024],
  [What if LLMs Have Different World Views: Simulating Alien Civilizations with LLM-based Agents],
  [Link],
  [*IV*],
  [HIGH],
  [HIGH],
  
  [2023],
  [Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate],
  [Link],
  [*IV*],
  [HIGH],
  [HIGH],
  
)

// Legend
*Legend:* Quadrants (I-IV) represent different categories. 
Creativity levels are marked as HIGH or LOW for both Player and Adjudicator roles.

// Summary Statistics
*Total papers:* 88 | Quadrant I: 43 | Quadrant II: 4 | Quadrant III: 33 | Quadrant IV: 8
