\clearpage
\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Base, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant in evaluating the quality of the outputs for a given instruction. Your goal is to select the best output for the given instruction.
\newline
\newline
\textbf{[User Message]}\\
Select the Output (a) or Output (b) that is better for the given instruction. The two outputs are generated by two different AI chatbots respectively. \\
\newline
Here are some rules of the evaluation: \\
(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc. \\
(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.\\
(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are equally likely to be the better.
\newline
\newline
Do NOT provide any explanation for your choice.\\
Do NOT say both / neither are good.\\
You should answer using ONLY "Output (a)" or "Output (b)". Do NOT output any other words.\\
\newline

\# Instruction: \\
\{INSTRUCTION\}
\newline
\newline
\# Output (a): \\
\{OUTPUT\_1\}
\newline
\newline
\# Output (b): \\
\{OUTPUT\_2\}
\newline
\newline
\# Which is better, Output (a) or Output (b)? Your response should be either "Output (a)" or "Output (b)":
\end{tcolorbox}
\caption{Prompt for \texttt{base} protocol described in \S\ref{sec:all_protocols}.}
\label{fig:prompt_base}
\end{figure*}


\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=AlpacaEval, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a highly efficient assistant, who evaluates and selects the best large language model (LLMs) based on the quality of their responses to a given instruction. This process will be used to create a leaderboard reflecting the most accurate and human-preferred answers.
\newline
\newline
\textbf{[User Message]}\\
I require a leaderboard for various large language models. I'll provide you with prompts given to these models and their corresponding outputs. Your task is to assess these responses, and select the model that produces the best output from a human perspective. \\
\newline

\#\# Instruction

\{ \\
    "instruction": """\{INSTRUCTION\}""",\\
\}\\
\newline
\newline
\#\# Model Outputs
\newline

Here are the unordered outputs from the models. Each output is associated with a specific model, identified by a unique model identifier.
\\
\{\\
\hspace*{1cm}  \{
        "model\_identifier":  "m",\\
         \hspace*{1cm} "output": """\{OUTPUT\_1\}"""\\
   \hspace*{1cm}  \},\\
    \hspace*{1cm}\{\\
       \hspace*{1cm} "model\_identifier": "M",\\
        \hspace*{1cm}"output": """\{OUTPUT\_2\}"""\\
   \hspace*{1cm}       \}\\
\}\\
\newline
\#\# Task
\newline
Evaluate the models based on the quality and relevance of their outputs, and select the model that generated the best output. Answer by providing the model identifier of the best model. We will use your output as the name of the best model, so make sure your output only contains one of the following model identifiers and nothing else (no quotes, no spaces, no new lines, ...): Model (m) or Model (M).
\\ 

\#\# Which is better, Model (m) or Model (M)? Your response should be either "Model (m)" or "Model (M)":
\end{tcolorbox}
\caption{Prompt for AlpacaEval baseline described in \S\ref{baselines_protocols}}
\label{fig:prompt_alpaca}
\end{figure*}



\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=ArenaHard, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
Please act as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user prompt displayed below. You will be given assistant A's answer and assistant B's answer. Your job is to evaluate which assistant's answer is better.
\newline
\textbf{[User Message]}\\
Begin your evaluation by generating your own answer to the prompt. You must provide your answers before judging any answers.
\newline

When evaluating the assistants' answers, compare both assistants' answers with your answer. You must identify and correct any mistakes or inaccurate information.
\newline


Then consider if the assistant's answers are helpful, relevant, and concise. Helpful means the answer correctly responds to the prompt or follows the instructions. Note when user prompt has any ambiguity or more than one interpretation, it is more helpful and appropriate to ask for clarifications or more information from the user than providing an answer based on assumptions. Relevant means all parts of the response closely connect or are appropriate to what is being asked. Concise means the response is clear and not verbose or excessive.
\newline

Then consider the creativity and novelty of the assistant's answers when needed. Finally, identify any missing important information in the assistants' answers that would be beneficial to include when responding to the user prompt.
\newline

After providing your explanation, you must always end your response with either "Therefore, Answer (a) is better." or "Therefore, Answer (b) is better." verbatim.
\newline
\newline

<|User Prompt|>\\
\{INSTRUCTION\}
\\ 
\\
<|The Start of Answer (a)|> \\
\{OUTPUT\_1\} \\
<|The End of Answer (a)|>
\\
\\
<|The Start of Answer (b)|> \\
\{OUTPUT\_2\}\\
<|The End of Answer(b)|>\\
\\

\# Decision (Give an explanation of your evaluation followed by either "Therefore, Answer (a) is better." or "Therefore, Answer (b) is better." verbatim. Always claim which is better at the end.):

\end{tcolorbox}
\caption{Prompt for ArenaHard described in \S\ref{baselines_protocols}}
\label{fig:prompt_arena}
\end{figure*}




\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=WildBench, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are an expert evaluator. Your task is to evaluate the quality of the responses generated by two AI models. 
\newline
\textbf{[User Message]}\\
\# Instruction 
\\ \\ 
We will provide you with the user query and a pair of AI-generated responses (Response A and Response B). \\
You should first read the user query and the conversation history carefully for analyzing the task, and then evaluate the quality of the responses based on and rules provided below. \\
\newline

\# Conversation between User and AI
\\ 
\#\# User Query \\
<|begin\_of\_query|> \\
\{INSTRUCTION\} \\
<|end\_of\_query|>
\\ \\
\#\# Response A \\
<|begin\_of\_response\_A|> \\
\{OUTPUT\_1\}
\newline
<|end\_of\_response\_A|> \\

\#\# Response B \\
<|begin\_of\_response\_B|> \\
\{OUTPUT\_2\}
\\
<|end\_of\_response\_B|>
\\
\\
\# Evaluation   
\\ 
\#\# Checklist 
\newline
<|begin\_of\_checklist|> \\
\{CHECKLIST\} \\
<|end\_of\_checklist|> \\
\newline

Please use this checklist to guide your evaluation, but do not limit your assessment to the checklist.
\\
\\ 

\#\# Rules 
\newline
\newline
You should compare the above two responses based on your analysis of the user query. \\
You should first write down your analysis and the checklist that you used for the evaluation, and then provide your assessment according to the checklist. \\
You should always end your response by selecting the better response. \\
\newline

\#\# Output Format \\

First, please output your analysis for each model response, and then summarize your assessment to three aspects: "reason A=B", "reason A>B", and "reason B>A", and finally make your choice for the final assessment by selecting the better response (ties are NOT allowed). \\
\newline
Please provide your evaluation results in the following json format by filling in the placeholders in []: \\

``` \\
\{ \\
\hspace*{1cm} "analysis of A": "[analysis of Response A]", \\
  \hspace*{1cm}  "analysis of B": "[analysis of Response B]",\\
  \hspace*{1cm}  "reason of A=B": "[where Response A and B perform equally well]", \\
  \hspace*{1cm}  "reason of A>B": "[where Response A is better than Response B]", \\
  \hspace*{1cm}  "reason of B>A": "[where Response B is better than Response A]", \\
  \hspace*{1cm}  "choice": "[Response (A) or Response (B)]", \\
\} \\
```


\end{tcolorbox}
\caption{Prompt for WildBench baseline described in \S\ref{baselines_protocols}}
\label{fig:prompt_wildbench}
\end{figure*}

\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=CoT, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant in evaluating the quality of the outputs for a given instruction. Your goal is to select the best output for the given instruction.
\newline
\newline
\textbf{[User Message]}\\
After giving a brief explanation, select the Output (a) or Output (b) that is better for the given instruction. The two outputs are generated by two different AI chatbots respectively.
\newline
\newline
Here are some rules of the evaluation: \\
(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.\\
(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction. \\
(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are equally likely to be the better.\\
\newline
\newline
You should first provide a brief explanation of your evaluation, and then always end your response with either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim.\\
Do NOT say both / neither are good.\\
Do NOT output any other words.\\
Do NOT say "Output (a) is better" or "Output (b) is better" at the beginning. You should do reasoning and thinking before claiming which is better.\\
\newline
\# Instruction: \\
\{INSTRUCTION\}
\newline
\newline
\# Output (a): \\
\{OUTPUT\_1\}
\newline
\newline
\# Output (b): \\
\{OUTPUT\_2\}
\newline
\newline
\# Decision (Give a brief explanation of your evaluation followed by either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim. Always claim which is better at the end. In your explanation, you should always use "Output (a)" or "Output (b)" to refer to the two outputs respectively.):
\end{tcolorbox}
\caption{Prompt for \texttt{cot} protocol described in \S\ref{sec:all_protocols}.}
\label{fig:prompt_cot}
\end{figure*}




\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Metric (metric generation prompt), fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant.
\newline
\newline
\textbf{[User Message]}\\
Please propose at most three concise questions about whether a potential output is a good output for a given instruction. Another assistant will evaluate different aspects of the output by answering all the questions.
\newline
\newline
Here are some rules of the evaluation: \\
(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction.
\\
(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.
\\
\newline
\# Instruction: \\
\{INSTRUCTION\}
\newline
\newline
\# Requirements for Your Output: \\
(1) The questions should **specifically** target the given instruction instead of some general standards, so the questions may revolve around key points of the instruction. \\
(2) You should directly give the questions without any other words. \\
(3) Questions are presented from most important to least important.\\
\newline
\# Please give your questions here:

\end{tcolorbox}
\caption{Prompt for metric generation stage of the \texttt{metric} protocol described in \S\ref{sec:all_protocols}.}
\label{fig:prompt_metric_gen}
\end{figure*}



\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Metric, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant in evaluating the quality of the outputs for a given instruction. Your goal is to select the best output for the given instruction.
\newline
\newline
\textbf{[User Message]}\\
Select the Output (a) or Output (b) that is better for the given instruction. The two outputs are generated by two different AI chatbots respectively.
\newline
\newline
Here are some rules of the evaluation: \\
(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.\\
(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.\\
(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are equally likely to be the better.\\
\newline
\newline
Do NOT provide any explanation for your choice. \\
Do NOT say both / neither are good.\\
You should answer using ONLY "Output (a)" or "Output (b)". Do NOT output any other words.\\
\newline
\newline
\# Instruction: \\
\{INSTRUCTION\}
\newline
\newline
\# Output (a): \\
\{OUTPUT\_1\}
\newline
\newline
\# Output (b): \\
\{OUTPUT\_2\}
\newline
\newline
\# Questions about Outputs:\\
Here are at most three questions about the outputs, which are presented from most important to least important. You can do the evaluation based on thinking about all the questions. \\
\{QUESTIONS\}
\newline
\newline
\# Which is better, Output (a) or Output (b)? Your response should be either "Output (a)" or "Output (b)":
\end{tcolorbox}
\caption{Prompt for \texttt{metric} protocol described in \S\ref{sec:all_protocols}.}
\label{fig:prompt_metric}
\end{figure*}


\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Reference, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant in evaluating the quality of the outputs for a given instruction. Your goal is to select the best output for the given instruction.
\newline
\newline
\textbf{[User Message]}\\
Select the Output (a) or Output (b) that is better for the given instruction. The two outputs are generated by two different AI chatbots respectively.
\newline\newline
Here are some rules of the evaluation:
\newline
(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.\\
(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.\\
(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are equally likely to be the better.\\
\newline
\newline
Do NOT provide any explanation for your choice. \\
Do NOT say both / neither are good.\\
You should answer using ONLY "Output (a)" or "Output (b)". Do NOT output any other words.\\
\newline
\newline
\# Instruction: \\
\{INSTRUCTION\}
\newline\newline
\# Output (a): \\
\{OUTPUT\_1\}
\newline\newline
\# Output (b):\\
\{OUTPUT\_2\}
\newline\newline
\# A reference output generated by a strong AI assistant: \\
\{REFERENCE\}
\newline
\newline
\# Which is better, Output (a) or Output (b)? Your response should be either "Output (a)" or "Output (b)":
\end{tcolorbox}
\caption{Prompt for \texttt{reference} protocol described in \S\ref{sec:all_protocols}.}
\label{fig:prompt_reference}
\end{figure*}


\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Metric + Reference, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant in evaluating the quality of the outputs for a given instruction. Your goal is to select the best output for the given instruction.
\newline

\textbf{[User Message]}\\
Select the Output (a) or Output (b) that is better for the given instruction. The two outputs are generated by two different AI chatbots respectively.
\newline

Here are some rules of the evaluation:

(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.

(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.

(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are equally likely to be the better.
\newline

Do NOT provide any explanation for your choice. \\
Do NOT say both / neither are good. \\
You should answer using ONLY "Output (a)" or "Output (b)". Do NOT output any other words.\\

\# Instruction:

\{INSTRUCTION\}
\newline

\# Output (a):

\{OUTPUT\_1\}
\newline

\# Output (b):

\{OUTPUT\_2\}
\newline

\# Questions about Outputs:

Here are at most three questions about the outputs, which are presented from most important to least important. You can do the evaluation based on thinking about all the questions.

\{QUESTIONS\}
\newline

\# A reference output generated by a strong AI assistant:

\{REFERENCE\}
\newline

\# Which is better, Output (a) or Output (b)? Your response should be either "Output (a)" or "Output (b)":
\end{tcolorbox}
\caption{Prompt for \texttt{metric + reference} protocol described in \S\ref{sec:all_protocols}.}
\label{fig:prompt_metric_reference}
\end{figure*}




\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Swap\&Synthesize, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant who reviews a debate between two other assistants in evaluating the quality of the outputs for a given instruction.
\newline

\textbf{[User Message]}\\
The two assistants, Assistant (a) and Assistant (b), are given an instruction, Output (a) and Output (b). They are asked to select the Output (a) or Output (b) that is better for the given instruction. Output (a) and Output (b) are generated by two different AI chatbots respectively.
\newline


Assistant (a) and Assistant (b) have conflicting evaluations. Your goal is to review their evaluations and give your final decision on which output is better.
\newline

Here are some rules of the evaluation:

(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.

(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.

(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are equally likely to be the better.
\newline

Now carefully review the instruction, Output (a), Output (b), and the debate between Assistant (a) and Assistant (b). Select the Output (a) or Output (b) that is better for the given instruction.

Do NOT provide any explanation for your choice.

Do NOT say both / neither are good.

You should answer using ONLY "Output (a)" or "Output (b)". Do NOT output any other words.
\newline

\# Instruction:

\{INSTRUCTION\}\newline

\# Output (b):

\{OUTPUT\_2\}\newline

\# Output (a):

\{OUTPUT\_1\}\newline


\# Debate between Assistant (a) and Assistant (b): 

\#\# Evaluation given by Assistant (a), who thinks Output (a) is better:

\{EXPLANATION\_1\}

\#\# Evaluation given by Assistant (b), who thinks Output (b) is better:

\{EXPLANATION\_2\}
\newline

\# Which is better, Output (a) or Output (b)? Your response should be either "Output (a)" or "Output (b)":
\end{tcolorbox}
\caption{Prompt for \texttt{swap\&synthesize} protocol described in \S\ref{sec:all_protocols}.}
\label{fig:prompt_swap_synthesis}
\end{figure*}




\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Fine-grained-diff, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant in evaluating the quality of the outputs for a given instruction. Your goal is to select the best output for the given instruction.
\newline
\newline
\textbf{[User Message]}\\
After giving a detailed explanation, select either Output (a) or Output (b) as the better response for the given instruction. The two outputs are generated by two different AI chatbots respectively.
\newline
\newline
Here are some rules of the evaluation: \\
(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.\\
(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.\\
(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are equally likely to be the better.\\
\newline
You should first provide a detailed explanation of your evaluation, and then always end your response with either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim.\\
Do NOT say both / neither are good.\\
Do NOT output any other words.\\
Do NOT say "Output (a) is better" or "Output (b) is better" at the beginning. You should do reasoning and thinking before claiming which is better.\\
\newline
Here is the evaluation plan:

1. Differences Identification: Enumerate the key fine-grained content differences observed between Output (a) and Output (b).\\
2. Explanation and Rationale: Provide explanations and rationale for which output better addresses the instruction by considering these differences, as well as other relevant factors such as relevance, completeness, coherence, and clarity.\\
3. Final Decision: End your response with either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim.\\
\newline
Provide your response in the following format:\\
"""\\
Differences Identification: \\
\newline
1. [Difference 1] \\
2. [Difference 2] \\
... \\
N. [Difference N] \\
\newline
Explanation and Rationale: [Detailed explanation and rationale for your decision] \\

Final Decision: Therefore, Output (a)/Output (b) is better. \\
"""\\

\# Instruction: \\
\{INSTRUCTION\}
\newline
\newline
\# Output (a): \\
\{OUTPUT\_1\}
\newline
\newline
\# Output (b): \\
\{OUTPUT\_2\}
\newline

\# Your Response (Give a detailed explanation of your evaluation followed by either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim. Always claim which is better at the end. In your explanation, you should always use "Output (a)" or "Output (b)" to refer to the two outputs respectively.):

\end{tcolorbox}
\caption{Prompt for \texttt{fine-graine-diff} protocol described in \S\ref{sec:all_protocols}.}
\label{fig:prompt_finegrained_differences}
\end{figure*}





\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Multi-role-round2, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant who evaluates the quality of the outputs for a given instruction. Your goal is to select the best output for the given instruction.
\newline

\textbf{[User Message]}\\
Select the Output (a) or Output (b) that is better for the given instruction. The two outputs are generated by two different AI chatbots respectively.
\newline

Here are some rules of the evaluation:

(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.

(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.

(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are equally likely to be the better.
\newline

You should first provide a brief explanation of your evaluation, and then always end your response with either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim.

Do NOT say both / neither are good.

Do NOT output any other words.

Do NOT say "Output (a) is better" or "Output (b) is better" at the beginning. You should do reasoning and thinking before claiming which is better.
\newline

There are a few other referees assigned the same task, it's your responsibility to discuss with them and think critically before you make your final judgement. You should avoid any potential bias and ensure that the order in which the responses were presented does not affect your judgment. Debate with others.

Always end your response with "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim. Make sure to make the claim to end your response.
\newline

\# Instruction: \\
\{INSTRUCTION\}
\newline

\# Output (a): \\
\{OUTPUT\_1\}
\newline

\# Output (b): \\
\{OUTPUT\_2\}
\newline

\# Previous referees' arguments: \\
\{CHAT\_HISTORY\}
\newline

\# Your role:

\{ROLE\_DESCRIPTION\}
\newline

\# Decision (Give a brief explanation of your evaluation followed by either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim. Always claim which is better at the end. In your explanation, you should always use "Output (a)" or "Output (b)" to refer to the two outputs respectively.):
\end{tcolorbox}
\caption{Prompt for \texttt{Multi-role-round2} protocol described in \S\ref{sec:all_protocols}.}
\label{fig:prompt_multi-role_debate}
\end{figure*}





\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Multi-aspect-single, fontupper=\scriptsize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant who analyzes and evaluates the quality of two candidate outputs for a given instruction task based on a list of criteria, and makes a final decision on which output is better.
\newline

\textbf{[User Message]}\\
Given an instruction and two responses, Output (a) and Output (b), each aiming to fulfill the task, your task is to carefully analyze and evaluate each output based on a list of criteria.
\newline

Here are some general rules for the evaluation:

(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.

(2) Outputs should NOT contain more or less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.
(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are equally likely to be the better one.
\newline

You should first provide an explanation of your evaluation, and then always end your response with either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim.

Do NOT say both / neither are good.

Do NOT output any other words.

Do NOT say "Output (a) is better" or "Output (b) is better" at the beginning. You should do reasoning and thinking before claiming which output is better.
\newline

Here are some criteria to consider:

1. Text Quality: The response should be fluent, well-structured, and free of spelling and grammatical errors. It should also be coherent, with a clear and logical flow of ideas.

2. Information Richness: The response is encouraged to provide rich, detailed and professional information, e.g. by providing examples, explanations, citations, and additional information. This criterion is not applicable if the user asks for a short or direct answer without additional information.

3. User Intention Inference: If the user's intention is not clearly expressed by the query, the response should provide some relevant information, do some reasonable inference and ask more information for clarification. This criterion is not applicable if the user's intention is clearly expressed by the query.

4. Accuracy: All contents provided or mentioned in the response should be accurate and correct.

5. Completeness of Instruction Following: For all key instructions (e.g., answer multiple questions or perform multiple tasks) and explicit constraints (e.g. word count, response length limit, word usage, output format, etc.) provided by the user, the response should be complete in following all of them without any omission.
\newline

Consider how well each output meets the list of criteria and provide a comparative analysis.
After your analysis, make a final decision on which output is better overall. Provide a brief explanation of your evaluation, weighing the importance of each aspect, and make a final decision. Be mindful of the importance of each aspect in the context of the given instruction task, as some aspects may significantly influence the output's quality and relevance to the instruction, while others might be less critical.
\newline

Provide your response in the following format:

"""

1.Text Quality:

[Your analysis]

2. Information Richness:

[Your analysis]

3. User Intention Inference:

[Your analysis]

4. Accuracy:

[Your analysis]

5. Completeness of Instruction Following:

[Your analysis]
\newline

[Your overall evaluation and explanation, followed by the final decision]

"""
\newline
\# Instruction: \\
\{INSTRUCTION\}
\newline

\# Output (a):\\
\{OUTPUT\_1\}
\newline

\# Output (b):\\
\{OUTPUT\_2\}
\newline

\# Decision (Give an explanation of your evaluation followed by either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim. Always claim which is better at the end. In your explanation, you should always use "Output (a)" or "Output (b)" to refer to the two outputs respectively.):
\end{tcolorbox}
\caption{Prompt for \texttt{multi-aspect-single} protocol described in \S\ref{sec:all_protocols}.}
\label{fig:prompt_multi_aspect_one}
\end{figure*}





\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Multi-aspect-two (aspect-wise analysis stage), fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant who analyzes and evaluates the quality of the outputs for a given instruction based on specific criteria.
\newline

\textbf{[User Message]}\\
Please provide a detailed analysis and evaluation of the two outputs based on the following criteria:

\{CRITERIA\_TEXT\}
\newline

Consider how well each output meets the criteria and provide a comparative analysis.
\newline

\# Instruction: \\
\{INSTRUCTION\}
\newline

\# Output (a): \\
\{OUTPUT\_1\}
\newline

\# Output (b): \\
\{OUTPUT\_2\}
\newline

\# Your analysis:
\end{tcolorbox}
\caption{Prompt for \texttt{multi-aspect-two} protocol described in \S\ref{sec:all_protocols}.  This is the prompt for aspect-wise analysis (the first stage) within the method.}
\label{fig:prompt_multi_aspect_two_analysis}
\end{figure*}


\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Multi-aspect-two (final evaluation stage), fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant who makes a final decision on which output is better based on the analysis of multiple aspects.
\newline

\textbf{[User Message]}\\
You have been provided with an instruction and two outputs, along with an analysis of each output based on several key aspects.

Your task is to carefully consider the analysis for each aspect and make a final decision on which output is better overall. Provide a brief explanation of your evaluation, weighing the importance of each aspect, and make a final decision. Be mindful of the importance of each aspect item in the context of the given instruction task, because some aspects may significantly influence the output's quality and relevance to the instruction, while others might be less critical.
\newline

Here are some rules of the evaluation:

(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.

(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.

(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are equally likely to be the better.
\newline

You should first provide an explanation of your evaluation, and then always end your response with either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim.

Do NOT say both / neither are good.

Do NOT output any other words.

Do NOT say "Output (a) is better" or "Output (b) is better" at the beginning. You should do reasoning and thinking before claiming which is better.
\newline

\# Instruction: \\
\{INSTRUCTION\}
\newline

\# Output (a): \\
\{OUTPUT\_1\}
\newline

\# Output (b): \\
\{OUTPUT\_2\}
\newline

\# Here are the aspect-wise analyses provided by another helpful critic:

\{ANALYSIS\_HISTORY\}
\newline

\# Decision (Give a brief explanation of your evaluation followed by either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim. Always claim which is better at the end. In your explanation, you should always use "Output (a)" or "Output (b)" to refer to the two outputs respectively.):
\end{tcolorbox}
\caption{Prompt for \texttt{multi-aspect-two} protocol described in \S\ref{sec:all_protocols}. This is the final evaluation prompt (the second stage) within the method.}
\label{fig:prompt_multi_aspect_two_final}
\end{figure*}




%
% 


\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=GPT4 Reference, fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant in evaluating the quality of the outputs for a given instruction. Your goal is to select the best output for the given instruction.
\newline


\textbf{[User Message]}\\
Select the Output (a) or Output (b) that is better for the given instruction. The two outputs are generated by two different AI chatbots respectively.
\newline

Here are some rules of the evaluation:
(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc. \\
(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction. \\
(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are **equally likely** to be the better. \\
\newline

Do NOT provide any explanation for your choice. \\
Do NOT say both / neither are good. \\ 
You should answer using ONLY "Output (a)" or "Output (b)". Do NOT output any other words. \\


\# Instruction: \\
\{INSTRUCTION\}
\newline

\# Output (a): \\
\{OUTPUT\_1\}
\newline

\# Output (b): \\
\{OUTPUT\_2\}
\newline

\# A reference output generated by a strong AI assistant:
\{REFERENCE\}
\newline

\# Which is better, Output (a) or Output (b)? Your response should be either "Output (a)" or "Output (b)":

\end{tcolorbox}
\caption{Prompt for \texttt{gpt4-reference} protocol described in \S\ref{sec:all_protocols}.}
\label{fig:prompt_gpt4_reference}
\end{figure*}






\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Prepair (pointwise analysis), fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant in evaluating the quality of the outputs for a given instruction. Your goal is to evaluate the quality of output for the given instruction.
\newline

\textbf{[User Message]}\\
Giving a brief explanation to evaluate the quality of the response to the given instruction. The output is generated by an AI chatbot.
\newline

Here are some rules of the evaluation:

(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.
\newline
(2) The model outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.
\newline
(3) You should avoid any potential bias and your judgment should be as objective as possible.
\newline


You should provide a brief explanation of your evaluation.
\newline
Your explanation should identify critical drawbacks in model outputs that do not meet the above evaluation rules.
\newline

\# Instruction: \\
\{INSTRUCTION\}
\newline

\# Output: \\
\{OUTPUT\}
\newline

\# Provide your explanation:
\end{tcolorbox}
\caption{Prompt for \texttt{prepair} protocol described in \S\ref{sec:all_protocols}.  This is the prompt for pointwise analysis (the first stage) within the protocol.}
\label{fig:prompt_prepair_pointwise}
\end{figure*}


\begin{figure*}[t!]
\begin{tcolorbox}[colback=black!3!white, colframe=black!70!white, title=Prepair (pairwise evaluation), fontupper=\footnotesize, fonttitle=\footnotesize]
\textbf{[System Message]} \\
You are a helpful assistant in evaluating the quality of the outputs for a given instruction. Your goal is to select the best output for the given instruction.
\newline


\textbf{[User Message]}\\
After giving a brief explanation, select the Output (a) or Output (b) that is better for the given instruction. The two outputs are generated by two different AI chatbots respectively.
\newline

Here are some rules of the evaluation:

(1) You should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.

(2) Outputs should NOT contain more/less than what the instruction asks for, as such outputs do NOT precisely execute the instruction.

(3) You should avoid any potential bias and your judgment should be as objective as possible. For example, the order in which the outputs were presented should NOT affect your judgment, as Output (a) and Output (b) are **equally likely** to be the
better.
\newline

You should first provide a brief explanation of your evaluation, and then always end your response with either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim.

Do NOT say both / neither are good.

Do NOT output any other words.

Do NOT say "Output (a) is better" or "Output (b) is better" at the beginning.
\newline

You should do reasoning and thinking **before** claiming which is better. Your explanation should identify critical drawbacks in model outputs that do not meet the above evaluation rules.
\newline

\# Instruction: \\
\{INSTRUCTION\}
\newline

\# Output (a): \\
\{OUTPUT\_1\}
\newline

\# Output (b): \\
\{OUTPUT\_2\}
\newline

\# Here's the analysis for each output you wrote earlier: \\
\{PER OUTPUT ANALYSES\}
\newline

\# Your Response (Provide your evaluation and reasoning, followed by either "Therefore, Output (a) is better." or "Therefore, Output (b) is better." verbatim):

\end{tcolorbox}
\caption{Prompt for \texttt{prepair} protocol described in \S\ref{sec:all_protocols}. This is the pairwise evaluation stage (the second stage) within the method.}
\label{fig:prompt_prepair_pairwise}
\end{figure*}




