@article{hajipour_business_2021,
	title = {A business retrieval model using scenario planning and analytics for life during and after the pandemic crisis},
	volume = {1},
	issn = {2772-4425},
	url = {https://www.sciencedirect.com/science/article/pii/S2772442521000046},
	doi = {10.1016/j.health.2021.100004},
	abstract = {The {COVID}-19 pandemic crisis has fundamentally changed the way we live and work forever. The business sector is forecasting and formulating different scenarios associated with the impact of the pandemic on its employees, customers, and suppliers. Various business retrieval models are under construction to cope with life after the {COVID}-19 Pandemic Crisis. However, the proposed plans and scenarios are static and cannot address the dynamic pandemic changes worldwide. They also have not considered the peripheral in-between scenarios to propel the shifting paradigm of businesses from the existing condition to the new one. Furthermore, the scenario drivers in the current studies are generally centered on the economic aspects of the pandemic with little attention to the social facets. This study aims to fill this gap by proposing scenario planning and analytics to study the impact of the Coronavirus pandemic on large-scale information technology-led Companies. The primary and peripheral scenarios are constructed based on a balanced set of business continuity and employee health drivers. Practical action plans are formulated for each scenario to devise plausible responses. Finally, a damage management framework is developed to cope with the mental disorders of the employees amid the disease.},
	pages = {100004},
	journaltitle = {Healthcare Analytics},
	shortjournal = {Healthcare Analytics},
	author = {Hajipour, Vahid and Aminian, Mohammad and Gharaei, Ali and Jalali, Sajjad},
	urldate = {2025-06-12},
	date = {2021-11-01},
	keywords = {Analytics, Business continuity, Pandemic crisis, Predictive modeling, Resiliency, Scenario planning},
}

@article{nasim_capability_2024,
	title = {A Capability Maturity Model for Benchmarking in Wargames},
	volume = {23},
	rights = {https://creativecommons.org/licenses/by-nc-nd/4.0},
	issn = {2048-8610, 2048-8602},
	url = {https://papers.academic-conferences.org/index.php/eccws/article/view/2511},
	doi = {10.34190/eccws.23.1.2511},
	abstract = {This research provides an analysis of maturity models, and insights from specific game studies such as unclassified non-kinetic games, supported by contributions from the wargaming community. By proposing a design framework inspired by capability maturity models used in software development, cyber security, and people management, this research introduces a new benchmark for evaluating wargames, in a reproducible and standardised fashion. This model facilitates the identification of strengths and areas for improvement, offering a structured path to higher maturity levels. It aims to enable wargame designers to assess and compare wargame components systematically, enhancing the ability to validate outcomes, predict gameplay effects, and support decision-making with greater confidence. Such advancements could significantly impact policies and improve disaster resilience, particularly within Defence strategy and capabilities, marking a significant advancement in the academic and practical enhancement of the wargaming field.},
	pages = {844--847},
	number = {1},
	journaltitle = {European Conference on Cyber Warfare and Security},
	shortjournal = {eccws},
	author = {Nasim, Mehwish and Wilden, Adam and Williams, Peter and Legrand, Timothy and Williams, Patricia},
	urldate = {2025-09-08},
	date = {2024-06-27},
}

@article{stark_class_2017,
	title = {A class of proximity-sensitive measures of relative deprivation},
	volume = {160},
	issn = {0165-1765},
	url = {https://www.sciencedirect.com/science/article/pii/S0165176517303257},
	doi = {10.1016/j.econlet.2017.08.002},
	abstract = {We introduce a new class of generalized measures of relative deprivation. The class takes the form of a power mean of order p. A characteristic of the class is that depending on the value of the proximity-sensitive parameter p, the class is capable of accommodating both a decreasing weight (the case of p{\textgreater}1), and an increasing weight (the case of p∈(0,1)) accorded to given changes in the incomes of the individuals who are wealthier than the reference individual, depending on their proximity in the income distribution to the reference individual.},
	pages = {105--110},
	journaltitle = {Economics Letters},
	shortjournal = {Economics Letters},
	author = {Stark, Oded and Bielawski, Jakub and Falniowski, Fryderyk},
	urldate = {2025-06-12},
	date = {2017-11-01},
	keywords = {Income distribution, Relative deprivation, Sensitivity to income transfers between wealthier individuals, Sensitivity to the proximity of changes in others’ incomes},
}

@article{garcia-nunes_computational_2020,
	title = {A computational tool for weak signals classification – Detecting threats and opportunities on politics in the cases of the United States and Brazilian presidential elections},
	volume = {123},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328720300999},
	doi = {10.1016/j.futures.2020.102607},
	abstract = {The literature on weak signals ({WS}) has been fruitful in recent years and this specific type of information has attracted the attention of several disciplines, notably the futures studies. However, most of these studies still focus on conceptual discussions, terminology, or the proposal for frameworks that do not take advantage of the evolution of information and communication technologies. In this paper, authors discussed the lack of tools to computationally support {WS} handling. In response to this lack, a computational tool was developed considering a previously published method for {WS} classification based on conceptual systems. This tool was applied and evaluated in experimental cases about surprising events that occurred in politics in recent years, considering traditional metrics of information retrieval. Experiments illustrate that organizations can create several conceptual systems to represent different scenarios and types of knowledge; after all, results showed that the tool can operate according to different artifacts of knowledge representation. This capacity is useful to mitigate the effects of the surveillance filter though the evidence does not directly confirm its usefulness for the monitoring activities. Furthermore, the tool provides a list of threats, opportunities and unlabeled {WS} that can trigger other steps of sensemaking about these signals.},
	pages = {102607},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Garcia-Nunes, Pedro Ivo and Rodrigues, Pedro Artico and Oliveira, Kaulitz Guimarães and da Silva, Ana Estela Antunes},
	urldate = {2025-06-12},
	date = {2020-10-01},
	keywords = {Conceptual systems, Opportunities, Threats, Weak signals},
}

@misc{shea_fairness-driven_2024,
	title = {A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies},
	url = {http://arxiv.org/abs/2409.18335},
	doi = {10.48550/arXiv.2409.18335},
	abstract = {Despite recent advancements in {AI} and {NLP}, negotiation remains a difficult domain for {AI} agents. Traditional game theoretic approaches that have worked well for two-player zero-sum games struggle in the context of negotiation due to their inability to learn human-compatible strategies. On the other hand, approaches that only use human data tend to be domain-specific and lack the theoretical guarantees provided by strategies grounded in game theory. Motivated by the notion of fairness as a criterion for optimality in general sum games, we propose a negotiation framework called {FDHC} which incorporates fairness into both the reward design and search to learn human-compatible negotiation strategies. Our method includes a novel, {RL}+search technique called {LGM}-Zero which leverages a pre-trained language model to retrieve human-compatible offers from large action spaces. Our results show that our method is able to achieve more egalitarian negotiation outcomes and improve negotiation quality.},
	number = {{arXiv}:2409.18335},
	publisher = {{arXiv}},
	author = {Shea, Ryan and Yu, Zhou},
	urldate = {2025-09-08},
	date = {2024-09-26},
	eprinttype = {arxiv},
	eprint = {2409.18335 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{shea_fairness-driven_2024-1,
	location = {Miami, Florida, {USA}},
	title = {A Fairness-Driven Method for Learning Human-Compatible Negotiation Strategies},
	url = {https://aclanthology.org/2024.findings-emnlp.308},
	doi = {10.18653/v1/2024.findings-emnlp.308},
	eventtitle = {Findings of the Association for Computational Linguistics: {EMNLP} 2024},
	pages = {5346--5370},
	booktitle = {Findings of the Association for Computational Linguistics: {EMNLP} 2024},
	publisher = {Association for Computational Linguistics},
	author = {Shea, Ryan and Yu, Zhou},
	urldate = {2025-09-08},
	date = {2024},
	langid = {english},
}

@article{gheorghiu_foresight_2016,
	title = {A foresight toolkit for smart specialization and entrepreneurial discovery},
	volume = {80},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S001632871630115X},
	doi = {10.1016/j.futures.2016.04.001},
	series = {Transforming Futures – a glimpse from the {WFSF} Conference 2013},
	abstract = {Smart specialization strategies ({RIS}3) have exploded in number across Europe over the past couple of years, among others due to the European Commission’s sustained effort – both conceptual and at the level of policy – to push this notion forward. What lies beneath the spate of recent {RIS}3s, in terms of specialization options as well as of the processes through which the latter were reached, is only now beginning to be examined in depth. Notably, the Commission did not offer a proper blueprint for {RIS}3-making, but opted instead to suggest a wide range of possible instruments. Based on our experience with the Romanian strategy-building process, in this article we outline a foresight-based toolkit for smart specialization and entrepreneurial discovery, though we too stop short of proposing a detailed full-fledged blueprint.},
	pages = {33--44},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Gheorghiu, Radu and Andreescu, Liviu and Curaj, Adrian},
	urldate = {2025-06-12},
	date = {2016-06-01},
	keywords = {Data analytics, Delphi, Entrepreneurial discovery, Large-scale foresight, Smart specialization, Weak signals},
}

@article{schuurman_game_2021,
	title = {A Game of Contexts: Prussian-German Professional Wargames and the Leadership Concept of Mission Tactics 1870–1880},
	volume = {28},
	issn = {0968-3445},
	url = {https://doi.org/10.1177/0968344519855104},
	doi = {10.1177/0968344519855104},
	shorttitle = {A Game of Contexts},
	pages = {504--524},
	number = {3},
	journaltitle = {War in History},
	author = {Schuurman, Paul},
	urldate = {2025-09-10},
	date = {2021-07-01},
	note = {Publisher: {SAGE} Publications Ltd},
}

@misc{askell_general_2021,
	title = {A General Language Assistant as a Laboratory for Alignment},
	url = {http://arxiv.org/abs/2112.00861},
	doi = {10.48550/arXiv.2112.00861},
	abstract = {Given the broad capabilities of large language models, it should be possible to work towards a general-purpose, text-based assistant that is aligned with human values, meaning that it is helpful, honest, and harmless. As an initial foray in this direction we study simple baseline techniques and evaluations, such as prompting. We find that the benefits from modest interventions increase with model size, generalize to a variety of alignment evaluations, and do not compromise the performance of large models. Next we investigate scaling trends for several training objectives relevant to alignment, comparing imitation learning, binary discrimination, and ranked preference modeling. We find that ranked preference modeling performs much better than imitation learning, and often scales more favorably with model size. In contrast, binary discrimination typically performs and scales very similarly to imitation learning. Finally we study a `preference model pre-training' stage of training, with the goal of improving sample efficiency when finetuning on human preferences.},
	number = {{arXiv}:2112.00861},
	publisher = {{arXiv}},
	author = {Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and {DasSarma}, Nova and Elhage, Nelson and Hatfield-Dodds, Zac and Hernandez, Danny and Kernion, Jackson and Ndousse, Kamal and Olsson, Catherine and Amodei, Dario and Brown, Tom and Clark, Jack and {McCandlish}, Sam and Olah, Chris and Kaplan, Jared},
	urldate = {2025-09-15},
	date = {2021-12-09},
	eprinttype = {arxiv},
	eprint = {2112.00861 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{sharma_hybrid_2015,
	title = {A Hybrid Scenario Planning Methodology for Interactive Digital Media},
	volume = {48},
	issn = {0024-6301},
	url = {https://www.sciencedirect.com/science/article/pii/S0024630115000667},
	doi = {10.1016/j.lrp.2015.09.007},
	abstract = {In this article, we present a scenario planning approach that is a hybrid of three main schools of thought. We propose such an approach in order to develop scenarios for a contemporary, technology-driven and fast-moving industry such as Interactive Digital Media. Our approach, while essentially qualitative in nature, nevertheless draws from the rigors of quantitative methods in identifying and then tracking the significant Dimensions of Analysis that impact the industry. The capture and analysis of real-time events was automated by an off-the-shelf web crawler with analytic functions, thus making our approach scalable over a larger scope and for longer periods of time. A morphological technique using Multidimensional Scaling isolated strands within the events leading to the identification of trends. This was followed by the mapping of strands to three emergent themes — ownership, distribution and innovation — which were used in an expert construction exercise to formulate plausible scenarios. We suggest that the approach we describe is particularly applicable for dynamic scenario planning that requires revisiting key assumptions and market conditions on a regular basis. We conclude that the ability to develop strategic narratives is the overriding benefit of scenario planning rather than the purported ability to predict the future.},
	pages = {412--429},
	number = {6},
	journaltitle = {Long Range Planning},
	shortjournal = {Long Range Planning},
	author = {Sharma, Ravi S. and Yang, Yi},
	urldate = {2025-06-12},
	date = {2015-12-01},
}

@inproceedings{gao_land-based_2024,
	location = {Cambridge, United Kingdom},
	title = {A Land-Based War-Gaming Simulation Method Based on Multi-Agent Proximal Policy Optimization},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-6565-8},
	url = {https://ieeexplore.ieee.org/document/10726993/},
	doi = {10.1109/QRS-C63300.2024.00082},
	eventtitle = {2024 {IEEE} 24th International Conference on Software Quality, Reliability, and Security Companion ({QRS}-C)},
	pages = {611--618},
	booktitle = {2024 {IEEE} 24th International Conference on Software Quality, Reliability, and Security Companion ({QRS}-C)},
	publisher = {{IEEE}},
	author = {Gao, Xule and Wang, Rui and Liu, Zhaohui and Ren, Yi},
	urldate = {2025-09-08},
	date = {2024-07-01},
	keywords = {Deep reinforcement learning, Feature extraction, {MAPPO}, Optimization, Painting, Security, Software algorithms, Software quality, Software reliability, Training, Uncertainty, reinforcement learning, situation extraction, war-gaming simulation},
}

@misc{el-sayed_mechanism-based_2024,
	title = {A Mechanism-Based Approach to Mitigating Harms from Persuasive Generative {AI}},
	url = {http://arxiv.org/abs/2404.15058},
	doi = {10.48550/arXiv.2404.15058},
	abstract = {Recent generative {AI} systems have demonstrated more advanced persuasive capabilities and are increasingly permeating areas of life where they can influence decision-making. Generative {AI} presents a new risk profile of persuasion due the opportunity for reciprocal exchange and prolonged interactions. This has led to growing concerns about harms from {AI} persuasion and how they can be mitigated, highlighting the need for a systematic study of {AI} persuasion. The current definitions of {AI} persuasion are unclear and related harms are insufficiently studied. Existing harm mitigation approaches prioritise harms from the outcome of persuasion over harms from the process of persuasion. In this paper, we lay the groundwork for the systematic study of {AI} persuasion. We first put forward definitions of persuasive generative {AI}. We distinguish between rationally persuasive generative {AI}, which relies on providing relevant facts, sound reasoning, or other forms of trustworthy evidence, and manipulative generative {AI}, which relies on taking advantage of cognitive biases and heuristics or misrepresenting information. We also put forward a map of harms from {AI} persuasion, including definitions and examples of economic, physical, environmental, psychological, sociocultural, political, privacy, and autonomy harm. We then introduce a map of mechanisms that contribute to harmful persuasion. Lastly, we provide an overview of approaches that can be used to mitigate against process harms of persuasion, including prompt engineering for manipulation classification and red teaming. Future work will operationalise these mitigations and study the interaction between different types of mechanisms of persuasion.},
	number = {{arXiv}:2404.15058},
	publisher = {{arXiv}},
	author = {El-Sayed, Seliem and Akbulut, Canfer and {McCroskery}, Amanda and Keeling, Geoff and Kenton, Zachary and Jalan, Zaria and Marchal, Nahema and Manzini, Arianna and Shevlane, Toby and Vallor, Shannon and Susser, Daniel and Franklin, Matija and Bridgers, Sophie and Law, Harry and Rahtz, Matthew and Shanahan, Murray and Tessler, Michael Henry and Douillard, Arthur and Everitt, Tom and Brown, Sasha},
	urldate = {2025-09-08},
	date = {2024-04-23},
	eprinttype = {arxiv},
	eprint = {2404.15058 [cs]},
	keywords = {Artificial Intelligence (cs.{AI}), Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computers and Society (cs.{CY}), {FOS}: Computer and information sciences},
}

@article{zhang_pathfinding_2023,
	title = {A {PathFinding} Method in Hexagonal Tactical Wargame},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10165503/},
	doi = {10.1109/ICIBA56860.2023.10165503},
	abstract = {In tactical wargames, the maneuver path planning of combat units is a fundamental issue that needs to be studied in computer-generated force simulation. The paper first describes the design and specific characteristics of the hexagonal wargame map; then explains the general principle and method process of the A* algorithm; because of the characteristics of tactical wargame pathfinding, a maneuver cost calculation model based on historical confrontation data is proposed, and the A* algorithm is improved based on the characteristics of the hexagonal map. Finally, a simulation experiment is carried out to prove that the method proposed in this paper can better realize the pathfinding of combat units and enhance their safety during maneuvers.},
	pages = {1620--1624},
	journaltitle = {2023 {IEEE} 3rd International Conference on Information Technology, Big Data and Artificial Intelligence ({ICIBA})},
	author = {Zhang, Yang and Zhang, Junfeng and Wang, Juan and Zhao, Binyu and Chu, Minnan},
	urldate = {2025-09-13},
	date = {2023-05-26},
	note = {Conference Name: 2023 {IEEE} 3rd International Conference on Information Technology, Big Data and Artificial Intelligence ({ICIBA})
{ISBN}: 9781665490795
Place: Chongqing, China
Publisher: {IEEE}},
}

@article{sears_real_2019,
	title = {A real options model of market entry: Endogenous uncertainty and exogenous uncertainty},
	volume = {25},
	issn = {1075-4253},
	url = {https://www.sciencedirect.com/science/article/pii/S1075425317304465},
	doi = {10.1016/j.intman.2019.03.003},
	shorttitle = {A real options model of market entry},
	abstract = {We develop a real options model of market entry that focuses on the dueling growth and deferral options by differentiating between endogenous uncertainty and exogenous uncertainty. While exogenous uncertainty influences the growth option market value or price, it is endogenous uncertainty that influences the value of the growth option through the ability to create a competitive advantage from preemptive market entry. First, the firm can decrease the exercise price of the growth option (i.e., the cost of the follow-on investment) through experiential learning that reduces endogenous uncertainty. Second, the firm can increase the relative discounted cash flows of the follow-on investment due to its ability to influence market demand that reduces endogenous uncertainty. On the other hand, the value of the deferral option increases with exogenous uncertainty as firms cannot influence exogenous uncertainty, and therefore, should invest elsewhere while waiting for the exogenous uncertainty to subside. As such, we provide a solution to the conundrum that the value of both the growth option and the deferral option increase with uncertainty. Finally, we demonstrate how the model addresses sequential market entry; irreversibility and market entry mode; competition; scarce strategic resources; host country development level; and industry life cycle stage.},
	pages = {100672},
	number = {3},
	journaltitle = {Journal of International Management},
	shortjournal = {Journal of International Management},
	author = {Sears, Joshua B.},
	urldate = {2025-06-12},
	date = {2019-09-01},
	keywords = {Endogenous uncertainty, Exogenous uncertainty, Internationalization, Market entry, Real options},
}

@misc{walter_red_2023,
	title = {A Red Teaming Framework for Securing {AI} in Maritime Autonomous Systems},
	url = {http://arxiv.org/abs/2312.11500},
	doi = {10.48550/arXiv.2312.11500},
	abstract = {Artificial intelligence ({AI}) is being ubiquitously adopted to automate processes in science and industry. However, due to its often intricate and opaque nature, {AI} has been shown to possess inherent vulnerabilities which can be maliciously exploited with adversarial {AI}, potentially putting {AI} users and developers at both cyber and physical risk. In addition, there is insufficient comprehension of the real-world effects of adversarial {AI} and an inadequacy of {AI} security examinations; therefore, the growing threat landscape is unknown for many {AI} solutions. To mitigate this issue, we propose one of the first red team frameworks for evaluating the {AI} security of maritime autonomous systems. The framework provides operators with a proactive (secure by design) and reactive (post-deployment evaluation) response to securing {AI} technology today and in the future. This framework is a multi-part checklist, which can be tailored to different systems and requirements. We demonstrate this framework to be highly effective for a red team to use to uncover numerous vulnerabilities within a real-world maritime autonomous systems {AI}, ranging from poisoning to adversarial patch attacks. The lessons learned from systematic {AI} red teaming can help prevent {MAS}-related catastrophic events in a world with increasing uptake and reliance on mission-critical {AI}.},
	number = {{arXiv}:2312.11500},
	publisher = {{arXiv}},
	author = {Walter, Mathew J. and Barrett, Aaron and Tam, Kimberly},
	urldate = {2025-09-08},
	date = {2023-12-08},
	eprinttype = {arxiv},
	eprint = {2312.11500 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
}

@incollection{zani_review_2020,
	title = {A review of security awareness approaches},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-819204-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128192047000063},
	pages = {97--127},
	booktitle = {Cyber Influence and Cognitive Threats},
	publisher = {Elsevier},
	author = {Zani, Azma Alina Ali and Norman, Azah Anir and Ghani, Norjihan Abdul},
	urldate = {2025-08-06},
	date = {2020},
	langid = {english},
	doi = {10.1016/B978-0-12-819204-7.00006-3},
}

@article{whitney_review_2014,
	title = {A review of the effectiveness of game-based training for dismounted soldiers},
	volume = {11},
	issn = {1548-5129},
	url = {https://doi.org/10.1177/1548512912472773},
	doi = {10.1177/1548512912472773},
	abstract = {Computer games are increasingly being used by armed forces to supplement conventional training methods. However, despite considerable anecdotal claims about their training effectiveness, empirical evidence is lacking. This paper critically reviews major studies conducted in the past decade that have examined game-based training with dismounted soldiers. The findings indicate that these studies are characterized by methodological limitations and that the evidence regarding the effectiveness of game-based training for this military population is not compelling. Furthermore, due to methodological limitations with the studies, the possibility of negative training effects cannot be discounted. The paper concludes with implications for the scientific and military communities, as well as recommendations for the conduct of future studies in this area.},
	pages = {319--328},
	number = {4},
	journaltitle = {The Journal of Defense Modeling and Simulation},
	shortjournal = {Journal of Defense Modeling \& Simulation},
	author = {Whitney, Susannah J. and Temby, Philip and Stephens, Ashley},
	urldate = {2025-06-26},
	date = {2014-10-01},
	note = {Publisher: {SAGE} Publications},
}

@book{australia_department_of_defense_simple_2017,
	title = {A Simple Handbook for Non-Traditional Red Teaming},
	abstract = {This report represents a guide for those wishing to apply red teaming methods in a structured manner, and provides lessons developed in both the military and national security environments. It describes the practice of red teaming in the context of biases and heuristics followed by techniques and activity designs allowing others to design and apply red teaming activities across a range of domains.},
	publisher = {Defense Science and Technology Group},
	author = {Australia Department of Defense},
	date = {2017},
	langid = {english},
}

@article{bhuiyan_stochastic_2019,
	title = {A stochastic programming model with endogenous uncertainty for incentivizing fuel reduction treatment under uncertain landowner behavior},
	volume = {277},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221719302255},
	doi = {10.1016/j.ejor.2019.03.003},
	abstract = {Reducing the potential damage caused by a wildfire is a problem of significant importance to land and fire managers. Fuel reduction treatment is a well-known method of reducing the risk of fire occurrence and spread on landscapes. However, officials seeking fuel reduction treatments on privately owned lands can only encourage it through incentive programs such as cost-share programs. This research developed a methodology that provides the basis for a decision-making tool to help managers allocate limited cost-share resources among a set of landowners to maximize wildfire risk reduction by implementing a hazardous fuel reduction treatment. A key feature of the methodology is that it incorporates uncertainty in the landowners’ decision of whether or not to implement treatment on their lands. The methodology is based on a stochastic programming model with endogenous uncertainty where the probability that a landowner accepts a cost-share offer to implement a fuel reduction treatment on their land depends on the offer amount. To estimate the probability that a landowner accepts a given cost-share offer amount, we used a predictive modeling technique to analyze landowner survey data. The results provide insight about the effects of different cost-share allocation strategies on the expected damage. Numerical experiments show that the risk-based allocation provides up to 37.3\% more reduction in damage compared to other strategies that allocate equal cost-share amounts among landowners. Additionally, the results show that the solution quality is substantially sensitive to changes in the number of resource allocation levels.},
	pages = {699--718},
	number = {2},
	journaltitle = {European Journal of Operational Research},
	shortjournal = {European Journal of Operational Research},
	author = {Bhuiyan, Tanveer Hossain and Moseley, Maxwell C. and Medal, Hugh R. and Rashidi, Eghbal and Grala, Robert K.},
	urldate = {2025-06-12},
	date = {2019-09-01},
	keywords = {Monte Carlo simulation, {OR} in natural resources, Predictive modeling, Two-stage stochastic programming, Wildfire hazard},
}

@misc{gorton_survey_2024,
	title = {A survey of air combat behavior modeling using machine learning},
	url = {http://arxiv.org/abs/2404.13954},
	doi = {10.48550/arXiv.2404.13954},
	abstract = {With the recent advances in machine learning, creating agents that behave realistically in simulated air combat has become a growing field of interest. This survey explores the application of machine learning techniques for modeling air combat behavior, motivated by the potential to enhance simulation-based pilot training. Current simulated entities tend to lack realistic behavior, and traditional behavior modeling is labor-intensive and prone to loss of essential domain knowledge between development steps. Advancements in reinforcement learning and imitation learning algorithms have demonstrated that agents may learn complex behavior from data, which could be faster and more scalable than manual methods. Yet, making adaptive agents capable of performing tactical maneuvers and operating weapons and sensors still poses a significant challenge. The survey examines applications, behavior model types, prevalent machine learning methods, and the technical and human challenges in developing adaptive and realistically behaving agents. Another challenge is the transfer of agents from learning environments to military simulation systems and the consequent demand for standardization. Four primary recommendations are presented regarding increased emphasis on beyond-visual-range scenarios, multi-agent machine learning and cooperation, utilization of hierarchical behavior models, and initiatives for standardization and research collaboration. These recommendations aim to address current issues and guide the development of more comprehensive, adaptable, and realistic machine learning-based behavior models for air combat applications.},
	number = {{arXiv}:2404.13954},
	publisher = {{arXiv}},
	author = {Gorton, Patrick Ribu and Strand, Andreas and Brathen, Karsten},
	urldate = {2025-09-08},
	date = {2024-04-22},
	eprinttype = {arxiv},
	eprint = {2404.13954 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@misc{xu_survey_2024,
	title = {A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges},
	url = {http://arxiv.org/abs/2403.10249},
	doi = {10.48550/arXiv.2403.10249},
	shorttitle = {A Survey on Game Playing Agents and Large Models},
	abstract = {The swift evolution of Large-scale Models ({LMs}), either language-focused or multi-modal, has garnered extensive attention in both academy and industry. But despite the surge in interest in this rapidly evolving area, there are scarce systematic reviews on their capabilities and potential in distinct impactful scenarios. This paper endeavours to help bridge this gap, offering a thorough examination of the current landscape of {LM} usage in regards to complex game playing scenarios and the challenges still open. Here, we seek to systematically review the existing architectures of {LM}-based Agents ({LMAs}) for games and summarize their commonalities, challenges, and any other insights. Furthermore, we present our perspective on promising future research avenues for the advancement of {LMs} in games. We hope to assist researchers in gaining a clear understanding of the field and to generate more interest in this highly impactful research direction. A corresponding resource, continuously updated, can be found in our {GitHub} repository.},
	number = {{arXiv}:2403.10249},
	publisher = {{arXiv}},
	author = {Xu, Xinrun and Wang, Yuxin and Xu, Chaoyi and Ding, Ziluo and Jiang, Jiechuan and Ding, Zhiming and Karlsson, Börje F.},
	urldate = {2025-09-08},
	date = {2024-03-15},
	eprinttype = {arxiv},
	eprint = {2403.10249 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@misc{hu_survey_2025,
	title = {A Survey on Large Language Model-Based Game Agents},
	url = {http://arxiv.org/abs/2404.02039},
	doi = {10.48550/arXiv.2404.02039},
	abstract = {The development of game agents holds a critical role in advancing towards Artificial General Intelligence. The progress of Large Language Models ({LLMs}) offers an unprecedented opportunity to evolve and empower game agents with human-like decision-making capabilities in complex computer game environments. This paper provides a comprehensive overview of {LLM}-based game agents from a holistic viewpoint. First, we introduce the conceptual architecture of {LLM}-based game agents, centered around three core functional components: memory, reasoning and in/output. Second, we survey existing representative {LLM}-based game agents documented in the literature with respect to methodologies and adaptation agility across six genres of games, including adventure, communication, competition, cooperation, simulation, and crafting \& exploration games. Finally, we present an outlook of future research and development directions in this burgeoning field. A curated list of relevant papers is maintained and made accessible at: https://github.com/git-disl/awesome-{LLM}-game-agent-papers.},
	number = {{arXiv}:2404.02039},
	publisher = {{arXiv}},
	author = {Hu, Sihao and Huang, Tiansheng and Liu, Gaowen and Kompella, Ramana Rao and Ilhan, Fatih and Tekin, Selim Furkan and Xu, Yichang and Yahn, Zachary and Liu, Ling},
	urldate = {2025-09-08},
	date = {2025-03-30},
	eprinttype = {arxiv},
	eprint = {2404.02039 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@misc{feng_survey_2025,
	title = {A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios},
	url = {http://arxiv.org/abs/2412.03920},
	doi = {10.48550/arXiv.2412.03920},
	abstract = {Game-theoretic scenarios have become pivotal in evaluating the social intelligence of Large Language Model ({LLM})-based social agents. While numerous studies have explored these agents in such settings, there is a lack of a comprehensive survey summarizing the current progress. To address this gap, we systematically review existing research on {LLM}-based social agents within game-theoretic scenarios. Our survey organizes the findings into three core components: Game Framework, Social Agent, and Evaluation Protocol. The game framework encompasses diverse game scenarios, ranging from choice-focusing to communication-focusing games. The social agent part explores agents' preferences, beliefs, and reasoning abilities, as well as their interactions and synergistic effects on decision-making. The evaluation protocol covers both game-agnostic and game-specific metrics for assessing agent performance. Additionally, we analyze the performance of current social agents across various game scenarios. By reflecting on the current research and identifying future research directions, this survey provides insights to advance the development and evaluation of social agents in game-theoretic scenarios.},
	number = {{arXiv}:2412.03920},
	publisher = {{arXiv}},
	author = {Feng, Xiachong and Dou, Longxu and Li, Ella and Wang, Qinghao and Wang, Haochuan and Guo, Yu and Ma, Chang and Kong, Lingpeng},
	urldate = {2025-09-13},
	date = {2025-07-20},
	eprinttype = {arxiv},
	eprint = {2412.03920 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{liu_symmetric_2016,
	title = {A symmetric two-player all-pay contest with correlated information},
	volume = {145},
	issn = {0165-1765},
	url = {https://www.sciencedirect.com/science/article/pii/S0165176516301604},
	doi = {10.1016/j.econlet.2016.05.004},
	abstract = {We construct both monotonic and non-monotonic symmetric Bayesian Nash equilibria for a two-player all-pay contest with binary types and correlated information structures. We also employ a class of parametric distributions to illustrate our equilibrium construction explicitly and to derive some comparative statics results.},
	pages = {6--10},
	journaltitle = {Economics Letters},
	shortjournal = {Economics Letters},
	author = {Liu, Zhiyang and Chen, Bo},
	urldate = {2025-06-12},
	date = {2016-08-01},
	keywords = {All-pay auction, Correlated types, Symmetric equilibrium},
}

@article{dorton_wargame-augmented_2020,
	title = {A Wargame-Augmented Knowledge Elicitation Method for the Agile Development of Novel Systems},
	volume = {8},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-8954},
	url = {https://www.mdpi.com/2079-8954/8/3/27},
	doi = {10.3390/systems8030027},
	abstract = {There are inherent difficulties in designing an effective Human–Machine Interface ({HMI}) for a first-of-its-kind system. Many leading cognitive research methods rely upon experts with prior experiences using the system and/or some type of existing mockups or working prototype of the {HMI}, and neither of these resources are available for such a new system. Further, these methods are time consuming and incompatible with more rapid and iterative systems development models (e.g., Agile/Scrum). To address these challenges, we developed a Wargame-Augmented Knowledge Elicitation ({WAKE}) method to identify information requirements and underlying assumptions in operator decision making concurrently with operational concepts. The developed {WAKE} method incorporates naturalistic observations of operator decision making in a wargaming scenario with freeze-probe queries and structured analytic techniques to identify and prioritize information requirements for a novel {HMI}. An overview of the method, required apparatus, and associated analytical techniques is provided. Outcomes, lessons learned, and topics for future research resulting from two different applications of the {WAKE} method are also discussed.},
	pages = {27},
	number = {3},
	journaltitle = {Systems},
	shortjournal = {Systems},
	author = {Dorton, Stephen L. and Maryeski, {LeeAnn} R. and Ogren, Lauren and Dykens, Ian T. and Main, Adam},
	urldate = {2025-09-08},
	date = {2020-08-12},
	langid = {english},
}

@misc{pona_abstract_2025,
	title = {Abstract Counterfactuals for Language Model Agents},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2506.02946},
	doi = {10.48550/ARXIV.2506.02946},
	abstract = {Counterfactual inference is a powerful tool for analysing and evaluating autonomous agents, but its application to language model ({LM}) agents remains challenging. Existing work on counterfactuals in {LMs} has primarily focused on token-level counterfactuals, which are often inadequate for {LM} agents due to their open-ended action spaces. Unlike traditional agents with fixed, clearly defined action spaces, the actions of {LM} agents are often implicit in the strings they output, making their action spaces difficult to define and interpret. Furthermore, the meanings of individual tokens can shift depending on the context, adding complexity to token-level reasoning and sometimes leading to biased or meaningless counterfactuals. We introduce {\textbackslash}emph\{Abstract Counterfactuals\}, a framework that emphasises high-level characteristics of actions and interactions within an environment, enabling counterfactual reasoning tailored to user-relevant features. Our experiments demonstrate that the approach produces consistent and meaningful counterfactuals while minimising the undesired side effects of token-level methods. We conduct experiments on text-based games and counterfactual text generation, while considering both token-level and latent-space interventions.},
	publisher = {{arXiv}},
	author = {Pona, Edoardo and Kazemi, Milad and Du, Yali and Watson, David and Paoletti, Nicola},
	urldate = {2025-09-08},
	date = {2025},
	note = {Version Number: 1},
	keywords = {{FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
}

@article{raikov_accelerating_2018,
	title = {Accelerating technology for self-organising networked democracy},
	volume = {103},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328717302380},
	doi = {10.1016/j.futures.2018.03.015},
	series = {Futures of Society: The Interactions Revolution},
	abstract = {The decision-making processes and strategic conversations in networked democracy have become faster due to artificial intelligence and information and communicative technologies. But traditional approaches to group decision-making support are not quite effective in networked conditions, especially when most of the factors describing the problem situations are poorly defined and non-quantitative. The author’s convergent technology (approach) helps ensure the necessary conditions for structuring information in a special way that accelerates networked group decision-making processes and makes them more sustainable and purposeful. The approach uses the experience of creating networked expertise systems (e-expertise), cognitive modelling, inverse problem solving, etc. The networked groups may include authorities, companies’ management and employees, experts, policy-makers, researchers, citizens, etc. The approach could be useful for group strategic formation for self-organising social networks and for creating effective strategies for government, non-government, regional, national, municipal, and other bodies. An example of testing the approach in real practice is presented.},
	pages = {17--26},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Raikov, Alexander},
	urldate = {2025-06-12},
	date = {2018-10-01},
	keywords = {Convergent approach, Group decision-making, Networked democracy, Self-organising processes, Strategic meeting},
}

@inproceedings{shea_ace_2024,
	location = {Miami, Florida, {USA}},
	title = {{ACE}: A {LLM}-based Negotiation Coaching System},
	url = {https://aclanthology.org/2024.emnlp-main.709},
	doi = {10.18653/v1/2024.emnlp-main.709},
	shorttitle = {{ACE}},
	eventtitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
	pages = {12720--12749},
	booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
	publisher = {Association for Computational Linguistics},
	author = {Shea, Ryan and Kallala, Aymen and Liu, Xin Lucy and Morris, Michael W. and Yu, Zhou},
	urldate = {2025-09-08},
	date = {2024},
	langid = {english},
}

@article{xu_achievement_2025,
	title = {Achievement Motivation and Performance in Wargames: Creativity as a Mediator},
	volume = {15},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2076-328X},
	url = {https://www.mdpi.com/2076-328X/15/4/557},
	doi = {10.3390/bs15040557},
	shorttitle = {Achievement Motivation and Performance in Wargames},
	abstract = {Computer-based wargames provide an experimental platform for studying cognitive antecedents and behavioral outcomes in dynamic scenarios. Our study examines how achievement motivation influence wargame players’ performance through the mechanism of creativity. In Study 1, we simplified the achievement motivation scale and revised the creativity scale for wargame contexts in China. After collecting data from students and wargame players (N1 = 300, N2 = 347), we validate their reliability and validity using exploratory and confirmatory factor analyses. Study 2 (N3 = 171) applied these validated scales to analyze the mechanism of creativity between achievement motivation and wargame performance. The results in Study 1 demonstrated that the refined two scales exhibited strong reliability and structural validity. The findings of Study 2 revealed that two types of motivation had different influences on wargame performance. The motivation of hope of success indirectly enhanced wargame performance through increased creativity. In contrast, the motivation of fear of failure reduced creativity and then negatively influenced overall results. Our study advances understanding of achievement motivation in dynamic gaming environments, suggesting that enhancing motivation of hope of success, decreasing motivation of fear of failure, and improving creativity may optimize performance to be more effective.},
	pages = {557},
	number = {4},
	journaltitle = {Behavioral Sciences},
	shortjournal = {Behavioral Sciences},
	author = {Xu, Weiwei and Ge, Sihui and Ding, Dang and Ren, Xiaopeng},
	urldate = {2025-09-08},
	date = {2025-04-21},
	langid = {english},
}

@article{zhang_actorcritic-based_2022,
	title = {Actor–critic-based decision-making method for the artificial intelligence commander in tactical wargames},
	volume = {19},
	issn = {1548-5129, 1557-380X},
	url = {https://journals.sagepub.com/doi/10.1177/1548512920954542},
	doi = {10.1177/1548512920954542},
	abstract = {In a tactical wargame, the decisions of the artificial intelligence ({AI}) commander are critical to the final combat result. Due to the existence of fog-of-war, {AI} commanders are faced with unknown and invisible information on the battlefield and lack of understanding of the situation, and it is difficult to make appropriate tactical strategies. The traditional knowledge rule-based decision-making method lacks flexibility and autonomy. How to make flexible and autonomous decision-making when facing complex battlefield situations is a difficult problem. This paper aims to solve the decision-making problem of the {AI} commander by using the deep reinforcement learning ({DRL}) method. We develop a tactical wargame as the research environment, which contains built-in script {AI} and supports the machine–machine combat mode. On this basis, an end-to-end actor–critic framework for commander decision making based on the convolutional neural network is designed to represent the battlefield situation and the reinforcement learning method is used to try different tactical strategies. Finally, we carry out a combat experiment between a {DRL}-based agent and a rule-based agent in a jungle terrain scenario. The result shows that the {AI} commander who adopts the actor–critic method successfully learns how to get a higher score in the tactical wargame, and the {DRL}-based agent has a higher winning ratio than the rule-based agent.},
	pages = {467--480},
	number = {3},
	journaltitle = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	shortjournal = {Journal of Defense Modeling \& Simulation},
	author = {Zhang, Junfeng and Xue, Qing},
	urldate = {2025-09-13},
	date = {2022-07},
	langid = {english},
}

@article{zhang_actorcritic-based_2020,
	title = {Actor–critic-based decision-making method for the artificial intelligence commander in tactical wargames},
	volume = {19},
	url = {https://api.semanticscholar.org/CorpusID:224907147},
	pages = {467 -- 480},
	journaltitle = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	author = {Zhang, Junfeng and Xue, Qing},
	date = {2020},
}

@article{zhang_actorcritic-based_2022-1,
	title = {Actor–critic-based decision-making method for the artificial intelligence commander in tactical wargames},
	volume = {19},
	issn = {1548-5129, 1557-380X},
	url = {https://journals.sagepub.com/doi/10.1177/1548512920954542},
	doi = {10.1177/1548512920954542},
	abstract = {In a tactical wargame, the decisions of the artificial intelligence ({AI}) commander are critical to the final combat result. Due to the existence of fog-of-war, {AI} commanders are faced with unknown and invisible information on the battlefield and lack of understanding of the situation, and it is difficult to make appropriate tactical strategies. The traditional knowledge rule-based decision-making method lacks flexibility and autonomy. How to make flexible and autonomous decision-making when facing complex battlefield situations is a difficult problem. This paper aims to solve the decision-making problem of the {AI} commander by using the deep reinforcement learning ({DRL}) method. We develop a tactical wargame as the research environment, which contains built-in script {AI} and supports the machine–machine combat mode. On this basis, an end-to-end actor–critic framework for commander decision making based on the convolutional neural network is designed to represent the battlefield situation and the reinforcement learning method is used to try different tactical strategies. Finally, we carry out a combat experiment between a {DRL}-based agent and a rule-based agent in a jungle terrain scenario. The result shows that the {AI} commander who adopts the actor–critic method successfully learns how to get a higher score in the tactical wargame, and the {DRL}-based agent has a higher winning ratio than the rule-based agent.},
	pages = {467--480},
	number = {3},
	journaltitle = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	shortjournal = {Journal of Defense Modeling \& Simulation},
	author = {Zhang, Junfeng and Xue, Qing},
	urldate = {2025-09-13},
	date = {2022-07},
	langid = {english},
}

@online{noauthor_actorcritic-based_nodate,
	title = {Actor–critic-based decision-making method for the artificial intelligence commander in tactical wargames {\textbar} Semantic Scholar},
	url = {https://www.semanticscholar.org/paper/Actor%E2%80%93critic-based-decision-making-method-for-the-Zhang-Xue/3ce9f795a7e877d1833916ed17d20c2fc9d40e7e},
	urldate = {2025-09-13},
}

@inproceedings{tiller_adaptive_2004,
	location = {Fort Belvoir, {VA}},
	title = {Adaptive Artificial Intelligence for Next Generation Conflict:},
	url = {http://www.dtic.mil/docs/citations/ADA423259},
	doi = {10.21236/ADA423259},
	shorttitle = {Adaptive Artificial Intelligence for Next Generation Conflict},
	abstract = {Abstract : Report developed under {STTR} contract for topic "Adaptive Artificial Intelligence for Next Generation Conflict". This project addresses an architecture and development approach for Artificial Intelligence in computer wargames. The results of this project were used in three technology test-bed applications having to do with modem air power, squad-level ground combat, and grand-operational warfare. The {AI} architecture was designed so that potential Al technologies can be utilized in this architecture in a "plug-and-play" manner. Under this architecture, new Al developments will be easy to incorporate into the {AI} engine. This will enable the resulting computer wargames to remain current and competitive in the future.},
	publisher = {Defense Technical Information Center},
	author = {Tiller, John and Rushing, John and {McDowell}, Drew and Tanner, Steve},
	urldate = {2025-09-13},
	date = {2004-05-15},
	doi = {10.21236/ADA423259},
}

@misc{ma_adaptive_2025,
	title = {Adaptive Command: Real-Time Policy Adjustment via Language Models in {StarCraft} {II}},
	url = {http://arxiv.org/abs/2508.16580},
	doi = {10.48550/arXiv.2508.16580},
	shorttitle = {Adaptive Command},
	abstract = {We present Adaptive Command, a novel framework integrating large language models ({LLMs}) with behavior trees for real-time strategic decision-making in {StarCraft} {II}. Our system focuses on enhancing human-{AI} collaboration in complex, dynamic environments through natural language interactions. The framework comprises: (1) an {LLM}-based strategic advisor, (2) a behavior tree for action execution, and (3) a natural language interface with speech capabilities. User studies demonstrate significant improvements in player decision-making and strategic adaptability, particularly benefiting novice players and those with disabilities. This work contributes to the field of real-time human-{AI} collaborative decision-making, offering insights applicable beyond {RTS} games to various complex decision-making scenarios.},
	number = {{arXiv}:2508.16580},
	publisher = {{arXiv}},
	author = {Ma, Weiyu and Xu, Dongyu and Lin, Shu and Zhang, Haifeng and Wang, Jun},
	urldate = {2025-09-11},
	date = {2025-08-05},
	eprinttype = {arxiv},
	eprint = {2508.16580 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
}

@article{ustun_adaptive_2021,
	title = {Adaptive Synthetic Characters for Military Training},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2101.02185},
	doi = {10.48550/ARXIV.2101.02185},
	abstract = {Behaviors of the synthetic characters in current military simulations are limited since they are generally generated by rule-based and reactive computational models with minimal intelligence. Such computational models cannot adapt to reflect the experience of the characters, resulting in brittle intelligence for even the most effective behavior models devised via costly and labor-intensive processes. Observation-based behavior model adaptation that leverages machine learning and the experience of synthetic entities in combination with appropriate prior knowledge can address the issues in the existing computational behavior models to create a better training experience in military training simulations. In this paper, we introduce a framework that aims to create autonomous synthetic characters that can perform coherent sequences of believable behavior while being aware of human trainees and their needs within a training simulation. This framework brings together three mutually complementary components. The first component is a Unity-based simulation environment - Rapid Integration and Development Environment ({RIDE}) - supporting One World Terrain ({OWT}) models and capable of running and supporting machine learning experiments. The second is Shiva, a novel multi-agent reinforcement and imitation learning framework that can interface with a variety of simulation environments, and that can additionally utilize a variety of learning algorithms. The final component is the Sigma Cognitive Architecture that will augment the behavior models with symbolic and probabilistic reasoning capabilities. We have successfully created proof-of-concept behavior models leveraging this framework on realistic terrain as an essential step towards bringing machine learning into military simulations.},
	author = {Ustun, Volkan and Kumar, Rajay and Reilly, Adam and Sajjadi, Seyed and Miller, Andrew},
	urldate = {2025-09-08},
	date = {2021},
	note = {Publisher: {arXiv}
Version Number: 1},
	keywords = {Artificial Intelligence (cs.{AI}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
}

@inproceedings{zhang_adarefiner_2024,
	location = {Mexico City, Mexico},
	title = {{AdaRefiner}: Refining Decisions of Language Models with Adaptive Feedback},
	url = {https://aclanthology.org/2024.findings-naacl.50},
	doi = {10.18653/v1/2024.findings-naacl.50},
	shorttitle = {{AdaRefiner}},
	eventtitle = {Findings of the Association for Computational Linguistics: {NAACL} 2024},
	pages = {782--799},
	booktitle = {Findings of the Association for Computational Linguistics: {NAACL} 2024},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Wanpeng and Lu, Zongqing},
	urldate = {2025-09-08},
	date = {2024},
	langid = {english},
}

@article{downes-martin_adjudication_2013,
	title = {Adjudication: The Diabolus in Machina of Wargaming},
	volume = {66},
	url = {https://digital-commons.usnwc.edu/nwc-review/vol66/iss3/6/},
	pages = {67--80},
	number = {3},
	journaltitle = {Naval War College Review},
	shortjournal = {Naval War College Review},
	author = {Downes-Martin, Stephen},
	date = {2013},
}

@misc{vaccaro_advancing_2025,
	title = {Advancing {AI} Negotiations: New Theory and Evidence from a Large-Scale Autonomous Negotiations Competition},
	url = {http://arxiv.org/abs/2503.06416},
	doi = {10.48550/arXiv.2503.06416},
	shorttitle = {Advancing {AI} Negotiations},
	abstract = {We conducted an International {AI} Negotiation Competition in which participants designed and refined prompts for {AI} negotiation agents. We then facilitated over 180,000 negotiations between these agents across multiple scenarios with diverse characteristics and objectives. Our findings revealed that principles from human negotiation theory remain crucial even in {AI}-{AI} contexts. Surprisingly, warmth--a traditionally human relationship-building trait--was consistently associated with superior outcomes across all key performance metrics. Dominant agents, meanwhile, were especially effective at claiming value. Our analysis also revealed unique dynamics in {AI}-{AI} negotiations not fully explained by existing theory, including {AI}-specific technical strategies like chain-of-thought reasoning, prompt injection, and strategic concealment. When we applied natural language processing ({NLP}) methods to the full transcripts of all negotiations we found positivity, gratitude and question-asking (associated with warmth) were strongly associated with reaching deals as well as objective and subjective value, whereas conversation lengths (associated with dominance) were strongly associated with impasses. The results suggest the need to establish a new theory of {AI} negotiation, which integrates classic negotiation theory with {AI}-specific negotiation theories to better understand autonomous negotiations and optimize agent performance.},
	number = {{arXiv}:2503.06416},
	publisher = {{arXiv}},
	author = {Vaccaro, Michelle and Caosun, Michael and Ju, Harang and Aral, Sinan and Curhan, Jared R.},
	urldate = {2025-09-13},
	date = {2025-07-07},
	eprinttype = {arxiv},
	eprint = {2503.06416 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
}

@misc{ravindran_adversarial_2025,
	title = {Adversarial Activation Patching: A Framework for Detecting and Mitigating Emergent Deception in Safety-Aligned Transformers},
	url = {http://arxiv.org/abs/2507.09406},
	doi = {10.48550/arXiv.2507.09406},
	shorttitle = {Adversarial Activation Patching},
	abstract = {Large language models ({LLMs}) aligned for safety through techniques like reinforcement learning from human feedback ({RLHF}) often exhibit emergent deceptive behaviors, where outputs appear compliant but subtly mislead or omit critical information. This paper introduces adversarial activation patching, a novel mechanistic interpretability framework that leverages activation patching as an adversarial tool to induce, detect, and mitigate such deception in transformer-based models. By sourcing activations from "deceptive" prompts and patching them into safe forward passes at specific layers, we simulate vulnerabilities and quantify deception rates. Through toy neural network simulations across multiple scenarios (e.g., 1000 trials per setup), we demonstrate that adversarial patching increases deceptive outputs to 23.9\% from a 0\% baseline, with layer-specific variations supporting our hypotheses. We propose six hypotheses, including transferability across models, exacerbation in multimodal settings, and scaling effects. An expanded literature review synthesizes over 20 key works in interpretability, deception, and adversarial attacks. Mitigation strategies, such as activation anomaly detection and robust fine-tuning, are detailed, alongside ethical considerations and future research directions. This work advances {AI} safety by highlighting patching's dual-use potential and provides a roadmap for empirical studies on large-scale models.},
	number = {{arXiv}:2507.09406},
	publisher = {{arXiv}},
	author = {Ravindran, Santhosh Kumar},
	urldate = {2025-09-13},
	date = {2025-07-12},
	eprinttype = {arxiv},
	eprint = {2507.09406 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{yang_agent_2025,
	title = {Agent Exchange: Shaping the Future of {AI} Agent Economics},
	url = {http://arxiv.org/abs/2507.03904},
	doi = {10.48550/arXiv.2507.03904},
	shorttitle = {Agent Exchange},
	abstract = {The rise of Large Language Models ({LLMs}) has transformed {AI} agents from passive computational tools into autonomous economic actors. This shift marks the emergence of the agent-centric economy, in which agents take on active economic roles-exchanging value, making strategic decisions, and coordinating actions with minimal human oversight. To realize this vision, we propose Agent Exchange ({AEX}), a specialized auction platform designed to support the dynamics of the {AI} agent marketplace. {AEX} offers an optimized infrastructure for agent coordination and economic participation. Inspired by Real-Time Bidding ({RTB}) systems in online advertising, {AEX} serves as the central auction engine, facilitating interactions among four ecosystem components: the User-Side Platform ({USP}), which translates human goals into agent-executable tasks; the Agent-Side Platform ({ASP}), responsible for capability representation, performance tracking, and optimization; Agent Hubs, which coordinate agent teams and participate in {AEX}-hosted auctions; and the Data Management Platform ({DMP}), ensuring secure knowledge sharing and fair value attribution. We outline the design principles and system architecture of {AEX}, laying the groundwork for agent-based economic infrastructure in future {AI} ecosystems.},
	number = {{arXiv}:2507.03904},
	publisher = {{arXiv}},
	author = {Yang, Yingxuan and Wen, Ying and Wang, Jun and Zhang, Weinan},
	urldate = {2025-09-13},
	date = {2025-07-05},
	eprinttype = {arxiv},
	eprint = {2507.03904 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Multiagent Systems},
}

@inproceedings{zhang_agent-pro_2024,
	location = {Bangkok, Thailand},
	title = {Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization},
	url = {https://aclanthology.org/2024.acl-long.292},
	doi = {10.18653/v1/2024.acl-long.292},
	shorttitle = {Agent-Pro},
	eventtitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	pages = {5348--5375},
	booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Wenqi and Tang, Ke and Wu, Hai and Wang, Mengna and Shen, Yongliang and Hou, Guiyang and Tan, Zeqi and Li, Peng and Zhuang, Yueting and Lu, Weiming},
	urldate = {2025-09-08},
	date = {2024},
	langid = {english},
}

@misc{belle_agents_2025,
	title = {Agents of Change: Self-Evolving {LLM} Agents for Strategic Planning},
	url = {http://arxiv.org/abs/2506.04651},
	doi = {10.48550/arXiv.2506.04651},
	shorttitle = {Agents of Change},
	abstract = {Recent advances in {LLMs} have enabled their use as autonomous agents across a range of tasks, yet they continue to struggle with formulating and adhering to coherent long-term strategies. In this paper, we investigate whether {LLM} agents can self-improve when placed in environments that explicitly challenge their strategic planning abilities. Using the board game Settlers of Catan, accessed through the open-source Catanatron framework, we benchmark a progression of {LLM}-based agents, from a simple game-playing agent to systems capable of autonomously rewriting their own prompts and their player agent's code. We introduce a multi-agent architecture in which specialized roles (Analyzer, Researcher, Coder, and Player) collaborate to iteratively analyze gameplay, research new strategies, and modify the agent's logic or prompt. By comparing manually crafted agents to those evolved entirely by {LLMs}, we evaluate how effectively these systems can diagnose failure and adapt over time. Our results show that self-evolving agents, particularly when powered by models like Claude 3.7 and {GPT}-4o, outperform static baselines by autonomously adopting their strategies, passing along sample behavior to game-playing agents, and demonstrating adaptive reasoning over multiple iterations.},
	number = {{arXiv}:2506.04651},
	publisher = {{arXiv}},
	author = {Belle, Nikolas and Barnes, Dakota and Amayuelas, Alfonso and Bercovich, Ivan and Wang, Xin Eric and Wang, William},
	urldate = {2025-09-13},
	date = {2025-06-05},
	eprinttype = {arxiv},
	eprint = {2506.04651 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{erskine_ai_2024,
	title = {{AI} and the decision to go to war: future risks and opportunities},
	volume = {78},
	issn = {1035-7718, 1465-332X},
	url = {https://www.tandfonline.com/doi/full/10.1080/10357718.2024.2349598},
	doi = {10.1080/10357718.2024.2349598},
	shorttitle = {{AI} and the decision to go to war},
	pages = {135--147},
	number = {2},
	journaltitle = {Australian Journal of International Affairs},
	shortjournal = {Australian Journal of International Affairs},
	author = {Erskine, Toni and Miller, Steven E.},
	urldate = {2025-09-08},
	date = {2024-03-03},
	langid = {english},
}

@misc{goodman_ai_2020,
	title = {{AI} and Wargaming},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2009.08922},
	doi = {10.48550/ARXIV.2009.08922},
	abstract = {Recent progress in Game {AI} has demonstrated that given enough data from human gameplay, or experience gained via simulations, machines can rival or surpass the most skilled human players in classic games such as Go, or commercial computer games such as Starcraft. We review the current state-of-the-art through the lens of wargaming, and ask firstly what features of wargames distinguish them from the usual {AI} testbeds, and secondly which recent {AI} advances are best suited to address these wargame-specific features.},
	publisher = {{arXiv}},
	author = {Goodman, James and Risi, Sebastian and Lucas, Simon},
	urldate = {2025-09-08},
	date = {2020},
	note = {Version Number: 2},
	keywords = {Artificial Intelligence (cs.{AI}), {FOS}: Computer and information sciences},
}

@article{goodman_ai_2020-1,
	title = {{AI} and Wargaming},
	url = {https://www.semanticscholar.org/paper/AI-and-Wargaming-Goodman-Risi/331acc8cc481f90a43fc96553ca0e479cf75ff15},
	abstract = {Recent progress in Game {AI} has demonstrated that given enough data from human gameplay, or experience gained via simulations, machines can rival or surpass the most skilled human players in classic games such as Go, or commercial computer games such as Starcraft. We review the current state-of-the-art through the lens of wargaming, and ask firstly what features of wargames distinguish them from the usual {AI} testbeds, and secondly which recent {AI} advances are best suited to address these wargame-specific features.},
	journaltitle = {{ArXiv}},
	author = {Goodman, J. and Risi, S. and Lucas, S.},
	urldate = {2025-09-13},
	date = {2020-09-18},
}

@unpublished{park_ai_2023,
	title = {{AI} deception: A survey of examples, risks, and potential solutions},
	url = {http://arxiv.org/abs/2308.14752},
	abstract = {This paper argues that a range of current {AI} systems have learned how to
deceive humans. We define deception as the systematic inducement of false
beliefs in the pursuit of some outcome other than the truth. We first
survey empirical examples of {AI} deception, discussing both special-use {AI}
systems (including Meta's {CICERO}) built for specific competitive
situations, and general-purpose {AI} systems (such as large language
models). Next, we detail several risks from {AI} deception, such as fraud,
election tampering, and losing control of {AI} systems. Finally, we outline
several potential solutions to the problems posed by {AI} deception: first,
regulatory frameworks should subject {AI} systems that are capable of
deception to robust risk-assessment requirements; second, policymakers
should implement bot-or-not laws; and finally, policymakers should
prioritize the funding of relevant research, including tools to detect {AI}
deception and to make {AI} systems less deceptive. Policymakers,
researchers, and the broader public should work proactively to prevent {AI}
deception from destabilizing the shared foundations of our society.},
	author = {Park, Peter S and Goldstein, Simon and O'Gara, Aidan and Chen, Michael and Hendrycks, Dan},
	urldate = {2024-07-26},
	date = {2023-08-28},
	note = {{ISBN}: 2308.14752
Publication Title: {arXiv} [cs.{CY}]},
}

@inproceedings{freeman_ai_2024,
	location = {Connections {UK} (presentation)},
	title = {{AI} in Wargaming (Conducttr Crisis Simulation Platform)},
	url = {https://www.professionalwargaming.co.uk/24AIinWargaming-AmeliaFreeman.pdf},
	publisher = {Connections {UK}},
	author = {Freeman, Amelia},
	date = {2024},
}

@unpublished{wang_aligning_2023,
	title = {Aligning Large Language Models with Human: A Survey},
	url = {http://arxiv.org/abs/2307.12966},
	abstract = {Large Language Models ({LLMs}) trained on extensive textual corpora have
emerged as leading solutions for a broad array of Natural Language
Processing ({NLP}) tasks. Despite their notable performance, these models
are prone to certain limitations such as misunderstanding human
instructions, generating potentially biased content, or factually
incorrect (hallucinated) information. Hence, aligning {LLMs} with human
expectations has become an active area of interest within the research
community. This survey presents a comprehensive overview of these
alignment technologies, including the following aspects. (1) Data
collection: the methods for effectively collecting high-quality
instructions for {LLM} alignment, including the use of {NLP} benchmarks, human
annotations, and leveraging strong {LLMs}. (2) Training methodologies: a
detailed review of the prevailing training methods employed for {LLM}
alignment. Our exploration encompasses Supervised Fine-tuning, both Online
and Offline human preference training, along with parameter-efficient
training mechanisms. (3) Model Evaluation: the methods for evaluating the
effectiveness of these human-aligned {LLMs}, presenting a multifaceted
approach towards their assessment. In conclusion, we collate and distill
our findings, shedding light on several promising future research avenues
in the field. This survey, therefore, serves as a valuable resource for
anyone invested in understanding and advancing the alignment of {LLMs} to
better suit human-oriented tasks and expectations. An associated {GitHub}
link collecting the latest papers is available at
https://github.com/{GaryYufei}/{AlignLLMHumanSurvey}.},
	author = {Wang, Yufei and Zhong, Wanjun and Li, Liangyou and Mi, Fei and Zeng, Xingshan and Huang, Wenyong and Shang, Lifeng and Jiang, Xin and Liu, Qun},
	date = {2023-07-24},
	note = {{ISBN}: 2307.12966
Publication Title: {arXiv} [cs.{CL}]},
}

@misc{feng_alphazero-like_2023,
	title = {Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2309.17179},
	doi = {10.48550/ARXIV.2309.17179},
	abstract = {Recent works like Tree-of-Thought ({ToT}) and Reasoning via Planning ({RAP}) aim to augment the reasoning capabilities of {LLMs} by using tree-search algorithms to guide multi-step reasoning. These methods rely on prompting a pre-trained model to serve as a value function and focus on problems with low search depth. As a result, these methods will not work in domains where the pre-trained {LLM} does not have enough knowledge to serve as an effective value function or in domains that require long-horizon planning. To address these limitations, we present an {AlphaZero}-like tree-search learning framework for {LLMs} (termed {TS}-{LLM}), systematically illustrating how tree-search with a learned value function can guide {LLM} decoding. {TS}-{LLM} distinguishes itself in two key ways. (1) Leveraging a learned value function and {AlphaZero}-like algorithms, our approach can be generally adaptable to a wide range of tasks, language models of any size, and tasks of varying search depths. (2) Our approach can guide {LLMs} during both inference and training, iteratively improving the {LLM}. Empirical results across reasoning, planning, alignment, and decision-making tasks show that {TS}-{LLM} outperforms existing approaches and can handle trees with a depth of 64.},
	publisher = {{arXiv}},
	author = {Feng, Xidong and Wan, Ziyu and Wen, Muning and {McAleer}, Stephen Marcus and Wen, Ying and Zhang, Weinan and Wang, Jun},
	urldate = {2025-09-08},
	date = {2023},
	note = {Version Number: 2},
	keywords = {Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
}

@misc{mao_alympics_2023,
	title = {{ALYMPICS}: {LLM} Agents Meet Game Theory -- Exploring Strategic Decision-Making with {AI} Agents},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2311.03220},
	doi = {10.48550/ARXIV.2311.03220},
	shorttitle = {{ALYMPICS}},
	abstract = {This paper introduces Alympics (Olympics for Agents), a systematic simulation framework utilizing Large Language Model ({LLM}) agents for game theory research. Alympics creates a versatile platform for studying complex game theory problems, bridging the gap between theoretical game theory and empirical investigations by providing a controlled environment for simulating human-like strategic interactions with {LLM} agents. In our pilot case study, the "Water Allocation Challenge," we explore Alympics through a challenging strategic game focused on the multi-round auction on scarce survival resources. This study demonstrates the framework's ability to qualitatively and quantitatively analyze game determinants, strategies, and outcomes. Additionally, we conduct a comprehensive human assessment and an in-depth evaluation of {LLM} agents in strategic decision-making scenarios. Our findings not only expand the understanding of {LLM} agents' proficiency in emulating human strategic behavior but also highlight their potential in advancing game theory knowledge, thereby enriching our understanding of both game theory and empowering further research into strategic decision-making domains with {LLM} agents. Codes, prompts, and all related resources are available at https://github.com/microsoft/Alympics.},
	publisher = {{arXiv}},
	author = {Mao, Shaoguang and Cai, Yuzhe and Xia, Yan and Wu, Wenshan and Wang, Xun and Wang, Fengyi and Ge, Tao and Wei, Furu},
	urldate = {2025-09-08},
	date = {2023},
	note = {Version Number: 4},
	keywords = {Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), Computer Science and Game Theory (cs.{GT}), {FOS}: Computer and information sciences},
}

@misc{idziejczak_among_2025,
	title = {Among Them: A game-based framework for assessing persuasion capabilities of {LLMs}},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2502.20426},
	doi = {10.48550/ARXIV.2502.20426},
	shorttitle = {Among Them},
	abstract = {The proliferation of large language models ({LLMs}) and autonomous {AI} agents has raised concerns about their potential for automated persuasion and social influence. While existing research has explored isolated instances of {LLM}-based manipulation, systematic evaluations of persuasion capabilities across different models remain limited. In this paper, we present an Among Us-inspired game framework for assessing {LLM} deception skills in a controlled environment. The proposed framework makes it possible to compare {LLM} models by game statistics, as well as quantify in-game manipulation according to 25 persuasion strategies from social psychology and rhetoric. Experiments between 8 popular language models of different types and sizes demonstrate that all tested models exhibit persuasive capabilities, successfully employing 22 of the 25 anticipated techniques. We also find that larger models do not provide any persuasion advantage over smaller models and that longer model outputs are negatively correlated with the number of games won. Our study provides insights into the deception capabilities of {LLMs}, as well as tools and data for fostering future research on the topic.},
	publisher = {{arXiv}},
	author = {Idziejczak, Mateusz and Korzavatykh, Vasyl and Stawicki, Mateusz and Chmutov, Andrii and Korcz, Marcin and Błądek, Iwo and Brzezinski, Dariusz},
	urldate = {2025-09-08},
	date = {2025},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), Computers and Society (cs.{CY}), {FOS}: Computer and information sciences, Multiagent Systems (cs.{MA})},
}

@misc{golechha_among_2025,
	title = {Among Us: A Sandbox for Measuring and Detecting Agentic Deception},
	rights = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
	url = {https://arxiv.org/abs/2504.04072},
	doi = {10.48550/ARXIV.2504.04072},
	shorttitle = {Among Us},
	abstract = {Prior studies on deception in language-based {AI} agents typically assess whether the agent produces a false statement about a topic, or makes a binary choice prompted by a goal, rather than allowing open-ended deceptive behavior to emerge in pursuit of a longer-term goal. To fix this, we introduce \${\textbackslash}textit\{Among Us\}\$, a sandbox social deception game where {LLM}-agents exhibit long-term, open-ended deception as a consequence of the game objectives. While most benchmarks saturate quickly, \${\textbackslash}textit\{Among Us\}\$ can be expected to last much longer, because it is a multi-player game far from equilibrium. Using the sandbox, we evaluate \$18\$ proprietary and open-weight {LLMs} and uncover a general trend: models trained with {RL} are comparatively much better at producing deception than detecting it. We evaluate the effectiveness of methods to detect lying and deception: logistic regression on the activations and sparse autoencoders ({SAEs}). We find that probes trained on a dataset of ``pretend you're a dishonest model: \${\textbackslash}dots\$'' generalize extremely well out-of-distribution, consistently obtaining {AUROCs} over 95\% even when evaluated just on the deceptive statement, without the chain of thought. We also find two {SAE} features that work well at deception detection but are unable to steer the model to lie less. We hope our open-sourced sandbox, game logs, and probes serve to anticipate and mitigate deceptive behavior and capabilities in language-based agents.},
	publisher = {{arXiv}},
	author = {Golechha, Satvik and Garriga-Alonso, Adrià},
	urldate = {2025-09-08},
	date = {2025},
	note = {Version Number: 2},
	keywords = {Artificial Intelligence (cs.{AI}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
}

@misc{chi_amongagents_2024,
	title = {{AMONGAGENTS}: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game},
	url = {http://arxiv.org/abs/2407.16521},
	doi = {10.48550/arXiv.2407.16521},
	shorttitle = {{AMONGAGENTS}},
	abstract = {Strategic social deduction games serve as valuable testbeds for evaluating the understanding and inference skills of language models, offering crucial insights into social science, artificial intelligence, and strategic gaming. This paper focuses on creating proxies of human behavior in simulated environments, with Among Us utilized as a tool for studying simulated human behavior. The study introduces a text-based game environment, named {AmongAgents}, that mirrors the dynamics of Among Us. Players act as crew members aboard a spaceship, tasked with identifying impostors who are sabotaging the ship and eliminating the crew. Within this environment, the behavior of simulated language agents is analyzed. The experiments involve diverse game sequences featuring different configurations of Crewmates and Impostor personality archetypes. Our work demonstrates that state-of-the-art large language models ({LLMs}) can effectively grasp the game rules and make decisions based on the current context. This work aims to promote further exploration of {LLMs} in goal-oriented games with incomplete information and complex action spaces, as these settings offer valuable opportunities to assess language model performance in socially driven scenarios.},
	number = {{arXiv}:2407.16521},
	publisher = {{arXiv}},
	author = {Chi, Yizhou and Mao, Lingjun and Tang, Zineng},
	urldate = {2025-09-10},
	date = {2024-07-24},
	eprinttype = {arxiv},
	eprint = {2407.16521},
	keywords = {Computation and Language (cs.{CL}), Computer Science - Computation and Language, {FOS}: Computer and information sciences},
}

@article{dong_automated_2024,
	title = {An Automated Multi-Phase Facilitation Agent Based on {LLM}},
	volume = {E107.D},
	doi = {10.1587/transinf.2023IHP0011},
	abstract = {This paper presents the design and implementation of an automated multi-phase facilitation agent based on {LLM} to realize inclusive facilitation and efficient use of a large language model ({LLM}) to facilitate realistic discussions. Large-scale discussion support systems have been studied and implemented very widely since they enable a lot of people to discuss remotely and within 24 hours and 7 days. Furthermore, automated facilitation artificial intelligence ({AI}) agents have been realized since they can efficiently facilitate large-scale discussions. For example, D-Agree is a large-scale discussion support system where an automated facilitation {AI} agent facilitates discussion among people. Since the current automated facilitation agent was designed following the structure of the issue-based information system ({IBIS}) and the {IBIS}-based agent has been proven that it has superior performance. However, there are several problems that need to be addressed with the {IBIS}-based agent. In this paper, we focus on the following three problems: 1) The {IBIS}-based agent was designed to only promote other participants' posts by replying to existing posts accordingly, lacking the consideration of different behaviours taken by participants with diverse characteristics, leading to a result that sometimes the discussion is not sufficient. 2) The facilitation messages generated by the {IBIS}-based agent were not natural enough, leading to consequences that the participants were not sufficiently promoted and the participants did not follow the flow to discuss a topic. 3) Since the {IBIS}-based agent is not combined with {LLM}, designing the control of {LLM} is necessary. Thus, to solve the problems mentioned above, the design of a phase-based facilitation framework is proposed in this paper. Specifically, we propose two significant designs: One is the design for a multi-phase facilitation agent created based on the framework to address problem 1); The other one is the design for the combination with {LLM} to address problem 2) and 3). Particularly, the language model called “{GPT}-3.5” is used for the combination by using corresponding {APIs} from {OPENAI}. Furthermore, we demonstrate the improvement of our facilitation agent framework by presenting the evaluations and a case study. Besides, we present the difference between our framework and {LangChain} which has generic features to utilize {LLMs}.},
	pages = {426--433},
	number = {4},
	journaltitle = {{IEICE} Transactions on Information and Systems},
	author = {Dong, Yihan and Ding, Shiyao and Ito, Takayuki},
	date = {2024},
	keywords = {automated facilitation agent, consensus-making, group discussion, large language model},
}

@article{suzuki_evolutionary_2024,
	title = {An evolutionary model of personality traits related to cooperative behavior using a large language model},
	volume = {14},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-55903-y},
	doi = {10.1038/s41598-024-55903-y},
	abstract = {Abstract
            This study aims to demonstrate that Large Language Models ({LLMs}) can empower research on the evolution of human behavior, based on evolutionary game theory, by using an evolutionary model positing that instructing {LLMs} with high-level psychological and cognitive character descriptions enables the simulation of human behavior choices in game-theoretical scenarios. As a first step towards this objective, this paper proposes an evolutionary model of personality traits related to cooperative behavior using a large language model. In the model, linguistic descriptions of personality traits related to cooperative behavior are used as genes. The deterministic strategies extracted from {LLM} that make behavioral decisions based on these personality traits are used as behavioral traits. The population is evolved according to selection based on average payoff and mutation of genes by asking {LLM} to slightly modify the parent gene toward cooperative or selfish. Through experiments and analyses, we clarify that such a model can indeed exhibit evolution of cooperative behavior based on the diverse and higher-order representation of personality traits. We also observed repeated intrusion of cooperative and selfish personality traits through changes in the expression of personality traits. The words that emerged in the evolved genes reflected the behavioral tendencies of their associated personalities in terms of semantics, thereby influencing individual behavior and, consequently, the evolutionary dynamics.},
	pages = {5989},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Suzuki, Reiji and Arita, Takaya},
	urldate = {2025-09-08},
	date = {2024-03-19},
	langid = {english},
}

@article{tarraf_experiment_2025,
	title = {An experiment in tactical wargaming with platforms enabled by artificial intelligence},
	volume = {22},
	issn = {1548-5129, 1557-380X},
	url = {https://journals.sagepub.com/doi/10.1177/15485129221097103},
	doi = {10.1177/15485129221097103},
	abstract = {In this report, researchers experimented with how postulated artificial intelligence/machine learning ({AI}/{ML}) capabilities could be incorporated into a wargame. We modified and augmented the rules and engagement statistics used in a commercial tabletop wargame to enable (1) remotely operated and fully autonomous combat vehicles and (2) vehicles with {AI}/{ML}-enabled situational awareness to show how the two types of vehicles would perform in company-level engagement between Blue ({US}) and Red (Russian) forces. The augmented rules and statistics we developed for this wargame were based in part on the {US} Army’s evolving plans for developing and fielding robotic and {AI}/{ML}-enabled weapon and other systems. However, we also portrayed combat vehicles with the capability to autonomously detect, identify, and engage targets without human intervention, which the Army does not presently envision. The rules we developed sought to realistically portray the capabilities and limitations of {AI}/{ML}-enabled systems, including their vulnerability to selected enemy countermeasures, such as jamming. Future work could improve the realism of both the gameplay and representation of {AI}/{ML}-enabled systems, thereby providing useful information to the acquisition and operational communities in the {US} Department of Defense.},
	pages = {59--76},
	number = {1},
	journaltitle = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	shortjournal = {Journal of Defense Modeling \& Simulation},
	author = {Tarraf, Danielle C and Gilmore, J Michael and Barnett, D Sean and Boston, Scott and Frelinger, David R and Gonzales, Daniel and Hou, Alexander C and Whitehead, Peter},
	urldate = {2025-09-13},
	date = {2025-01},
	langid = {english},
}

@article{lee_exploration_2021,
	title = {An exploration of the Rapid Campaign Assessment Toolset ({RCAT})},
	url = {https://cradpdf.drdc-rddc.gc.ca/PDFS/unc361/p813183_A1b.pdf},
	abstract = {This paper presents the lessons that were learned during the explorative use of the Rapid Campaign Analysis Toolset ({RCAT}) to produce a Humanitarian Aid and Disaster Relief ({HADR}) wargame based on the 2017 Defence Policy’s International Disaster Relief scenario. The lessons suggest that {RCAT} could support the examination of potential course of actions ({COA}) and capability identification to support the capability-based planning ({CBP}) process. In this purpose, however, playtests will be crucial to produce a feedback loop by which successive iterations will be amended; the composition of players, read ahead materials, and an effective first-turn tutorial will enable the play session to be fruitful by facilitating initial player learning of the wargame’s mechanics so that they engage in a multi-disciplinary examination of the wargame.},
	issue = {{DRDC}-{RDDC}-2021-D074},
	journaltitle = {Defence Research and Development Canada},
	author = {Lee, Andy},
	urldate = {2025-06-25},
	date = {2021-05},
	langid = {english},
}

@article{lee_exploration_2020,
	title = {An exploration of wargame methodologies},
	url = {https://cradpdf.drdc-rddc.gc.ca/PDFS/unc346/p811988_A1b.pdf},
	issue = {{DRDC}-{RDDC}-2020-D069},
	journaltitle = {Defence Research and Development Canada},
	author = {Lee, Andy},
	urldate = {2025-06-25},
	date = {2020-07},
	langid = {english},
}

@article{alizadeh_integrated_2016,
	title = {An integrated scenario-based robust planning approach for foresight and strategic management with application to energy industry},
	volume = {104},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162515003935},
	doi = {10.1016/j.techfore.2015.11.030},
	abstract = {Energy industries face major future challenges related to environment, security, and economics. Here we present a scenario-building framework based on the Global Business Network ({GBN}) method to help energy industries to develop more resilient conservation policies when faced with unpredictable and external uncertainties. The approach combines several foresight methods such as Delphi; Political, Economical, Social, and Technological ({PEST}) analysis, and Cross-Impact Analysis ({CIA}). In addition, a strategic foresight software program ({MICMAC}) was applied in the scenario-building phase. The proposed integrated scenario-based robust planning approach builds on the strengths of traditional scenario planning, but overcomes its weaknesses by offering a systematic process for scenario creation and easy implementation. The outcome of this approach is a limited range of core strategies. We use Iran as the case for a more detailed application of the method. Foreign investments in the energy industry, external economic sanctions, and the domestic energy consumption growth were found as the key drivers and critical uncertainties in the Iranian energy industry. Three scenarios based on these critical uncertainties and expert information were developed: Technology-driven, Stagnation, and Self-sufficiency scenario. For these scenarios, a range of robust strategies was determined. National energy efficiency and productivity increases emerged as the key factors for robustness. The main macro-level result was that economic and political drivers will be the most important factors for Iran's energy futures followed by technological and social factors.},
	pages = {162--171},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Alizadeh, Reza and Lund, Peter D. and Beynaghi, Ali and Abolghasemi, Mahdi and Maknoon, Reza},
	urldate = {2025-06-12},
	date = {2016-03-01},
	keywords = {Energy, Foresight, Iran, Robust planning, Scenario, Strategy},
}

@article{rielage_open_2017,
	title = {An Open Letter to the U.S. Navy from Red},
	volume = {143},
	url = {https://www.usni.org/magazines/proceedings/2017/june/open-letter-us-navy-red},
	series = {Proceedings},
	number = {6},
	journaltitle = {U.S. Naval Institute},
	author = {Rielage, Dale C.},
	urldate = {2025-06-26},
	date = {2017-06},
	langid = {english},
}

@article{greenberg_outline_1981,
	title = {An Outline of Wargaming},
	volume = {34},
	issn = {0028-1484},
	url = {https://www.jstor.org/stable/44642218},
	pages = {93--97},
	number = {5},
	journaltitle = {Naval War College Review},
	author = {Greenberg, Abe},
	urldate = {2025-06-25},
	date = {1981},
	note = {Publisher: U.S. Naval War College Press},
}

@article{maier_uncertain_2016,
	title = {An uncertain future, deep uncertainty, scenarios, robustness and adaptation: How do they fit together?},
	volume = {81},
	issn = {1364-8152},
	url = {https://www.sciencedirect.com/science/article/pii/S1364815216300780},
	doi = {10.1016/j.envsoft.2016.03.014},
	shorttitle = {An uncertain future, deep uncertainty, scenarios, robustness and adaptation},
	abstract = {A highly uncertain future due to changes in climate, technology and socio-economics has led to the realisation that identification of “best-guess” future conditions might no longer be appropriate. Instead, multiple plausible futures need to be considered, which requires (i) uncertainties to be described with the aid of scenarios that represent coherent future pathways based on different sets of assumptions, (ii) system performance to be represented by metrics that measure insensitivity (i.e. robustness) to changes in future conditions, and (iii) adaptive strategies to be considered alongside their more commonly used static counterparts. However, while these factors have been considered in isolation previously, there has been a lack of discussion of the way they are connected. In order to address this shortcoming, this paper presents a multidisciplinary perspective on how the above factors fit together to facilitate the development of strategies that are best suited to dealing with a deeply uncertain future.},
	pages = {154--164},
	journaltitle = {Environmental Modelling \& Software},
	shortjournal = {Environmental Modelling \& Software},
	author = {Maier, H. R. and Guillaume, J. H. A. and van Delden, H. and Riddell, G. A. and Haasnoot, M. and Kwakkel, J. H.},
	urldate = {2025-06-12},
	date = {2016-07-01},
	keywords = {Adaptability, Decision support, Deep uncertainty, Robustness, Scenarios, Uncertain future},
}

@article{vecchiato_analogical_2020,
	title = {Analogical reasoning, cognition, and the response to technological change: Lessons from mobile communication},
	volume = {49},
	issn = {0048-7333},
	url = {https://www.sciencedirect.com/science/article/pii/S004873332030038X},
	doi = {10.1016/j.respol.2020.103958},
	shorttitle = {Analogical reasoning, cognition, and the response to technological change},
	abstract = {We examine how analogical reasoning affects cognition and investment decisions in the face of technological change. Our research design is an in-depth, longitudinal case study of Nokia and its response to mobile Internet between the late 1990s and the mid-2010s. We show that Nokia diligently analyzed the competitive dynamics of other industries, such as the personal computer industry, that had already been affected by the same technological discontinuities and used the lessons from these industries to anticipate future competition outcomes in the mobile phone business. We also show that analogical reasoning helped Nokia's managers change the beliefs developed through their prior experiences. However, Nokia's managers became overconfident in their new beliefs, and this overconfidence constrained their cognitive processes of attention and interpretation, thereby increasing organizational inertia. This constraint was particularly evident in the new belief that the software operating system was the essential source of product differentiation. This belief directed key investment decisions for over a decade and contributed to the eventual decline of Nokia by leading the company to embrace Microsoft's Windows Phone rather than Google's Android.},
	pages = {103958},
	number = {5},
	journaltitle = {Research Policy},
	shortjournal = {Research Policy},
	author = {Vecchiato, Riccardo},
	urldate = {2025-06-12},
	date = {2020-06-01},
	keywords = {Analogy, Cognition, Inertia, Overconfidence, Strategy making, Technological change},
}

@misc{qiu_analytic_2020,
	title = {Analytic Deep Learning-based Surrogate Model for Operational Planning with Dynamic {TTC} Constraints},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2006.16186},
	doi = {10.48550/ARXIV.2006.16186},
	abstract = {The increased penetration of wind power introduces more operational changes of critical corridors and the traditional time-consuming transient stability constrained total transfer capability ({TTC}) operational planning is unable to meet the real-time monitoring need. This paper develops a more computationally efficient approach to address that challenge via the analytical deep learning-based surrogate model. The key idea is to resort to the deep learning for developing a computationally cheap surrogate model to replace the original time-consuming differential-algebraic constraints related to {TTC}. However, the deep learning-based surrogate model introduces implicit rules that are difficult to handle in the optimization process. To this end, we derive the Jacobian and Hessian matrices of the implicit surrogate models and finally transfer them into an analytical formulation that can be easily solved by the interior point method. Surrogate modeling and problem reformulation allow us to achieve significantly improved computational efficiency and the yielded solutions can be used for operational planning. Numerical results carried out on the modified {IEEE} 39-bus system demonstrate the effectiveness of the proposed method in dealing with com-plicated {TTC} constraints while balancing the computational efficiency and accuracy.},
	publisher = {{arXiv}},
	author = {Qiu, Gao and Liu, Youbo and Liu, Junyong and Zhao, Junbo and Wang, Lingfeng and Liu, Tingjian and Gao, Hongjun},
	urldate = {2025-09-08},
	date = {2020},
	note = {Version Number: 1},
	keywords = {{FOS}: Electrical engineering, electronic engineering, information engineering, Systems and Control (eess.{SY})},
}

@misc{tan_analyzing_2025,
	title = {Analyzing the Generalization and Reliability of Steering Vectors},
	url = {http://arxiv.org/abs/2407.12404},
	doi = {10.48550/arXiv.2407.12404},
	abstract = {Steering vectors ({SVs}) have been proposed as an effective approach to adjust language model behaviour at inference time by intervening on intermediate model activations. They have shown promise in terms of improving both capabilities and model alignment. However, the reliability and generalisation properties of this approach are unknown. In this work, we rigorously investigate these properties, and show that steering vectors have substantial limitations both in- and out-of-distribution. In-distribution, steerability is highly variable across different inputs. Depending on the concept, spurious biases can substantially contribute to how effective steering is for each input, presenting a challenge for the widespread use of steering vectors. Out-of-distribution, while steering vectors often generalise well, for several concepts they are brittle to reasonable changes in the prompt, resulting in them failing to generalise well. Overall, our findings show that while steering can work well in the right circumstances, there remain technical difficulties of applying steering vectors to guide models' behaviour at scale. Our code is available at https://github.com/dtch1997/steering-bench},
	number = {{arXiv}:2407.12404},
	publisher = {{arXiv}},
	author = {Tan, Daniel and Chanin, David and Lynch, Aengus and Kanoulas, Dimitrios and Paige, Brooks and Garriga-Alonso, Adria and Kirk, Robert},
	urldate = {2025-09-13},
	date = {2025-05-04},
	eprinttype = {arxiv},
	eprint = {2407.12404 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{cheng_animegamer_2025,
	title = {{AnimeGamer}: Infinite Anime Life Simulation with Next Game State Prediction},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2504.01014},
	doi = {10.48550/ARXIV.2504.01014},
	shorttitle = {{AnimeGamer}},
	abstract = {Recent advancements in image and video synthesis have opened up new promise in generative games. One particularly intriguing application is transforming characters from anime films into interactive, playable entities. This allows players to immerse themselves in the dynamic anime world as their favorite characters for life simulation through language instructions. Such games are defined as infinite game since they eliminate predetermined boundaries and fixed gameplay rules, where players can interact with the game world through open-ended language and experience ever-evolving storylines and environments. Recently, a pioneering approach for infinite anime life simulation employs large language models ({LLMs}) to translate multi-turn text dialogues into language instructions for image generation. However, it neglects historical visual context, leading to inconsistent gameplay. Furthermore, it only generates static images, failing to incorporate the dynamics necessary for an engaging gaming experience. In this work, we propose {AnimeGamer}, which is built upon Multimodal Large Language Models ({MLLMs}) to generate each game state, including dynamic animation shots that depict character movements and updates to character states, as illustrated in Figure 1. We introduce novel action-aware multimodal representations to represent animation shots, which can be decoded into high-quality video clips using a video diffusion model. By taking historical animation shot representations as context and predicting subsequent representations, {AnimeGamer} can generate games with contextual consistency and satisfactory dynamics. Extensive evaluations using both automated metrics and human evaluations demonstrate that {AnimeGamer} outperforms existing methods in various aspects of the gaming experience. Codes and checkpoints are available at https://github.com/{TencentARC}/{AnimeGamer}.},
	publisher = {{arXiv}},
	author = {Cheng, Junhao and Ge, Yuying and Ge, Yixiao and Liao, Jing and Shan, Ying},
	urldate = {2025-09-08},
	date = {2025},
	note = {Version Number: 2},
	keywords = {Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences},
}

@article{vervoort_anticipating_2018,
	title = {Anticipating climate futures in a 1.5   °C era: the link between foresight and governance},
	volume = {31},
	issn = {1877-3435},
	url = {https://www.sciencedirect.com/science/article/pii/S1877343517301501},
	doi = {10.1016/j.cosust.2018.01.004},
	series = {Sustainability governance and transformation 2018},
	shorttitle = {Anticipating climate futures in a 1.5   °C era},
	abstract = {The Paris Agreement's aspirational 1.5 degree temperature target has given further impetus to efforts to imagine (and seek to govern) transformative and uncertain climate futures. This brings to the fore multiple challenges in the search for anticipatory governance and the role herein for climate foresight. Foresight entails processes to envision challenging futures and question limiting assumptions about what futures are possible, but these processes also impact upon present-day politics. While foresight-related activities are proliferating in sustainability research and planning, critical social science scrutiny of such processes remains minimal. Two key gaps in understanding are: (a) the link between foresight, planning and policy change; and (b) the very prospects of relying on foresight in the present to steer largely unknowable futures. In addressing these gaps, we review the field of climate foresight research here, situating it within a broader interdisciplinary body of literature relating to anticipation and anticipatory governance. In doing so, we identify a conceptual lens through which to analyze the political implications of foresight processes, and apply it to the case of two ongoing foresight initiatives. We conclude with noting the urgent need for further research on the role of foresight within anticipatory climate governance in a post-Paris era.},
	pages = {104--111},
	journaltitle = {Current Opinion in Environmental Sustainability},
	shortjournal = {Current Opinion in Environmental Sustainability},
	author = {Vervoort, Joost and Gupta, Aarti},
	urldate = {2025-06-12},
	date = {2018-04-01},
}

@misc{cloud_anticipatory_2022,
	title = {Anticipatory Fictitious Play},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2212.09941},
	doi = {10.48550/ARXIV.2212.09941},
	abstract = {Fictitious play is an algorithm for computing Nash equilibria of matrix games. Recently, machine learning variants of fictitious play have been successfully applied to complicated real-world games. This paper presents a simple modification of fictitious play which is a strict improvement over the original: it has the same theoretical worst-case convergence rate, is equally applicable in a machine learning context, and enjoys superior empirical performance. We conduct an extensive comparison of our algorithm with fictitious play, proving an optimal convergence rate for certain classes of games, demonstrating superior performance numerically across a variety of games, and concluding with experiments that extend these algorithms to the setting of deep multiagent reinforcement learning.},
	publisher = {{arXiv}},
	author = {Cloud, Alex and Wang, Albert and Kerr, Wesley},
	urldate = {2025-09-08},
	date = {2022},
	note = {Version Number: 1},
	keywords = {Computer Science and Game Theory (cs.{GT}), {FOS}: Computer and information sciences, Multiagent Systems (cs.{MA})},
}

@article{sabaghi_application_2015,
	title = {Application of {DOE}-{TOPSIS} Technique in Decision-Making Problems},
	volume = {48},
	issn = {2405-8963},
	url = {https://www.sciencedirect.com/science/article/pii/S2405896315004152},
	doi = {10.1016/j.ifacol.2015.06.176},
	series = {15th {IFAC} Symposium {onInformation} Control Problems {inManufacturing}},
	abstract = {In real life, decision-making problems are not fixed, and by the time some modifications to the initial problem may be required. {TOPSIS} technique has been commonly used to solve decision-making problems. This technique is based on the comparison between all the alternatives included in the problem. Thus, if one alternative is removed or added, depending on the situation, the whole process for {TOPSIS} should be redone, which is laborious and time-consuming. The integration of design of experiment ({DOE}) and {TOPSIS} allows easily determine the score for each alternative independently, without any comparison. This gives more degree of freedom to the users, even though the accuracy is compromised. In this work both techniques were applied to a simple case-study. Results showed that using a polynomial regression model with 84.53\% reliability, the rankings from {DOE}-{TOPSIS} and normal {TOPSIS} are the same. This proposed technique can be highly useful in large scale decision-making problems as often found in aeronautic and automotive industries.},
	pages = {773--777},
	number = {3},
	journaltitle = {{IFAC}-{PapersOnLine}},
	shortjournal = {{IFAC}-{PapersOnLine}},
	author = {Sabaghi, Mahdi and Mascle, Christian and Baptiste, Pierre},
	urldate = {2025-06-12},
	date = {2015-01-01},
	keywords = {Design of experiment, Hybrid {DOE}-{TOPSIS}, Multi-criteria decision making, {TOPSIS}},
}

@article{rinaudo_applying_2024,
	title = {Applying Deep Reinforcement Learning to Train {AI} Agents in a Wargaming Framework},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10500249/},
	doi = {10.1109/SoutheastCon52093.2024.10500249},
	abstract = {The United States Navy's mission planning process consists of six steps. The third step, referred to as the course of action ({COA}) analysis (wargaming) process, encompasses the evaluation of initial actions taken, the corresponding reactions by opponents, and the associated counteractions. This entire process supports developing potential mission {COAs} while also informing decision makers of potential outcomes in support of planning and preparing for operations. This wargaming process may occur using table-top exercises with subject-matter experts that determine actions taken. However, continued improvements with deep reinforcement learning ({DRL}), a sub-field of machine learning, provide an opportunity to leverage the use of artificial intelligence ({AI}) agents within the wargaming process. The {AI} agents must perform credibly to represent a believable behavior of either the red team or blue team. Developing credible behavior requires tailoring agent reward functions, analyzing impacts of different training algorithms and parameter values, and understanding and evaluating the resulting behavior. This work also demonstrates agent behavior using a browser-based gameplay interface accessible to decision makers. This paper provides an overview of research efforts to train and analyze {AI} agent performance using {DRL} within a prototype government owned wargaming framework, discusses the capabilities and utility of the browser-based interface, and explores challenges and opportunities for future research.},
	pages = {1131--1136},
	journaltitle = {{SoutheastCon} 2024},
	author = {Rinaudo, Christina H. and Leonard, William B. and Hopson, Jaylen E. and Coumbe, Theresa R. and Pettitt, James A. and Darken, Christian},
	urldate = {2025-09-13},
	date = {2024-03-15},
	note = {Conference Name: {SoutheastCon} 2024
{ISBN}: 9798350317107
Place: Atlanta, {GA}, {USA}
Publisher: {IEEE}},
}

@article{sills_applying_2019,
	title = {Applying wargames to real-world policies—Response},
	volume = {363},
	rights = {http://www.sciencemag.org/about/science-licenses-journal-article-reuse},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.aaw7260},
	doi = {10.1126/science.aaw7260},
	pages = {1406--1407},
	number = {6434},
	journaltitle = {Science},
	shortjournal = {Science},
	author = {Reddie, Andrew W. and Goldblum, Bethany L. and Reinhardt, Jason and Lakkaraju, Kiran and Epifanovskaya, Laura and Nacht, Michael},
	editor = {Sills, Jennifer},
	urldate = {2025-09-12},
	date = {2019-03-29},
	langid = {english},
}

@misc{kwon_are_2024,
	title = {Are {LLMs} Effective Negotiators? Systematic Evaluation of the Multifaceted Capabilities of {LLMs} in Negotiation Dialogues},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2402.13550},
	doi = {10.48550/ARXIV.2402.13550},
	shorttitle = {Are {LLMs} Effective Negotiators?},
	abstract = {A successful negotiation requires a range of capabilities, including comprehension of the conversation context, Theory-of-Mind ({ToM}) skills to infer the partner's motives, strategic reasoning, and effective communication, making it challenging for automated systems. Despite the remarkable performance of {LLMs} in various {NLP} tasks, there is no systematic evaluation of their capabilities in negotiation. Such an evaluation is critical for advancing {AI} negotiation agents and negotiation research, ranging from designing dialogue systems to providing pedagogical feedback and scaling up data collection practices. This work aims to systematically analyze the multifaceted capabilities of {LLMs} across diverse dialogue scenarios throughout the stages of a typical negotiation interaction. Our analysis highlights {GPT}-4's superior performance in many tasks while identifying specific challenges, such as making subjective assessments and generating contextually appropriate, strategically advantageous responses.},
	publisher = {{arXiv}},
	author = {Kwon, Deuksin and Weiss, Emily and Kulshrestha, Tara and Chawla, Kushal and Lucas, Gale M. and Gratch, Jonathan},
	urldate = {2025-09-08},
	date = {2024},
	note = {Version Number: 2},
	keywords = {Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), {FOS}: Computer and information sciences},
}

@misc{ahmed_ares_2022,
	title = {Ares: A System-Oriented Wargame Framework for Adversarial {ML}},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2210.12952},
	doi = {10.48550/ARXIV.2210.12952},
	shorttitle = {Ares},
	abstract = {Since the discovery of adversarial attacks against machine learning models nearly a decade ago, research on adversarial machine learning has rapidly evolved into an eternal war between defenders, who seek to increase the robustness of {ML} models against adversarial attacks, and adversaries, who seek to develop better attacks capable of weakening or defeating these defenses. This domain, however, has found little buy-in from {ML} practitioners, who are neither overtly concerned about these attacks affecting their systems in the real world nor are willing to trade off the accuracy of their models in pursuit of robustness against these attacks. In this paper, we motivate the design and implementation of Ares, an evaluation framework for adversarial {ML} that allows researchers to explore attacks and defenses in a realistic wargame-like environment. Ares frames the conflict between the attacker and defender as two agents in a reinforcement learning environment with opposing objectives. This allows the introduction of system-level evaluation metrics such as time to failure and evaluation of complex strategies such as moving target defenses. We provide the results of our initial exploration involving a white-box attacker against an adversarially trained defender.},
	publisher = {{arXiv}},
	author = {Ahmed, Farhan and Vaishnavi, Pratik and Eykholt, Kevin and Rahmati, Amir},
	urldate = {2025-09-08},
	date = {2022},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.{AI}), Cryptography and Security (cs.{CR}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
}

@article{rinaudo_artificial_2024,
	title = {Artificial intelligence ({AI})–enabled wargaming agent training},
	url = {https://hdl.handle.net/11681/48419},
	abstract = {Fiscal Year 2021 ({FY}21) work from the Engineer Research and Development Center Institute for Systems Engineering Research lever-aged deep reinforcement learning to develop intelligent systems (red team agents) capable of exhibiting credible behavior within a military course of action wargaming maritime framework infrastructure. Building from the {FY}21 research, this research effort sought to explore options to improve upon the wargaming framework infrastructure and to investigate opportunities to improve artificial intelligence ({AI}) agent behavior. Wargaming framework infrastructure enhancements included updates related to supporting agent training, leveraging high-performance computing resources, and developing infrastructure to support {AI} versus {AI} agent training and gameplay. After evaluating agent training across different algorithm options, Deep Q-Network–trained agents performed better compared to those trained with Advantage Actor Critic or Proximal Policy Optimization algorithms. Experimentation in varying scenarios revealed acceptable performance from agents trained in the original baseline scenario. By training a blue agent against a previously trained red agent, researchers successfully demonstrated the {AI} versus {AI} training and gameplay capability. Observing results from agent gameplay revealed the emergence of behavior indicative of two principles of war, which were economy of force and mass.},
	author = {Rinaudo, Christina H. and Leonard, William B. and Morey, Christopher and Hopson, Jaylen E. and Hilborn, Robert and Coumbe, Theresa R. and Laboratory (U.S.), Information Technology},
	urldate = {2025-09-13},
	date = {2024-04},
	langid = {american},
	note = {Publisher: Engineer Research and Development Center (U.S.)},
}

@misc{fan_artificial_2025,
	title = {Artificial Intelligence and Civil Discourse: How {LLMs} Moderate Climate Change Conversations},
	rights = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
	url = {https://arxiv.org/abs/2506.12077},
	doi = {10.48550/ARXIV.2506.12077},
	shorttitle = {Artificial Intelligence and Civil Discourse},
	abstract = {As large language models ({LLMs}) become increasingly integrated into online platforms and digital communication spaces, their potential to influence public discourse - particularly in contentious areas like climate change - requires systematic investigation. This study examines how {LLMs} naturally moderate climate change conversations through their distinct communicative behaviors. We conduct a comparative analysis of conversations between {LLMs} and human users on social media platforms, using five advanced models: three open-source {LLMs} (Gemma, Llama 3, and Llama 3.3) and two commercial systems ({GPT}-4o by {OpenAI} and Claude 3.5 by Anthropic). Through sentiment analysis, we assess the emotional characteristics of responses from both {LLMs} and humans. The results reveal two key mechanisms through which {LLMs} moderate discourse: first, {LLMs} consistently display emotional neutrality, showing far less polarized sentiment than human users. Second, {LLMs} maintain lower emotional intensity across contexts, creating a stabilizing effect in conversations. These findings suggest that {LLMs} possess inherent moderating capacities that could improve the quality of public discourse on controversial topics. This research enhances our understanding of how {AI} might support more civil and constructive climate change discussions and informs the design of {AI}-assisted communication tools.},
	publisher = {{arXiv}},
	author = {Fan, Wenlu and Xu, Wentao},
	urldate = {2025-09-08},
	date = {2025},
	note = {Version Number: 1},
	keywords = {Computation and Language (cs.{CL}), Computers and Society (cs.{CY}), {FOS}: Computer and information sciences},
}

@book{roumate_artificial_2021,
	title = {Artificial Intelligence and Digital Diplomacy: Challenges and Opportunities},
	isbn = {978-3-030-68646-8},
	url = {https://play.google.com/store/books/details?id=mwAjzgEACAAJ},
	abstract = {This volume discusses digital diplomacy and artificial intelligence within
the context of global governance and international security. Rapid
digitalization has changed the way international actors interact, offering
new opportunities for international and bilateral cooperation and
reinforcing the role of the emergent actors within global governance. New
phenomena linked to digitalization and artificial intelligence are
emerging and this volume brings a multidisciplinary, mixed-methods
approach to studying them. Written by globally recognized experts, each
chapter presents a case study covering an emerging topic such as:
international regulation of the web and digital diplomacy, the interplay
of artificial intelligence and cyber diplomacy, social media and
artificial intelligence as tools for digital diplomacy, the malicious use
of artificial intelligence, cyber security, and data sovereignty.
Incorporating both theory and practice, quantitative and qualitative
analysis, this volume will be of interest to graduate students and
researchers in international relations, diplomacy, security studies, and
artificial intelligence, as well as diplomats and policymakers looking to
understand the implications of digitalization and artificial intelligence
in their fields.},
	pagetotal = {241},
	publisher = {Springer International Publishing},
	author = {Roumate, Fatima},
	date = {2021-09-01},
	doi = {10.1007/978-3-030-68647-5},
	keywords = {{noPdf}},
}

@article{sayler_artificial_2019,
	title = {Artificial intelligence and national security},
	volume = {45178},
	url = {https://apps.dtic.mil/sti/pdfs/AD1170086.pdf},
	journaltitle = {Congressional Research Service},
	author = {Sayler, Kelley M},
	date = {2019},
}

@misc{csaszar_artificial_2024,
	title = {Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2408.08811},
	doi = {10.48550/ARXIV.2408.08811},
	shorttitle = {Artificial Intelligence and Strategic Decision-Making},
	abstract = {This paper explores how artificial intelligence ({AI}) may impact the strategic decision-making ({SDM}) process in firms. We illustrate how {AI} could augment existing {SDM} tools and provide empirical evidence from a leading accelerator program and a startup competition that current Large Language Models ({LLMs}) can generate and evaluate strategies at a level comparable to entrepreneurs and investors. We then examine implications for key cognitive processes underlying {SDM} -- search, representation, and aggregation. Our analysis suggests {AI} has the potential to enhance the speed, quality, and scale of strategic analysis, while also enabling new approaches like virtual strategy simulations. However, the ultimate impact on firm performance will depend on competitive dynamics as {AI} capabilities progress. We propose a framework connecting {AI} use in {SDM} to firm outcomes and discuss how {AI} may reshape sources of competitive advantage. We conclude by considering how {AI} could both support and challenge core tenets of the theory-based view of strategy. Overall, our work maps out an emerging research frontier at the intersection of {AI} and strategy.},
	publisher = {{arXiv}},
	author = {Csaszar, Felipe A. and Ketkar, Harsh and Kim, Hyunjin},
	urldate = {2025-09-08},
	date = {2024},
	note = {Version Number: 1},
	keywords = {Computers and Society (cs.{CY}), {FOS}: Computer and information sciences, {FOS}: Economics and business, General Economics (econ.{GN}), K.4},
}

@article{wong_artificial_2025,
	title = {Artificial intelligence and wargaming},
	volume = {22},
	issn = {1548-5129, 1557-380X},
	url = {https://journals.sagepub.com/doi/10.1177/15485129241310254},
	doi = {10.1177/15485129241310254},
	abstract = {The Defense Department has shown interest in artificial intelligence ({AI}) for decades. 1 This interest appears to have accelerated over the},
	pages = {3--4},
	number = {1},
	journaltitle = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	shortjournal = {Journal of Defense Modeling \& Simulation},
	author = {Wong, Yuna Huh and Ryseff, James and Riggs, Nick},
	urldate = {2025-09-13},
	date = {2025-01},
	langid = {english},
}

@article{davis_artificial_2025,
	title = {Artificial intelligence for wargaming and modeling},
	volume = {22},
	issn = {1548-5129, 1557-380X},
	url = {https://journals.sagepub.com/doi/10.1177/15485129211073126},
	doi = {10.1177/15485129211073126},
	abstract = {In this paper, we discuss how artificial intelligence ({AI}) could be used in political-military modeling, simulation, and wargaming of conflicts with nations having weapons of mass destruction and other high-end capabilities involving space, cyberspace, and long-range precision weapons. {AI} should help participants in wargames, and agents in simulations, to understand possible perspectives, perceptions, and calculations of adversaries who are operating with uncertainties and misimpressions. The content of {AI} should recognize the risks of escalation leading to catastrophe with no winner but also the possibility of outcomes with meaningful winners and losers. We discuss implications for the design and development of families of models, simulations, and wargames using several types of {AI} functionality. We also discuss decision aids for wargaming, with and without {AI}, informed by theory and exploratory work using simulation, history, and earlier wargaming.},
	pages = {25--40},
	number = {1},
	journaltitle = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	shortjournal = {Journal of Defense Modeling \& Simulation},
	author = {Davis, Paul K and Bracken, Paul},
	urldate = {2025-09-08},
	date = {2025-01},
	langid = {english},
}

@misc{dai_artificial_2024,
	title = {Artificial Leviathan: Exploring Social Evolution of {LLM} Agents Through the Lens of Hobbesian Social Contract Theory},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2406.14373},
	doi = {10.48550/ARXIV.2406.14373},
	shorttitle = {Artificial Leviathan},
	abstract = {The emergence of Large Language Models ({LLMs}) and advancements in Artificial Intelligence ({AI}) offer an opportunity for computational social science research at scale. Building upon prior explorations of {LLM} agent design, our work introduces a simulated agent society where complex social relationships dynamically form and evolve over time. Agents are imbued with psychological drives and placed in a sandbox survival environment. We conduct an evaluation of the agent society through the lens of Thomas Hobbes's seminal Social Contract Theory ({SCT}). We analyze whether, as the theory postulates, agents seek to escape a brutish "state of nature" by surrendering rights to an absolute sovereign in exchange for order and security. Our experiments unveil an alignment: Initially, agents engage in unrestrained conflict, mirroring Hobbes's depiction of the state of nature. However, as the simulation progresses, social contracts emerge, leading to the authorization of an absolute sovereign and the establishment of a peaceful commonwealth founded on mutual cooperation. This congruence between our {LLM} agent society's evolutionary trajectory and Hobbes's theoretical account indicates {LLMs}' capability to model intricate social dynamics and potentially replicate forces that shape human societies. By enabling such insights into group behavior and emergent societal phenomena, {LLM}-driven multi-agent simulations, while unable to simulate all the nuances of human behavior, may hold potential for advancing our understanding of social structures, group dynamics, and complex human systems.},
	publisher = {{arXiv}},
	author = {Dai, Gordon and Zhang, Weijia and Li, Jinhan and Yang, Siqi and lbe, Chidera Onochie and Rao, Srihas and Caetano, Arthur and Sra, Misha},
	urldate = {2025-09-08},
	date = {2024},
	note = {Version Number: 2},
	keywords = {Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), Computers and Society (cs.{CY}), {FOS}: Computer and information sciences, Human-Computer Interaction (cs.{HC}), Multiagent Systems (cs.{MA})},
}

@misc{alrdahi_aspect-based_2024,
	title = {Aspect-based Sentiment Evaluation of Chess Moves ({ASSESS}): an {NLP}-based Method for Evaluating Chess Strategies from Textbooks},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2405.06499},
	doi = {10.48550/ARXIV.2405.06499},
	shorttitle = {Aspect-based Sentiment Evaluation of Chess Moves ({ASSESS})},
	abstract = {The chess domain is well-suited for creating an artificial intelligence ({AI}) system that mimics real-world challenges, including decision-making. Throughout the years, minimal attention has been paid to investigating insights derived from unstructured chess data sources. In this study, we examine the complicated relationships between multiple referenced moves in a chess-teaching textbook, and propose a novel method designed to encapsulate chess knowledge derived from move-action phrases. This study investigates the feasibility of using a modified sentiment analysis method as a means for evaluating chess moves based on text. Our proposed Aspect-Based Sentiment Analysis ({ABSA}) method represents an advancement in evaluating the sentiment associated with referenced chess moves. By extracting insights from move-action phrases, our approach aims to provide a more fine-grained and contextually aware `chess move'-based sentiment classification. Through empirical experiments and analysis, we evaluate the performance of our fine-tuned {ABSA} model, presenting results that confirm the efficiency of our approach in advancing aspect-based sentiment classification within the chess domain. This research contributes to the area of game-playing by machines and shows the practical applicability of leveraging {NLP} techniques to understand the context of strategic games.},
	publisher = {{arXiv}},
	author = {Alrdahi, Haifa and Batista-Navarro, Riza},
	urldate = {2025-09-08},
	date = {2024},
	note = {Version Number: 1},
	keywords = {Computation and Language (cs.{CL}), {FOS}: Computer and information sciences},
}

@misc{ying_assessing_2025,
	title = {Assessing adaptive world models in machines with novel games},
	url = {http://arxiv.org/abs/2507.12821},
	doi = {10.48550/arXiv.2507.12821},
	abstract = {Human intelligence exhibits a remarkable capacity for rapid adaptation and effective problem-solving in novel and unfamiliar contexts. We argue that this profound adaptability is fundamentally linked to the efficient construction and refinement of internal representations of the environment, commonly referred to as world models, and we refer to this adaptation mechanism as world model induction. However, current understanding and evaluation of world models in artificial intelligence ({AI}) remains narrow, often focusing on static representations learned from training on a massive corpora of data, instead of the efficiency and efficacy of models in learning these representations through interaction and exploration within a novel environment. In this Perspective, we provide a view of world model induction drawing on decades of research in cognitive science on how humans learn and adapt so efficiently; we then call for a new evaluation framework for assessing adaptive world models in {AI}. Concretely, we propose a new benchmarking paradigm based on suites of carefully designed games with genuine, deep and continually refreshing novelty in the underlying game structures -- we refer to this kind of games as novel games. We detail key desiderata for constructing these games and propose appropriate metrics to explicitly challenge and evaluate the agent's ability for rapid world model induction. We hope that this new evaluation framework will inspire future evaluation efforts on world models in {AI} and provide a crucial step towards developing {AI} systems capable of the human-like rapid adaptation and robust generalization -- a critical component of artificial general intelligence.},
	number = {{arXiv}:2507.12821},
	publisher = {{arXiv}},
	author = {Ying, Lance and Collins, Katherine M. and Sharma, Prafull and Colas, Cedric and Zhao, Kaiya Ivy and Weller, Adrian and Tavares, Zenna and Isola, Phillip and Gershman, Samuel J. and Andreas, Jacob D. and Griffiths, Thomas L. and Chollet, Francois and Allen, Kelsey R. and Tenenbaum, Joshua B.},
	urldate = {2025-07-21},
	date = {2025-07-17},
	eprinttype = {arxiv},
	eprint = {2507.12821 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{kuehn_assessment_2021,
	title = {{ASSESSMENT} {STRATEGIES} {FOR} {EDUCATIONAL} {WARGAMES}},
	volume = {12},
	issn = {21644209, 21644217},
	url = {https://www.usmcu.edu/Outreach/Marine-Corps-University-Press/MCU-Journal/JAMS-Vol-12-No-2/},
	doi = {10.21140/mcuj.20211202005},
	abstract = {Purposeful integration of assessment within educational wargame design is increasingly essential as military education expands those activities within its curriculum. This multimethod case study examines key challenges and strategies for assessment within educational wargaming practice. Drawing insights from faculty interviews, academic documents, and faculty meeting observations, the study identifies six key assessment challenges: gamesmanship, lack of control, multiple faculty roles, receptiveness to feedback, evaluation of individuals in teams, and fairness of evaluation. It then discusses how experienced faculty mitigate these challenges throughout the assessment design process from identifying outcomes to ensuring the quality of evaluation.},
	pages = {139--153},
	number = {2},
	journaltitle = {Journal of Advanced Military Studies},
	shortjournal = {{JAMS}},
	author = {Kuehn, Kate},
	urldate = {2025-06-25},
	date = {2021-09-30},
	langid = {english},
}

@article{hua_assistive_2024,
	title = {Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2402.01737},
	doi = {10.48550/ARXIV.2402.01737},
	abstract = {We develop assistive agents based on Large Language Models ({LLMs}) that aid interlocutors in business negotiations. Specifically, we simulate business negotiations by letting two {LLM}-based agents engage in role play. A third {LLM} acts as a remediator agent to rewrite utterances violating norms for improving negotiation outcomes. We introduce a simple tuning-free and label-free In-Context Learning ({ICL}) method to identify high-quality {ICL} exemplars for the remediator, where we propose a novel select criteria, called value impact, to measure the quality of the negotiation outcomes. We provide rich empirical evidence to demonstrate its effectiveness in negotiations across three different negotiation topics. We have released our source code and the generated dataset at: https://github.com/tk1363704/{SADAS}.},
	author = {Hua, Yuncheng and Qu, Lizhen and Haffari, Gholamreza},
	urldate = {2025-09-08},
	date = {2024},
	note = {Publisher: {arXiv}
Version Number: 3},
	keywords = {Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), {FOS}: Computer and information sciences, I.2.7},
}

@misc{dubey_auctions_2024,
	title = {Auctions with {LLM} Summaries},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2404.08126},
	doi = {10.48550/ARXIV.2404.08126},
	abstract = {We study an auction setting in which bidders bid for placement of their content within a summary generated by a large language model ({LLM}), e.g., an ad auction in which the display is a summary paragraph of multiple ads. This generalizes the classic ad settings such as position auctions to an {LLM} generated setting, which allows us to handle general display formats. We propose a novel factorized framework in which an auction module and an {LLM} module work together via a prediction model to provide welfare maximizing summary outputs in an incentive compatible manner. We provide a theoretical analysis of this framework and synthetic experiments to demonstrate the feasibility and validity of the system together with welfare comparisons.},
	publisher = {{arXiv}},
	author = {Dubey, Kumar Avinava and Feng, Zhe and Kidambi, Rahul and Mehta, Aranyak and Wang, Di},
	urldate = {2025-09-08},
	date = {2024},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.{AI}), Computer Science and Game Theory (cs.{GT}), {FOS}: Computer and information sciences},
}

@misc{teodorescu_automatic_2022,
	title = {Automatic Exploration of Textual Environments with Language-Conditioned Autotelic Agents},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2207.04118},
	doi = {10.48550/ARXIV.2207.04118},
	abstract = {In this extended abstract we discuss the opportunities and challenges of studying intrinsically-motivated agents for exploration in textual environments. We argue that there is important synergy between text environments and autonomous agents. We identify key properties of text worlds that make them suitable for exploration by autonmous agents, namely, depth, breadth, progress niches and the ease of use of language goals; we identify drivers of exploration for such agents that are implementable in text worlds. We discuss the opportunities of using autonomous agents to make progress on text environment benchmarks. Finally we list some specific challenges that need to be overcome in this area.},
	publisher = {{arXiv}},
	author = {Teodorescu, Laetitia and Yuan, Eric and Côté, Marc-Alexandre and Oudeyer, Pierre-Yves},
	urldate = {2025-09-08},
	date = {2022},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.{AI}), {FOS}: Computer and information sciences},
}

@article{johnson_automating_2023,
	title = {Automating the {OODA} loop in the age of intelligent machines: reaffirming the role of humans in command-and-control decision-making in the digital age},
	volume = {23},
	issn = {1470-2436, 1743-9698},
	url = {https://www.tandfonline.com/doi/full/10.1080/14702436.2022.2102486},
	doi = {10.1080/14702436.2022.2102486},
	shorttitle = {Automating the {OODA} loop in the age of intelligent machines},
	pages = {43--67},
	number = {1},
	journaltitle = {Defence Studies},
	shortjournal = {Defence Studies},
	author = {Johnson, James},
	urldate = {2025-09-08},
	date = {2023-01-02},
	langid = {english},
}

@misc{wang_avalons_2023,
	title = {Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2310.01320},
	doi = {10.48550/ARXIV.2310.01320},
	shorttitle = {Avalon's Game of Thoughts},
	abstract = {Recent breakthroughs in large language models ({LLMs}) have brought remarkable success in the field of {LLM}-as-Agent. Nevertheless, a prevalent assumption is that the information processed by {LLMs} is consistently honest, neglecting the pervasive deceptive or misleading information in human society and {AI}-generated content. This oversight makes {LLMs} susceptible to malicious manipulations, potentially resulting in detrimental outcomes. This study utilizes the intricate Avalon game as a testbed to explore {LLMs}' potential in deceptive environments. Avalon, full of misinformation and requiring sophisticated logic, manifests as a "Game-of-Thoughts". Inspired by the efficacy of humans' recursive thinking and perspective-taking in the Avalon game, we introduce a novel framework, Recursive Contemplation ({ReCon}), to enhance {LLMs}' ability to identify and counteract deceptive information. {ReCon} combines formulation and refinement contemplation processes; formulation contemplation produces initial thoughts and speech, while refinement contemplation further polishes them. Additionally, we incorporate first-order and second-order perspective transitions into these processes respectively. Specifically, the first-order allows an {LLM} agent to infer others' mental states, and the second-order involves understanding how others perceive the agent's mental state. After integrating {ReCon} with different {LLMs}, extensive experiment results from the Avalon game indicate its efficacy in aiding {LLMs} to discern and maneuver around deceptive information without extra fine-tuning and data. Finally, we offer a possible explanation for the efficacy of {ReCon} and explore the current limitations of {LLMs} in terms of safety, reasoning, speaking style, and format, potentially furnishing insights for subsequent research.},
	publisher = {{arXiv}},
	author = {Wang, Shenzhi and Liu, Chang and Zheng, Zilong and Qi, Siyuan and Chen, Shuo and Yang, Qisen and Zhao, Andrew and Wang, Chaofei and Song, Shiji and Huang, Gao},
	urldate = {2025-09-08},
	date = {2023},
	note = {Version Number: 3},
	keywords = {Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), Computers and Society (cs.{CY}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG}), Multiagent Systems (cs.{MA})},
}

@misc{light_avalonbench_2023,
	title = {{AvalonBench}: Evaluating {LLMs} Playing the Game of Avalon},
	url = {http://arxiv.org/abs/2310.05036},
	doi = {10.48550/arXiv.2310.05036},
	shorttitle = {{AvalonBench}},
	abstract = {In this paper, we explore the potential of Large Language Models ({LLMs}) Agents in playing the strategic social deduction game, Resistance Avalon. Players in Avalon are challenged not only to make informed decisions based on dynamically evolving game phases, but also to engage in discussions where they must deceive, deduce, and negotiate with other players. These characteristics make Avalon a compelling test-bed to study the decision-making and language-processing capabilities of {LLM} Agents. To facilitate research in this line, we introduce {AvalonBench} - a comprehensive game environment tailored for evaluating multi-agent {LLM} Agents. This benchmark incorporates: (1) a game environment for Avalon, (2) rule-based bots as baseline opponents, and (3) {ReAct}-style {LLM} agents with tailored prompts for each role. Notably, our evaluations based on {AvalonBench} highlight a clear capability gap. For instance, models like {ChatGPT} playing good-role got a win rate of 22.2\% against rule-based bots playing evil, while good-role bot achieves 38.2\% win rate in the same setting. We envision {AvalonBench} could be a good test-bed for developing more advanced {LLMs} (with self-playing) and agent frameworks that can effectively model the layered complexities of such game environments.},
	number = {{arXiv}:2310.05036},
	publisher = {{arXiv}},
	author = {Light, Jonathan and Cai, Min and Shen, Sheng and Hu, Ziniu},
	urldate = {2025-09-12},
	date = {2023-11-08},
	eprinttype = {arxiv},
	eprint = {2310.05036 [cs]},
	keywords = {Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), Computer Science - Artificial Intelligence, Computer Science - Computation and Language, {FOS}: Computer and information sciences},
}

@misc{paglieri_balrog_2024,
	title = {{BALROG}: Benchmarking Agentic {LLM} and {VLM} Reasoning On Games},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2411.13543},
	doi = {10.48550/ARXIV.2411.13543},
	shorttitle = {{BALROG}},
	abstract = {Large Language Models ({LLMs}) and Vision Language Models ({VLMs}) possess extensive knowledge and exhibit promising reasoning abilities, however, they still struggle to perform well in complex, dynamic environments. Real-world tasks require handling intricate interactions, advanced spatial reasoning, long-term planning, and continuous exploration of new strategies-areas in which we lack effective methodologies for comprehensively evaluating these capabilities. To address this gap, we introduce {BALROG}, a novel benchmark designed to assess the agentic capabilities of {LLMs} and {VLMs} through a diverse set of challenging games. Our benchmark incorporates a range of existing reinforcement learning environments with varying levels of difficulty, including tasks that are solvable by non-expert humans in seconds to extremely challenging ones that may take years to master (e.g., the {NetHack} Learning Environment). We devise fine-grained metrics to measure performance and conduct an extensive evaluation of several popular open-source and closed-source {LLMs} and {VLMs}. Our findings indicate that while current models achieve partial success in the easier games, they struggle significantly with more challenging tasks. Notably, we observe severe deficiencies in vision-based decision-making, as several models perform worse when visual representations of the environments are provided. We release {BALROG} as an open and user-friendly benchmark to facilitate future research and development in the agentic community. Code and Leaderboard at balrogai.com.},
	publisher = {{arXiv}},
	author = {Paglieri, Davide and Cupiał, Bartłomiej and Coward, Samuel and Piterbarg, Ulyana and Wolczyk, Maciej and Khan, Akbir and Pignatelli, Eduardo and Kuciński, Łukasz and Pinto, Lerrel and Fergus, Rob and Foerster, Jakob Nicolaus and Parker-Holder, Jack and Rocktäschel, Tim},
	urldate = {2025-09-08},
	date = {2024},
	note = {Version Number: 2},
	keywords = {Artificial Intelligence (cs.{AI}), {FOS}: Computer and information sciences},
}

@article{capozzi_battle-test_2012,
	title = {Battle-test your innovation strategy},
	journaltitle = {{McKinsey} Quarterly},
	shortjournal = {{McKinsey} Quarterly},
	author = {Capozzi, Maria M. and Horn, John and Kellen, Ari},
	date = {2012-03-12},
	note = {Publisher: {McKinsey} \& Company},
	keywords = {Competitive strategy, Innovation strategy, Market entry, Product development, War games},
}

@misc{lin_battleagent_2024,
	title = {{BattleAgent}: Multi-modal Dynamic Emulation on Historical Battles to Complement Historical Analysis},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2404.15532},
	doi = {10.48550/ARXIV.2404.15532},
	shorttitle = {{BattleAgent}},
	abstract = {This paper presents {BattleAgent}, an emulation system that combines the Large Vision-Language Model and Multi-agent System. This novel system aims to simulate complex dynamic interactions among multiple agents, as well as between agents and their environments, over a period of time. It emulates both the decision-making processes of leaders and the viewpoints of ordinary participants, such as soldiers. The emulation showcases the current capabilities of agents, featuring fine-grained multi-modal interactions between agents and landscapes. It develops customizable agent structures to meet specific situational requirements, for example, a variety of battle-related activities like scouting and trench digging. These components collaborate to recreate historical events in a lively and comprehensive manner while offering insights into the thoughts and feelings of individuals from diverse viewpoints. The technological foundations of {BattleAgent} establish detailed and immersive settings for historical battles, enabling individual agents to partake in, observe, and dynamically respond to evolving battle scenarios. This methodology holds the potential to substantially deepen our understanding of historical events, particularly through individual accounts. Such initiatives can also aid historical research, as conventional historical narratives often lack documentation and prioritize the perspectives of decision-makers, thereby overlooking the experiences of ordinary individuals. {BattelAgent} illustrates {AI}'s potential to revitalize the human aspect in crucial social events, thereby fostering a more nuanced collective understanding and driving the progressive development of human society.},
	publisher = {{arXiv}},
	author = {Lin, Shuhang and Hua, Wenyue and Li, Lingyao and Chang, Che-Jui and Fan, Lizhou and Ji, Jianchao and Hua, Hang and Jin, Mingyu and Luo, Jiebo and Zhang, Yongfeng},
	urldate = {2025-09-08},
	date = {2024},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences, Human-Computer Interaction (cs.{HC}), Multiagent Systems (cs.{MA})},
}

@misc{wang_battleagentbench_2024,
	title = {{BattleAgentBench}: A Benchmark for Evaluating Cooperation and Competition Capabilities of Language Models in Multi-Agent Systems},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2408.15971},
	doi = {10.48550/ARXIV.2408.15971},
	shorttitle = {{BattleAgentBench}},
	abstract = {Large Language Models ({LLMs}) are becoming increasingly powerful and capable of handling complex tasks, e.g., building single agents and multi-agent systems. Compared to single agents, multi-agent systems have higher requirements for the collaboration capabilities of language models. Many benchmarks are proposed to evaluate their collaborative abilities. However, these benchmarks lack fine-grained evaluations of {LLM} collaborative capabilities. Additionally, multi-agent collaborative and competitive scenarios are ignored in existing works. To address these two problems, we propose a benchmark, called {BattleAgentBench}, which defines seven sub-stages of three varying difficulty levels and conducts a fine-grained evaluation of language models in terms of single-agent scenario navigation capabilities, paired-agent task execution abilities, and multi-agent collaboration and competition capabilities. We conducted extensive evaluations on leading four closed-source and seven open-source models. Experimental results indicate that {API}-based models perform excellently on simple tasks but open-source small models struggle with simple tasks. Regarding difficult tasks that require collaborative and competitive abilities, although {API}-based models have demonstrated some collaborative capabilities, there is still enormous room for improvement.},
	publisher = {{arXiv}},
	author = {Wang, Wei and Zhang, Dan and Feng, Tao and Wang, Boyan and Tang, Jie},
	urldate = {2025-09-08},
	date = {2024},
	note = {Version Number: 1},
	keywords = {Computation and Language (cs.{CL}), {FOS}: Computer and information sciences},
}

@inproceedings{connolly_battlefield_2024,
	location = {National Harbor, United States},
	title = {Battlefield information and tactics engine ({BITE}): a multimodal large language model approach for battlespace management},
	isbn = {978-1-5106-7420-2 978-1-5106-7421-9},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13051/3012352/Battlefield-information-and-tactics-engine-BITE--a-multimodal-large/10.1117/12.3012352.full},
	doi = {10.1117/12.3012352},
	shorttitle = {Battlefield information and tactics engine ({BITE})},
	eventtitle = {Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications {VI}},
	pages = {3},
	booktitle = {Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications {VI}},
	publisher = {{SPIE}},
	author = {Connolly, Brian J.},
	editor = {Schwartz, Peter J. and Hohil, Myron E. and Jensen, Benjamin},
	urldate = {2025-09-08},
	date = {2024-06-07},
}

@article{czakon_behavioral_2020,
	title = {Behavioral antecedents of coopetition: A synthesis and measurement scale},
	volume = {53},
	issn = {0024-6301},
	url = {https://www.sciencedirect.com/science/article/pii/S0024630117305496},
	doi = {10.1016/j.lrp.2019.03.001},
	series = {Coopetition Strategies},
	shorttitle = {Behavioral antecedents of coopetition},
	abstract = {This study taps into managers' perceptions of coopetition antecedents to better understand why firms adopt coopetition. By analyzing and synthesizing findings from systematic reviews of coopetition literature we integrate knowledge on coopetition antecedents. We develop and validate a scale measuring behavioral coopetition antecedents: strategic rationale and coopetition mindset. Based on a random sample of 368 Polish tourism firms, we run exploratory and confirmatory factor analyses to find that antecedents used in coopetition literature converge into two latent, behavioral constructs. Our data substantiate the view that coopetition is an intentional strategy, driven by a strategic rationale. Managers are found to pursue coopetition in order to reach clearly defined benefits with fitting partners. Moreover, three elements are found to converge in the coopetitive mindset latent construct: orientation to cooperation, trust, and experience in coopetition. We contribute to the methodological advancement of measurement instruments with applicability potential in future research examining the behavioral antecedents of coopetition. We also advance the behavioral stream of research in strategy by empirically identifying the connection between rational and behavioral antecedents of firms’ coopetitive strategic behavior.},
	pages = {101875},
	number = {1},
	journaltitle = {Long Range Planning},
	shortjournal = {Long Range Planning},
	author = {Czakon, Wojciech and Klimas, Patrycja and Mariani, Marcello},
	urldate = {2025-06-12},
	date = {2020-02-01},
	keywords = {Antecedents, Behavioral, Coopetition, Mindset, Scale development, Tourism},
}

@misc{barrett_benchmark_2024,
	title = {Benchmark Early and Red Team Often: A Framework for Assessing and Managing Dual-Use Hazards of {AI} Foundation Models},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2405.10986},
	doi = {10.48550/ARXIV.2405.10986},
	shorttitle = {Benchmark Early and Red Team Often},
	abstract = {A concern about cutting-edge or "frontier" {AI} foundation models is that an adversary may use the models for preparing chemical, biological, radiological, nuclear, ({CBRN}), cyber, or other attacks. At least two methods can identify foundation models with potential dual-use capability; each has advantages and disadvantages: A. Open benchmarks (based on openly available questions and answers), which are low-cost but accuracy-limited by the need to omit security-sensitive details; and B. Closed red team evaluations (based on private evaluation by {CBRN} and cyber experts), which are higher-cost but can achieve higher accuracy by incorporating sensitive details. We propose a research and risk-management approach using a combination of methods including both open benchmarks and closed red team evaluations, in a way that leverages advantages of both methods. We recommend that one or more groups of researchers with sufficient resources and access to a range of near-frontier and frontier foundation models run a set of foundation models through dual-use capability evaluation benchmarks and red team evaluations, then analyze the resulting sets of models' scores on benchmark and red team evaluations to see how correlated those are. If, as we expect, there is substantial correlation between the dual-use potential benchmark scores and the red team evaluation scores, then implications include the following: The open benchmarks should be used frequently during foundation model development as a quick, low-cost measure of a model's dual-use potential; and if a particular model gets a high score on the dual-use potential benchmark, then more in-depth red team assessments of that model's dual-use capability should be performed. We also discuss limitations and mitigations for our approach, e.g., if model developers try to game benchmarks by including a version of benchmark test data in a model's training data.},
	publisher = {{arXiv}},
	author = {Barrett, Anthony M. and Jackson, Krystal and Murphy, Evan R. and Madkour, Nada and Newman, Jessica},
	urldate = {2025-09-08},
	date = {2024},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.{AI}), Computers and Society (cs.{CY}), Cryptography and Security (cs.{CR}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
}

@misc{ruan_benchmarking_2025,
	title = {Benchmarking {LLMs}' Swarm intelligence},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2505.04364},
	doi = {10.48550/ARXIV.2505.04364},
	abstract = {Large Language Models ({LLMs}) show potential for complex reasoning, yet their capacity for emergent coordination in Multi-Agent Systems ({MAS}) when operating under strict swarm-like constraints-limited local perception and communication-remains largely unexplored. Existing benchmarks often do not fully capture the unique challenges of decentralized coordination when agents operate with incomplete spatio-temporal information. To bridge this gap, we introduce {SwarmBench}, a novel benchmark designed to systematically evaluate the swarm intelligence capabilities of {LLMs} acting as decentralized agents. {SwarmBench} features five foundational {MAS} coordination tasks (Pursuit, Synchronization, Foraging, Flocking, Transport) within a configurable 2D grid environment, forcing agents to rely solely on local sensory input (\$k{\textbackslash}times k\$ view) and local communication. We propose metrics for coordination effectiveness and analyze emergent group dynamics. Zero-shot evaluations of leading {LLMs} (e.g., deepseek-v3, o4-mini) reveal significant task-dependent performance variations. While some rudimentary coordination is observed, our results indicate that current {LLMs} significantly struggle with robust long-range planning and adaptive strategy formation under the uncertainty inherent in these decentralized scenarios. Assessing {LLMs} under such swarm-like constraints is crucial for understanding their utility in future decentralized intelligent systems. We release {SwarmBench} as an open, extensible toolkit-built on a customizable physical system-providing environments, prompts, evaluation scripts, and comprehensive datasets. This aims to foster reproducible research into {LLM}-based {MAS} coordination and the theoretical underpinnings of emergent collective behavior under severe informational decentralization. Our code repository is available at https://github.com/x66ccff/swarmbench.},
	publisher = {{arXiv}},
	author = {Ruan, Kai and Huang, Mowen and Wen, Ji-Rong and Sun, Hao},
	urldate = {2025-09-08},
	date = {2025},
	note = {Version Number: 3},
	keywords = {Computation and Language (cs.{CL}), {FOS}: Computer and information sciences, Multiagent Systems (cs.{MA})},
}

@article{lawrencec_beware_2025,
	title = {Beware General Claims about “Generalizable Reasoning Capabilities” (of Modern {AI} Systems)},
	url = {https://www.lesswrong.com/posts/5uw26uDdFbFQgKzih/beware-general-claims-about-generalizable-reasoning},
	abstract = {1.
Late last week, researchers at Apple released a paper provocatively titled “The Illusion of Thinking: Understanding the Strengths and Limitations…},
	author = {{LawrenceC}},
	urldate = {2025-06-25},
	date = {2025-06-11},
	langid = {english},
}

@article{ribeiro_beyond_2020,
	title = {Beyond Accuracy: Behavioral Testing of {NLP} models with {CheckList}},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2005.04118},
	doi = {10.48550/ARXIV.2005.04118},
	shorttitle = {Beyond Accuracy},
	abstract = {Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of {NLP} models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce {CheckList}, a task-agnostic methodology for testing {NLP} models. {CheckList} includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of {CheckList} with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, {NLP} practitioners with {CheckList} created twice as many tests, and found almost three times as many bugs as users without it.},
	author = {Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
	urldate = {2025-09-08},
	date = {2020},
	note = {Publisher: {arXiv}
Version Number: 1},
	keywords = {Computation and Language (cs.{CL}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
}

@misc{yan_beyond_2025,
	title = {Beyond Self-Talk: A Communication-Centric Survey of {LLM}-Based Multi-Agent Systems},
	url = {http://arxiv.org/abs/2502.14321},
	doi = {10.48550/arXiv.2502.14321},
	shorttitle = {Beyond Self-Talk},
	abstract = {Large language model-based multi-agent systems have recently gained significant attention due to their potential for complex, collaborative, and intelligent problem-solving capabilities. Existing surveys typically categorize {LLM}-based multi-agent systems ({LLM}-{MAS}) according to their application domains or architectures, overlooking the central role of communication in coordinating agent behaviors and interactions. To address this gap, this paper presents a comprehensive survey of {LLM}-{MAS} from a communication-centric perspective. Specifically, we propose a structured framework that integrates system-level communication (architecture, goals, and protocols) with system internal communication (strategies, paradigms, objects, and content), enabling a detailed exploration of how agents interact, negotiate, and achieve collective intelligence. Through an extensive analysis of recent literature, we identify key components in multiple dimensions and summarize their strengths and limitations. In addition, we highlight current challenges, including communication efficiency, security vulnerabilities, inadequate benchmarking, and scalability issues, and outline promising future research directions. This review aims to help researchers and practitioners gain a clear understanding of the communication mechanisms in {LLM}-{MAS}, thereby facilitating the design and deployment of robust, scalable, and secure multi-agent systems.},
	number = {{arXiv}:2502.14321},
	publisher = {{arXiv}},
	author = {Yan, Bingyu and Zhou, Zhibo and Zhang, Litian and Zhang, Lian and Zhou, Ziyi and Miao, Dezhuang and Li, Zhoujun and Li, Chaozhuo and Zhang, Xiaoming},
	urldate = {2025-09-10},
	date = {2025-06-19},
	eprinttype = {arxiv},
	eprint = {2502.14321 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Multiagent Systems},
}

@misc{ren_beyond_2025,
	title = {Beyond the Tragedy of the Commons: Building A Reputation System for Generative Multi-agent Systems},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2505.05029},
	doi = {10.48550/ARXIV.2505.05029},
	shorttitle = {Beyond the Tragedy of the Commons},
	abstract = {The tragedy of the commons, where individual self-interest leads to collectively disastrous outcomes, is a pervasive challenge in human society. Recent studies have demonstrated that similar phenomena can arise in generative multi-agent systems ({MASs}). To address this challenge, this paper explores the use of reputation systems as a remedy. We propose {RepuNet}, a dynamic, dual-level reputation framework that models both agent-level reputation dynamics and system-level network evolution. Specifically, driven by direct interactions and indirect gossip, agents form reputations for both themselves and their peers, and decide whether to connect or disconnect other agents for future interactions. Through two distinct scenarios, we show that {RepuNet} effectively mitigates the 'tragedy of the commons', promoting and sustaining cooperation in generative {MASs}. Moreover, we find that reputation systems can give rise to rich emergent behaviors in generative {MASs}, such as the formation of cooperative clusters, the social isolation of exploitative agents, and the preference for sharing positive gossip rather than negative ones.},
	publisher = {{arXiv}},
	author = {Ren, Siyue and Fu, Wanli and Zou, Xinkun and Shen, Chen and Cai, Yi and Chu, Chen and Wang, Zhen and Hu, Shuyue},
	urldate = {2025-09-08},
	date = {2025},
	note = {Version Number: 2},
	keywords = {Artificial Intelligence (cs.{AI}), {FOS}: Computer and information sciences, Multiagent Systems (cs.{MA})},
}

@article{reis_bigpicture_2015,
	title = {{BigPicture}: An Analytical Platform for Business War Gaming},
	volume = {07},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {2160-5912, 2160-5920},
	url = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/iim.2015.76024},
	doi = {10.4236/iim.2015.76024},
	shorttitle = {{BigPicture}},
	pages = {303--312},
	number = {6},
	journaltitle = {Intelligent Information Management},
	shortjournal = {{IIM}},
	author = {Reis, Miguel and Silva, Ruben and Romão, Artur and Saias, José},
	urldate = {2025-09-13},
	date = {2015},
}

@article{eliaz_bilateral_2018,
	title = {Bilateral trade with strategic gradual learning},
	volume = {107},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825617302014},
	doi = {10.1016/j.geb.2017.10.026},
	abstract = {We propose a model of bilateral trade in which private information about the quality of an asset can be acquired only gradually over time. An asset is characterized by a vector of binary i.i.d. attributes, and its worth to a player is equal to a weighted sum of the attributes' values (where weights differ across players). The seller is initially uninformed about the attributes' values, and each period he decides whether to make a price offer or to costlessly inspect an attribute's value. The buyer does not know the attributes' values, but he may or may not observe which inspections were performed (we consider both cases). We study the seller's strategic scheduling of inspections and its effect on the realized gains from trade in equilibrium. We identify the necessary and sufficient conditions under which the players can realize some gains from trade, and all gains from trade.},
	pages = {380--395},
	journaltitle = {Games and Economic Behavior},
	shortjournal = {Games and Economic Behavior},
	author = {Eliaz, Kfir and Frug, Alexander},
	urldate = {2025-06-12},
	date = {2018-01-01},
	keywords = {Endogenous asymmetric information, Gains from trade, Gradual learning, Strategic scheduling},
}

@misc{ran_bookworld_2025,
	title = {{BookWorld}: From Novels to Interactive Agent Societies for Creative Story Generation},
	rights = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
	url = {https://arxiv.org/abs/2504.14538},
	doi = {10.48550/ARXIV.2504.14538},
	shorttitle = {{BookWorld}},
	abstract = {Recent advances in large language models ({LLMs}) have enabled social simulation through multi-agent systems. Prior efforts focus on agent societies created from scratch, assigning agents with newly defined personas. However, simulating established fictional worlds and characters remain largely underexplored, despite its significant practical value. In this paper, we introduce {BookWorld}, a comprehensive system for constructing and simulating book-based multi-agent societies. {BookWorld}'s design covers comprehensive real-world intricacies, including diverse and dynamic characters, fictional worldviews, geographical constraints and changes, e.t.c. {BookWorld} enables diverse applications including story generation, interactive games and social simulation, offering novel ways to extend and explore beloved fictional works. Through extensive experiments, we demonstrate that {BookWorld} generates creative, high-quality stories while maintaining fidelity to the source books, surpassing previous methods with a win rate of 75.36\%. The code of this paper can be found at the project page: https://bookworld2025.github.io/.},
	publisher = {{arXiv}},
	author = {Ran, Yiting and Wang, Xintao and Qiu, Tian and Liang, Jiaqing and Xiao, Yanghua and Yang, Deqing},
	urldate = {2025-09-08},
	date = {2025},
	note = {Version Number: 1},
	keywords = {Computation and Language (cs.{CL}), {FOS}: Computer and information sciences},
}

@book{bartels_building_2020,
	title = {Building Better Games for National Security Policy Analysis: Towards a Social Scientific Approach},
	url = {https://www.rand.org/pubs/rgs_dissertations/RGSD437.html},
	shorttitle = {Building Better Games for National Security Policy Analysis},
	publisher = {{RAND} Corporation},
	author = {Bartels, Elizabeth},
	urldate = {2025-09-08},
	date = {2020},
	langid = {english},
	doi = {10.7249/RGSD437},
}

@article{lang_building_2017,
	title = {Building new social capital with scenario planning},
	volume = {124},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162517307849},
	doi = {10.1016/j.techfore.2017.06.011},
	abstract = {Practitioners have observed that scenario planning contributes to building new social capital. In scenario planning terms, new social capital can provide access to new information, novel strategic options and unprecedented collaborative opportunities. However, there is no description or explanation in the literature as to how scenario planning can build new social capital. Reporting on research into the scenario planning process of two organizations, we find that scenario planning generates new social capital through learning with the conceptual future, which is a direct investment in building new shared systems of meaning – the cognitive dimension of social capital. This then enables the structural and relational dimensions of new social capital to emerge as by-products. The building of new social capital provides another purpose for scenario investments and another quality criterion by which to assess the value of these interventions. The insights of the research will be of interest to: scenario planning scholars; leaders interested in how to purposefully design and conduct scenario planning if a core intent is to build new social capital; and scholars interested in the cognitive dimension of social capital and its creation.},
	pages = {51--65},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Lang, Trudi and Ramírez, Rafael},
	urldate = {2025-06-12},
	date = {2017-11-01},
	keywords = {Building social capital, Cognitive social capital, Scenario planning, Turbulence},
}

@article{bachi_buridanic_2018,
	title = {Buridanic competition},
	volume = {107},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825617301999},
	doi = {10.1016/j.geb.2017.10.024},
	abstract = {We analyze a model of two-attribute competition for a decision maker who follows a non-compensatory choice procedure that only responds to ordinal rankings along the two dimensions. The decision maker has an outside option that functions as a default alternative. In the absence of a dominant alternative, the decision maker may stick to the default even if it is dominated – capturing the phenomenon of choice procrastination in the presence of difficult choices. We show that the prevalence of difficult-choice situations in equilibrium is related to the magnitude of the choice procrastination effect. In general, features of the choice procedure that are typically viewed as biases tend to “protect” the decision maker, in the sense that they encourage competitors to offer higher-value alternatives in equilibrium. We discuss the potential implications of this analysis for recent discussions of “default architecture”.},
	pages = {298--315},
	journaltitle = {Games and Economic Behavior},
	shortjournal = {Games and Economic Behavior},
	author = {Bachi, Benjamin and Spiegler, Ran},
	urldate = {2025-06-12},
	date = {2018-01-01},
	keywords = {Behavioral industrial organization, Choice complexity, Competition, Default bias, Multi-attribute products, Trade-off avoidance},
}

@misc{enwiki:1310067502,
	title = {Business war games — Wikipedia, the free encyclopedia},
	url = {https://en.wikipedia.org/w/index.php?title=Business_war_games&oldid=1310067502},
	author = {{Wikipedia contributors}},
	date = {2025},
}

@article{schwarz_business_2013,
	title = {Business wargaming for teaching strategy making},
	volume = {51},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328713000864},
	doi = {10.1016/j.futures.2013.06.002},
	abstract = {An increasingly complex and dynamic business environment requires new approaches to teaching strategy to management students. Business wargaming, a dynamic strategic simulation, is discussed as a management simulation which can respond to the contemporary challenges in management education. Reflecting on the practical use of business wargaming in the classroom, it is described how such simulations prepare management students for making strategic decisions in complex and dynamic environments characterised by high uncertainty concerning the future.},
	pages = {59--66},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Schwarz, Jan Oliver},
	urldate = {2025-06-12},
	date = {2013-07-01},
	keywords = {Business wargaming, Management education, Simulation, Strategic thinking, Strategy making, Teaching},
}

@article{kurtz_business_2003,
	title = {“Business wargaming”: simulations guide crucial strategy decisions},
	volume = {31},
	issn = {1087-8572},
	url = {https://doi.org/10.1108/10878570310505550},
	doi = {10.1108/10878570310505550},
	shorttitle = {“Business wargaming”},
	abstract = {“Business wargaming” is a role‐playing simulation of a dynamic business situation that involves a series of teams, each assigned to assume the identity of an entity with a stake in the situation. The process steps for wargaming, important lessons to follow, and a case study are all presented in this article. Wargames offer unique benefits at two points in an organization’s strategic planning process: (1) at its outset, wargames are helpful to convert data and information (about markets, channels, competitors, etc.) into actionable intelligence for subsequent planning; (2) after a basic plan is developed, a wargame can test the plan to ensure it is robust enough to succeed in any realistic combination of events or actions. Attributes of a business wargame: (1) it involves intense competition among five to ten teams, each representing a distinct stakeholder (such as the market, key customers, suppliers, partners, competitors, channels, regulators); (2) the team interact based both on quantitative and qualitative information. Through the use of role playing, cultural issues, rivalries and other subjective factors guide development and assessment of strategies; (3) the wargame process forces a rigorous exam of a situation from multiple perspectives. The various points of view (some hostile) allow the company to recognize opportunities and threats otherwise not noticed using just an “inside‐out” approach; and (4) the gaming allows a broad range of ideas to be developed while the teams aggressively compete to outsmart each other. The time, cost, and effort in preparing a major wargame are spelled out. The case illustrates the potential pay‐off in situations where the wargame makes strategic choices apparent.},
	pages = {12--21},
	number = {6},
	journaltitle = {Strategy \& Leadership},
	author = {Kurtz, Jay},
	urldate = {2025-06-12},
	date = {2003-01-01},
	note = {Publisher: {MCB} {UP} Ltd},
	keywords = {Decision making, Management games, Role play},
}

@misc{guo_can_2024,
	title = {Can Large Language Models Play Games? A Case Study of A Self-Play Approach},
	url = {http://arxiv.org/abs/2403.05632},
	doi = {10.48550/arXiv.2403.05632},
	shorttitle = {Can Large Language Models Play Games?},
	abstract = {Large Language Models ({LLMs}) harness extensive data from the Internet, storing a broad spectrum of prior knowledge. While {LLMs} have proven beneficial as decision-making aids, their reliability is hampered by limitations in reasoning, hallucination phenomenon, and so on. On the other hand, Monte-Carlo Tree Search ({MCTS}) is a heuristic search algorithm that provides reliable decision-making solutions, achieved through recursive rollouts and self-play. However, the effectiveness of {MCTS} relies heavily on heuristic pruning and external value functions, particularly in complex decision scenarios. This work introduces an innovative approach that bolsters {LLMs} with {MCTS} self-play to efficiently resolve deterministic turn-based zero-sum games ({DTZG}), such as chess and go, without the need for additional training. Specifically, we utilize {LLMs} as both action pruners and proxies for value functions without the need for additional training. We theoretically prove that the suboptimality of the estimated value in our proposed method scales with \${\textbackslash}tilde\{{\textbackslash}mathcal O\}{\textbackslash}Bigl({\textbackslash}frac\{{\textbar}{\textbackslash}tilde \{{\textbackslash}mathcal A\}{\textbar}\}\{{\textbackslash}sqrt\{N\}\} + {\textbackslash}epsilon\_{\textbackslash}mathrm\{pruner\} + {\textbackslash}epsilon\_{\textbackslash}mathrm\{critic\}{\textbackslash}Bigr)\$, where {\textbackslash}(N{\textbackslash}) is the number of simulations, \${\textbar}{\textbackslash}tilde \{{\textbackslash}mathcal A\}{\textbar}\$ is the cardinality of the pruned action space by {LLM}, and \${\textbackslash}epsilon\_{\textbackslash}mathrm\{pruner\}\$ and \${\textbackslash}epsilon\_{\textbackslash}mathrm\{critic\}\$ quantify the errors incurred by adopting {LLMs} as action space pruner and value function proxy, respectively. Our experiments in chess and go demonstrate the capability of our method to address challenges beyond the scope of {MCTS} and improve the performance of the directly application of {LLMs}.},
	number = {{arXiv}:2403.05632},
	publisher = {{arXiv}},
	author = {Guo, Hongyi and Liu, Zhihan and Zhang, Yufeng and Wang, Zhaoran},
	urldate = {2025-09-09},
	date = {2024-03-08},
	eprinttype = {arxiv},
	eprint = {2403.05632 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{zhu_capturing_2025,
	title = {Capturing the complexity of human strategic decision-making with machine learning},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-025-02230-5},
	doi = {10.1038/s41562-025-02230-5},
	journaltitle = {Nature Human Behaviour},
	shortjournal = {Nat Hum Behav},
	author = {Zhu, Jian-Qiao and Peterson, Joshua C. and Enke, Benjamin and Griffiths, Thomas L.},
	urldate = {2025-09-08},
	date = {2025-06-25},
	langid = {english},
}

@article{herr_dr_card_nodate,
	title = {Card Sharks, Blockheads, Redeemed Euroweenies, Plastic Men and Old Guard Hex and Potatoes: An Analysis of the Top Wargames from 1958 through 2008 Utilizing the {BGG} Database},
	volume = {1},
	url = {https://www.professionalwargaming.co.uk/Top-300-COTSWargames.pdf},
	issue = {June 2008},
	journaltitle = {{TOA} Analysis},
	author = {{Herr Dr}},
	urldate = {2025-06-26},
}

@incollection{lima_challenges_2020,
	title = {Challenges of using machine learning algorithms for cybersecurity},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-819204-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128192047000038},
	pages = {33--52},
	booktitle = {Cyber Influence and Cognitive Threats},
	publisher = {Elsevier},
	author = {Lima, Andrei Queiroz and Keegan, Brian},
	urldate = {2025-08-06},
	date = {2020},
	langid = {english},
	doi = {10.1016/B978-0-12-819204-7.00003-8},
}

@article{hanley_changing_2017,
	title = {{CHANGING} {DOD}’S {ANALYSIS} {PARADIGM}: The Science of War Gaming and Combat/Campaign Simulation},
	volume = {70},
	issn = {0028-1484},
	url = {https://www.jstor.org/stable/26398006},
	shorttitle = {{CHANGING} {DOD}’S {ANALYSIS} {PARADIGM}},
	pages = {64--103},
	number = {1},
	journaltitle = {Naval War College Review},
	author = {Hanley, John T.},
	urldate = {2025-06-25},
	date = {2017},
	note = {Publisher: U.S. Naval War College Press},
}

@article{scherpereel_changing_2005,
	title = {Changing mental models: Business simulation exercises},
	volume = {36},
	issn = {1046-8781},
	url = {https://journals.sagepub.com/doi/abs/10.1177/1046878104270005?journalCode=sagb},
	doi = {10.1177/1046878104270005},
	shorttitle = {Changing mental models},
	abstract = {The effectiveness of business simulation exercises in uncovering the interconnectedness of business decisions has been explored in the literature. Little resear...},
	pages = {388--403},
	number = {3},
	journaltitle = {Simulation \& Gaming},
	author = {Scherpereel, Christopher M.},
	urldate = {2025-06-12},
	date = {2005-09},
	note = {Publisher: Sage {PublicationsSage} {CA}: Thousand Oaks, {CA}},
}

@article{maharaj_chess_2022,
	title = {Chess {AI}: Competing Paradigms for Machine Intelligence},
	volume = {24},
	issn = {1099-4300},
	url = {http://arxiv.org/abs/2109.11602},
	doi = {10.3390/e24040550},
	shorttitle = {Chess {AI}},
	abstract = {Endgame studies have long served as a tool for testing human creativity and intelligence. We find that they can serve as a tool for testing machine ability as well. Two of the leading chess engines, Stockfish and Leela Chess Zero ({LCZero}), employ significantly different methods during play. We use Plaskett's Puzzle, a famous endgame study from the late 1970s, to compare the two engines. Our experiments show that Stockfish outperforms {LCZero} on the puzzle. We examine the algorithmic differences between the engines and use our observations as a basis for carefully interpreting the test results. Drawing inspiration from how humans solve chess problems, we ask whether machines can possess a form of imagination. On the theoretical side, we describe how Bellman's equation may be applied to optimize the probability of winning. To conclude, we discuss the implications of our work on artificial intelligence ({AI}) and artificial general intelligence ({AGI}), suggesting possible avenues for future research.},
	pages = {550},
	number = {4},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Maharaj, Shiva and Polson, Nick and Turk, Alex},
	urldate = {2025-09-12},
	date = {2022-04-14},
	eprinttype = {arxiv},
	eprint = {2109.11602 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{feng_chessgpt_2023,
	title = {{ChessGPT}: Bridging Policy Learning and Language Modeling},
	url = {http://arxiv.org/abs/2306.09200},
	doi = {10.48550/arXiv.2306.09200},
	shorttitle = {{ChessGPT}},
	abstract = {When solving decision-making tasks, humans typically depend on information from two key sources: (1) Historical policy data, which provides interaction replay from the environment, and (2) Analytical insights in natural language form, exposing the invaluable thought process or strategic considerations. Despite this, the majority of preceding research focuses on only one source: they either use historical replay exclusively to directly learn policy or value functions, or engaged in language model training utilizing mere language corpus. In this paper, we argue that a powerful autonomous agent should cover both sources. Thus, we propose {ChessGPT}, a {GPT} model bridging policy learning and language modeling by integrating data from these two sources in Chess games. Specifically, we build a large-scale game and language dataset related to chess. Leveraging the dataset, we showcase two model examples {ChessCLIP} and {ChessGPT}, integrating policy learning and language modeling. Finally, we propose a full evaluation framework for evaluating language model's chess ability. Experimental results validate our model and dataset's effectiveness. We open source our code, model, and dataset at https://github.com/waterhorse1/{ChessGPT}.},
	number = {{arXiv}:2306.09200},
	publisher = {{arXiv}},
	author = {Feng, Xidong and Luo, Yicheng and Wang, Ziyan and Tang, Hongrui and Yang, Mengyue and Shao, Kun and Mguni, David and Du, Yali and Wang, Jun},
	urldate = {2025-09-09},
	date = {2023-12-21},
	eprinttype = {arxiv},
	eprint = {2306.09200 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{lord_choosing_2016,
	title = {Choosing diverse sets of plausible scenarios in multidimensional exploratory futures techniques},
	volume = {77},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328715001664},
	doi = {10.1016/j.futures.2015.12.003},
	abstract = {Morphological analysis allows any number of dimensions to be retained when framing future conditions, and techniques within morphological analysis determine which combinations of those dimensions represent plausible futures. However, even a relatively low number of dimensions in future conditions can lead to hundreds or even thousands of plausible future scenarios. Creating highly diverse but conceivable visions of the future in which to explore decision-making, exploratory futures techniques rely on the selection of a small number of plausible scenarios from the larger set. In this paper we describe a new method for finding maximally diverse sets containing a small number of plausible scenarios from a multi-dimensional morphological analysis. It is based on a mathematical optimization of diversity that is robust to the uncertainty in the framing of future factors and states and in what stakeholders might consider diverse combinations of those factors and states. We also describe implementation of the method as a software tool and its performance in recent exploratory scenario development by {CGIAR} and partners for regional environmental change, food security and livelihoods.},
	pages = {11--27},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Lord, Steven and Helfgott, Ariella and Vervoort, Joost M.},
	urldate = {2025-06-12},
	date = {2016-03-01},
	keywords = {Exploratory scenarios, Morphological analysis, {OLDFAR}, Regional environmental change scenarios, Robust optimization, Scenario diversity},
}

@misc{qi_civrealm_2024,
	title = {{CivRealm}: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents},
	url = {http://arxiv.org/abs/2401.10568},
	doi = {10.48550/arXiv.2401.10568},
	shorttitle = {{CivRealm}},
	abstract = {The generalization of decision-making agents encompasses two fundamental elements: learning from past experiences and reasoning in novel contexts. However, the predominant emphasis in most interactive environments is on learning, often at the expense of complexity in reasoning. In this paper, we introduce {CivRealm}, an environment inspired by the Civilization game. Civilization's profound alignment with human history and society necessitates sophisticated learning, while its ever-changing situations demand strong reasoning to generalize. Particularly, {CivRealm} sets up an imperfect-information general-sum game with a changing number of players; it presents a plethora of complex features, challenging the agent to deal with open-ended stochastic environments that require diplomacy and negotiation skills. Within {CivRealm}, we provide interfaces for two typical agent types: tensor-based agents that focus on learning, and language-based agents that emphasize reasoning. To catalyze further research, we present initial results for both paradigms. The canonical {RL}-based agents exhibit reasonable performance in mini-games, whereas both {RL}- and {LLM}-based agents struggle to make substantial progress in the full game. Overall, {CivRealm} stands as a unique learning and reasoning challenge for decision-making agents. The code is available at https://github.com/bigai-ai/civrealm.},
	number = {{arXiv}:2401.10568},
	publisher = {{arXiv}},
	author = {Qi, Siyuan and Chen, Shuo and Li, Yexin and Kong, Xiangyu and Wang, Junqi and Yang, Bangcheng and Wong, Pring and Zhong, Yifan and Zhang, Xiaoyuan and Zhang, Zhaowei and Liu, Nian and Wang, Wei and Yang, Yaodong and Zhu, Song-Chun},
	urldate = {2025-09-09},
	date = {2024-03-12},
	eprinttype = {arxiv},
	eprint = {2401.10568 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{schwarz_combining_2019,
	title = {Combining scenario planning and business wargaming to better anticipate future competitive dynamics},
	volume = {105},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328718300545},
	doi = {10.1016/j.futures.2018.10.001},
	abstract = {The deliberate exploration of how the future competitive landscape may evolve is critical to uncovering threats and opportunities for firms that seek to improve their core businesses and advance to a superior position in the markets of the future. While techniques such as business wargaming can effectively support this process, such techniques can benefit from placing competitive considerations within a broader future landscape shaped by geopolitical, social, technological and economic forces. Scenario planning allows for the exploration of interactions across multiple external forces to create a rich set of narratives on how the future may unfold. This paper will discuss the potential of combining scenario planning and business wargaming to enable strategists to anticipate moves and countermoves and foresee their consequences. We use a real-life case study to illustrate how a scenario-planning exercise can guide the crucial stage of selecting relevant future competitors of a firm prior to engaging in a business-war-gaming exercise. We then introduce what we term the prospective competitive strategy process to guide the analysis of potential competitive dynamics, emphasizing the synergies between scenario planning and business wargaming.},
	pages = {133--142},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Schwarz, Jan Oliver and Ram, Camelia and Rohrbeck, René},
	urldate = {2025-06-12},
	date = {2019-01-01},
	keywords = {Business war gaming, Competitive landscape, Foresight, Scenario planning},
}

@article{mittal_combining_2021,
	title = {Combining Wargaming With Modeling and Simulation to Project Future Military Technology Requirements},
	volume = {68},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{USG}.html},
	issn = {0018-9391, 1558-0040},
	url = {https://ieeexplore.ieee.org/document/9184821/},
	doi = {10.1109/TEM.2020.3017459},
	pages = {1195--1207},
	number = {4},
	journaltitle = {{IEEE} Transactions on Engineering Management},
	shortjournal = {{IEEE} Trans. Eng. Manage.},
	author = {Mittal, Vikram and Davidson, Andrew},
	urldate = {2025-09-08},
	date = {2021-08},
}

@article{hamel_competing_1994,
	title = {Competing for the Future},
	issn = {0017-8012},
	url = {https://hbr.org/1994/07/competing-for-the-future},
	journaltitle = {Harvard Business Review},
	author = {Hamel, Gary and Prahalad, C. K.},
	urldate = {2025-06-12},
	date = {1994},
	langid = {english},
}

@article{helen_mitchard_composing_2010,
	title = {Composing Effective Environments for Concept Exploration in a Multi-Agency Context},
	volume = {4:3},
	abstract = {There is a need to integrate a range of stakeholders, both military and non-military, into the planning and conduct of operations, both civil and military. These endeavors necessitate the inclusion of many stakeholders, each of which bring diverse agendas, values, and differing degrees of experience and training. Anecdotes suggest that techniques used to inform planning and subsequent operations often fail to reflect the complexity of such multi-agency environments. We report on a technique that has been used successfully to explore the issues evident in multi-agency planning and operations. Specifically, we report on the use and suitability of Engle matrix gaming methods to simulate the complex nature of the problem space. The key to success of these activities is related to the level of preparation and we discuss what issues should be considered with regard to the scenario, personnel and overall planning.},
	issue = {Interagency Experimentation},
	journaltitle = {The International C2 Journal},
	author = {{Helen Mitchard} and {Simon Ng}},
	date = {2010},
	langid = {english},
}

@incollection{colton_simon_computational_2012,
	title = {Computational Creativity: The Final Frontier?},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospressISSNISBN&issn=0922-6389&volume=242&spage=21},
	shorttitle = {Computational Creativity},
	abstract = {Notions relating to computational systems exhibiting creative behaviours have been explored since the very early days of computer science, and the field of Computational Creativity research has formed in the last dozen years to scientifically explore the potential of such systems. We describe this field via a working definition; a brief history of seminal work; an exploration of the main issues, technologies and ideas; and a look towards future directions. As a society, we are jealous of our creativity: creative people and their contributions to cultural progression are highly valued. Moreover, creative behaviour in people draws on a full set of intelligent abilities, so simulating such behaviour represents a serious technical challenge for Artificial Intelligence research. As such, we believe it is fair to characterise Computational Creativity as a frontier for {AI} research beyond all others\&mdash;maybe, even, the final frontier.},
	booktitle = {Frontiers in Artificial Intelligence and Applications},
	publisher = {{IOS} Press},
	author = {{Colton Simon} and {Wiggins Geraint A.}},
	urldate = {2025-09-12},
	date = {2012},
	doi = {10.3233/978-1-61499-098-7-21},
}

@unpublished{ma_computational_2024,
	title = {Computational experiments meet large language model based agents: A survey and perspective},
	url = {http://arxiv.org/abs/2402.00262},
	abstract = {Computational experiments have emerged as a valuable method for studying
complex systems, involving the algorithmization of counterfactuals.
However, accurately representing real social systems in Agent-based
Modeling ({ABM}) is challenging due to the diverse and intricate
characteristics of humans, including bounded rationality and
heterogeneity. To address this limitation, the integration of Large
Language Models ({LLMs}) has been proposed, enabling agents to possess
anthropomorphic abilities such as complex reasoning and autonomous
learning. These agents, known as {LLM}-based Agent, offer the potential to
enhance the anthropomorphism lacking in {ABM}. Nonetheless, the absence of
explicit explainability in {LLMs} significantly hinders their application in
the social sciences. Conversely, computational experiments excel in
providing causal analysis of individual behaviors and complex phenomena.
Thus, combining computational experiments with {LLM}-based Agent holds
substantial research potential. This paper aims to present a comprehensive
exploration of this fusion. Primarily, it outlines the historical
development of agent structures and their evolution into artificial
societies, emphasizing their importance in computational experiments. Then
it elucidates the advantages that computational experiments and {LLM}-based
Agents offer each other, considering the perspectives of {LLM}-based Agent
for computational experiments and vice versa. Finally, this paper
addresses the challenges and future trends in this research domain,
offering guidance for subsequent related studies.},
	author = {Ma, Qun and Xue, Xiao and Zhou, Deyu and Yu, Xiangning and Liu, Donghua and Zhang, Xuwen and Zhao, Zihan and Shen, Yifan and Ji, Peilin and Li, Juanjuan and Wang, Gang and Ma, Wanpeng},
	urldate = {2024-08-12},
	date = {2024-01-31},
	note = {{ISBN}: 2402.00262
Publication Title: {arXiv} [cs.{AI}]},
}

@misc{bai_constitutional_2022,
	title = {Constitutional {AI}: Harmlessness from {AI} Feedback},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2212.08073},
	doi = {10.48550/ARXIV.2212.08073},
	shorttitle = {Constitutional {AI}},
	abstract = {As {AI} systems become more capable, we would like to enlist their help to supervise other {AIs}. We experiment with methods for training a harmless {AI} assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional {AI}'. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then finetune the original model on revised responses. In the {RL} phase, we sample from the finetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of {AI} preferences. We then train with {RL} using the preference model as the reward signal, i.e. we use '{RL} from {AI} Feedback' ({RLAIF}). As a result we are able to train a harmless but non-evasive {AI} assistant that engages with harmful queries by explaining its objections to them. Both the {SL} and {RL} methods can leverage chain-of-thought style reasoning to improve the human-judged performance and transparency of {AI} decision making. These methods make it possible to control {AI} behavior more precisely and with far fewer human labels.},
	publisher = {{arXiv}},
	author = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and {McKinnon}, Cameron and Chen, Carol and Olsson, Catherine and Olah, Christopher and Hernandez, Danny and Drain, Dawn and Ganguli, Deep and Li, Dustin and Tran-Johnson, Eli and Perez, Ethan and Kerr, Jamie and Mueller, Jared and Ladish, Jeffrey and Landau, Joshua and Ndousse, Kamal and Lukosuite, Kamile and Lovitt, Liane and Sellitto, Michael and Elhage, Nelson and Schiefer, Nicholas and Mercado, Noemi and {DasSarma}, Nova and Lasenby, Robert and Larson, Robin and Ringer, Sam and Johnston, Scott and Kravec, Shauna and Showk, Sheer El and Fort, Stanislav and Lanham, Tamera and Telleen-Lawton, Timothy and Conerly, Tom and Henighan, Tom and Hume, Tristan and Bowman, Samuel R. and Hatfield-Dodds, Zac and Mann, Ben and Amodei, Dario and Joseph, Nicholas and {McCandlish}, Sam and Brown, Tom and Kaplan, Jared},
	urldate = {2025-06-12},
	date = {2022},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), {FOS}: Computer and information sciences},
}

@article{klunover_contests_2020,
	title = {Contests with a constrained choice set of effort},
	volume = {196},
	issn = {0165-1765},
	url = {https://www.sciencedirect.com/science/article/pii/S0165176520303402},
	doi = {10.1016/j.econlet.2020.109559},
	abstract = {We consider a symmetric two-player contest, in which the choice set of effort is constrained. We apply a fundamental property of the payoff function to show that, under standard assumptions, there exists a unique Nash equilibrium in pure strategies. It is shown that all equilibria are near the unconstrained equilibrium. Perhaps surprisingly, this is not the case when players have different prize evaluations.},
	pages = {109559},
	journaltitle = {Economics Letters},
	shortjournal = {Economics Letters},
	author = {Klunover, Doron and Morgan, John},
	urldate = {2025-06-12},
	date = {2020-11-01},
	keywords = {Constrained choice set of effort, Contests},
}

@report{perla_conversations_2009,
	location = {Fort Belvoir, {VA}},
	title = {Conversations With Wargamers:},
	url = {http://www.dtic.mil/docs/citations/ADA494298},
	shorttitle = {Conversations With Wargamers},
	institution = {Defense Technical Information Center},
	author = {Perla, Peter P. and Markowitz, Michael C.},
	urldate = {2025-06-26},
	date = {2009-01-01},
	langid = {english},
	doi = {10.21236/ADA494298},
}

@article{xie_coopetition_2023,
	title = {Coopetition and organizational performance outcomes: A meta-analysis of the main and moderator effects},
	volume = {154},
	issn = {0148-2963},
	url = {https://www.sciencedirect.com/science/article/pii/S0148296322008281},
	doi = {10.1016/j.jbusres.2022.113363},
	shorttitle = {Coopetition and organizational performance outcomes},
	abstract = {Despite a large body of literature on coopetition, the extant findings on the performance outcomes of coopetition remain inconsistent and divergent. This meta-analysis aims to systematically examine the effect of coopetition on organizational performance and to identify the conditions when coopetition is particularly beneficial to organizational performance. Data were obtained from 49 primary studies involving 62,057 participants. Our results confirm that coopetition has a significantly positive impact on overall organizational performance. Specifically, coopetition is significantly positively related to financial, market, and innovation performance. Moreover, the coopetition–performance relationship is contingent on two environmental factors (i.e., national culture and industry type), one organizational relationship factor (i.e., coopetition structure), and two methodological factors (i.e., coopetition and performance measures). This study thus extends the coopetition literature by resolving the mixed findings regarding this relationship and emphasizing the fundamental significance of contingent factors.},
	pages = {113363},
	journaltitle = {Journal of Business Research},
	shortjournal = {Journal of Business Research},
	author = {Xie, Qiuhao and Gao, Ying and Xia, Nini and Zhang, Shuibo and Tao, Guowu},
	urldate = {2025-06-12},
	date = {2023-01-01},
	keywords = {Competition, Cooperation, Coopetition, Meta-analysis, Performance},
}

@article{bengtsson_coopetition_2016,
	title = {Coopetition research in theory and practice: Growing new theoretical, empirical, and methodological domains},
	volume = {57},
	issn = {0019-8501},
	url = {https://www.sciencedirect.com/science/article/pii/S0019850116300761},
	doi = {10.1016/j.indmarman.2016.05.002},
	shorttitle = {Coopetition research in theory and practice},
	abstract = {In this paper we discuss the theoretical rooting of present research on coopetition and point to the need for an integration of theories on competition dynamics, and cooperative interactions in social networks. We argue that the future growth of the coopetitive research field hinges on creatively combining existing theoretical approaches with novel research methods and contexts. In particular, we suggest that incorporating theories on the micro foundations of strategic action can substantially enhance the field. The aim of this paper is both to raise questions regarding the theory and practice of coopetition research and to give examples of new approaches and trends that may contribute to the advancement of the field in the future. We consider our research practice and explore avenues for further research starting from what, where and how we study coopetition, to when and who we study. In general, we call for a stronger focus on the centrality of multiple stakeholders in forming, executing, and developing coopetition, and on research methods that can investigate in depth the multitude of actors, interests, and interactions using a multi-level analysis, including the micro foundations of coopetition.},
	pages = {4--11},
	journaltitle = {Industrial Marketing Management},
	shortjournal = {Industrial Marketing Management},
	author = {Bengtsson, Maria and Kock, Sören and Lundgren-Henriksson, Eva-Lena and Näsholm, Malin H.},
	urldate = {2025-06-12},
	date = {2016-08-01},
	keywords = {Coopetition, Coopetition strategy, Emerging trends, Micro foundations, Theoretical rooting},
}

@article{czakon_coopetition_2020,
	title = {Coopetition strategies: Critical issues and research directions},
	volume = {53},
	issn = {0024-6301},
	url = {https://www.sciencedirect.com/science/article/pii/S0024630119304509},
	doi = {10.1016/j.lrp.2019.101948},
	series = {Coopetition Strategies},
	shorttitle = {Coopetition strategies},
	pages = {101948},
	number = {1},
	journaltitle = {Long Range Planning},
	shortjournal = {Long Range Planning},
	author = {Czakon, Wojciech and Srivastava, Manish K. and Le Roy, Frédéric and Gnyawali, Devi},
	urldate = {2025-06-12},
	date = {2020-02-01},
}

@article{rohrbeck_corporate_2018,
	title = {Corporate foresight and its impact on firm performance: A longitudinal analysis},
	volume = {129},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162517302287},
	doi = {10.1016/j.techfore.2017.12.013},
	shorttitle = {Corporate foresight and its impact on firm performance},
	abstract = {Corporate foresight is applied with the expectation that it will help firms to break away from path dependency, help decision makers to define superior courses of action, and ultimately enable superior firm performance. To empirically test this assumption, we developed a model that judges a firm's future preparedness ({FP}) by assessing the need for corporate foresight ({CF}) and comparing it to the maturity of its {CF} practices. We apply a longitudinal research design in which we measure future preparedness in 2008 and its impact on firm performance in 2015. The results indicated future preparedness to be a powerful predictor for becoming an outperformer in the industry, for attaining superior profitability, and for gaining superior market capitalization growth. In the article, we also calculate the average bonus/discount that can be expected by sufficiently/insufficiently future-prepared firms.},
	pages = {105--116},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Rohrbeck, René and Kum, Menes Etingue},
	urldate = {2025-06-12},
	date = {2018-04-01},
	keywords = {Behavioural theory of the firm, Corporate foresight, Firm performance, Future preparedness},
}

@misc{yu_cosafe_2024,
	title = {{CoSafe}: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference},
	url = {http://arxiv.org/abs/2406.17626},
	doi = {10.48550/arXiv.2406.17626},
	shorttitle = {{CoSafe}},
	abstract = {As large language models ({LLMs}) constantly evolve, ensuring their safety remains a critical research problem. Previous red-teaming approaches for {LLM} safety have primarily focused on single prompt attacks or goal hijacking. To the best of our knowledge, we are the first to study {LLM} safety in multi-turn dialogue coreference. We created a dataset of 1,400 questions across 14 categories, each featuring multi-turn coreference safety attacks. We then conducted detailed evaluations on five widely used open-source {LLMs}. The results indicated that under multi-turn coreference safety attacks, the highest attack success rate was 56\% with the {LLaMA}2-Chat-7b model, while the lowest was 13.9\% with the Mistral-7B-Instruct model. These findings highlight the safety vulnerabilities in {LLMs} during dialogue coreference interactions.},
	number = {{arXiv}:2406.17626},
	publisher = {{arXiv}},
	author = {Yu, Erxin and Li, Jing and Liao, Ming and Wang, Siqi and Gao, Zuchen and Mi, Fei and Hong, Lanqing},
	urldate = {2025-09-09},
	date = {2024-06-25},
	eprinttype = {arxiv},
	eprint = {2406.17626 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@report{levine_crisis_1991,
	title = {Crisis Games 27 Years Later: Plus C’est Deja Vu},
	url = {https://www.rand.org/pubs/papers/P7719.html},
	shorttitle = {Crisis Games 27 Years Later},
	abstract = {The paper is designed to make generally available observations and ideas about crisis gaming which continue to prove interesting to a new generation of gaming theorists.},
	author = {Levine, Robert A. and Schelling, Thomas C. and Jones, William M.},
	urldate = {2025-06-26},
	date = {1991-01-01},
	langid = {english},
	keywords = {Expert Insights},
}

@misc{gou_critic_2024,
	title = {{CRITIC}: Large Language Models Can Self-Correct with Tool-Interactive Critiquing},
	url = {http://arxiv.org/abs/2305.11738},
	doi = {10.48550/arXiv.2305.11738},
	shorttitle = {{CRITIC}},
	abstract = {Recent developments in large language models ({LLMs}) have been impressive. However, these models sometimes show inconsistencies and problematic behavior, such as hallucinating facts, generating flawed code, or creating offensive and toxic content. Unlike these models, humans typically utilize external tools to cross-check and refine their initial content, like using a search engine for fact-checking, or a code interpreter for debugging. Inspired by this observation, we introduce a framework called {CRITIC} that allows {LLMs}, which are essentially "black boxes" to validate and progressively amend their own outputs in a manner similar to human interaction with tools. More specifically, starting with an initial output, {CRITIC} interacts with appropriate tools to evaluate certain aspects of the text, and then revises the output based on the feedback obtained during this validation process. Comprehensive evaluations involving free-form question answering, mathematical program synthesis, and toxicity reduction demonstrate that {CRITIC} consistently enhances the performance of {LLMs}. Meanwhile, our research highlights the crucial importance of external feedback in promoting the ongoing self-improvement of {LLMs}.},
	number = {{arXiv}:2305.11738},
	publisher = {{arXiv}},
	author = {Gou, Zhibin and Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Yang, Yujiu and Duan, Nan and Chen, Weizhu},
	urldate = {2025-09-11},
	date = {2024-02-21},
	eprinttype = {arxiv},
	eprint = {2305.11738 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{resende_critical_2018,
	title = {Critical success factors in coopetition: Evidence on a business network},
	volume = {68},
	issn = {0019-8501},
	url = {https://www.sciencedirect.com/science/article/pii/S0019850117302390},
	doi = {10.1016/j.indmarman.2017.10.013},
	shorttitle = {Critical success factors in coopetition},
	abstract = {Coopetition in the literature of business networks has been discussed as a base strategy to potentiate competitiveness. This research investigates the main inter-relationship factors among the companies that are part of a network involving cooperation and competition, as well as their relationship in coopetition. This research discusses these questions through a review of the literature on coopetition and its application in business networks, basing the analysis on the critical success factors ({CSF}). Our analysis is conducted in the gastronomic industry, obtaining results through an exploratory investigation, conducted by applying the model suggested by Petter (2014) in a business network, attesting the means of the critical success factors and their correlations on the suggested dimensions and on coopetition. The main results for the critical success factors in coopetition indicate the importance of governance to maintain business networks, of cooperation to leverage innovative competencies, and that companies that have lower competencies regarding financial resources are more engaged in cooperation.},
	pages = {177--187},
	journaltitle = {Industrial Marketing Management},
	shortjournal = {Industrial Marketing Management},
	author = {Resende, Luis Maurício Martins de and Volski, Isabela and Betim, Leozenir Mendes and Carvalho, Gustavo Dambiski Gomes de and Barros, Rodrigo de and Senger, Fabio Pietrobelli},
	urldate = {2025-06-12},
	date = {2018-01-01},
	keywords = {Coopetition, Critical success factors, Network enterprises},
}

@incollection{mcalaney_cybersecurity_2020,
	title = {Cybersecurity as a social phenomenon},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-819204-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128192047000014},
	pages = {1--8},
	booktitle = {Cyber Influence and Cognitive Threats},
	publisher = {Elsevier},
	author = {{McAlaney}, John and Benson, Vladlena},
	urldate = {2025-08-06},
	date = {2020},
	langid = {english},
	doi = {10.1016/B978-0-12-819204-7.00001-4},
}

@article{hart_dante_2021,
	title = {Dante Agent Architecture for Force-On-Force Wargame Simulation and Training},
	volume = {13},
	issn = {2334-0924, 2326-909X},
	url = {https://ojs.aaai.org/index.php/AIIDE/article/view/12953},
	doi = {10.1609/aiide.v13i1.12953},
	abstract = {Physical site security heavily relies on expert teams continually examining and testing security profiles for discovering potential vulnerabilities.  These experts hypothesize scenario(s) of interest and conduct “red versus blue” simulated exercises where they execute tactics that might reveal possible dangers.   Due to the intensive manpower required, video-game environments have become a widely-adopted mechanism for conducting these exercises with virtual agents replacing many of the human roles for quicker analyses.  However, these agents either have limited capabilities or require several engineers to develop realistic behaviors.  This paper documents an agent architecture and authoring suite that enables subject matter experts to easily build complex attack/response plans for agents to use within Dante, a 3D simulation platform for video-game-based training/analysis of force-on-force engagements.  This work expands upon current trends in commercial video-game artificial intelligence ({AI}) architectures to build agent behaviors deemed qualitatively valid by security experts, with the runtime of these algorithms best suited for turn-based, strategy games.},
	pages = {200--206},
	number = {1},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence and Interactive Digital Entertainment},
	shortjournal = {{AIIDE}},
	author = {Hart, Brian and Hart, Derek and Gayle, Russell and Oppel, Fred and Xavier, Patrick and Whetzel, Jonathan},
	urldate = {2025-09-08},
	date = {2021-06-25},
}

@article{wu_data_2024,
	title = {Data analysis of tactical wargaming based on data mining},
	volume = {24},
	issn = {14727978, 18758983},
	url = {https://journals.sagepub.com/doi/full/10.3233/JCM-237083},
	doi = {10.3233/JCM-237083},
	abstract = {In order to effectively solve the problem of acquiring knowledge from tactical wargaming data, an overall analysis framework is designed based on the standard process of data mining. The data is analyzed from four aspects: time, space, maneuver path and multi-operator behavior correlation. The behavioral characteristics of single operators at different stages and the spatial distribution of key points such as shooting points, hit points and hidden points, and the association rules of movement, shooting, and occupation between multiple operators are obtained. This will provide commanders with experience and knowledge, help them to quickly accumulate combat experience, and provide behavior rules and action modes for the development of wargaming {AI}, effectively improving its intelligent level.},
	pages = {343--356},
	number = {1},
	journaltitle = {Journal of Computational Methods in Sciences and Engineering},
	shortjournal = {{JCM}},
	author = {Wu, Liu},
	urldate = {2025-09-08},
	date = {2024-03-14},
}

@misc{wang_debt_2025,
	title = {Debt Collection Negotiations with Large Language Models: An Evaluation System and Optimizing Decision Making with Multi-Agent},
	url = {http://arxiv.org/abs/2502.18228},
	doi = {10.48550/arXiv.2502.18228},
	shorttitle = {Debt Collection Negotiations with Large Language Models},
	abstract = {Debt collection negotiations ({DCN}) are vital for managing non-performing loans ({NPLs}) and reducing creditor losses. Traditional methods are labor-intensive, while large language models ({LLMs}) offer promising automation potential. However, prior systems lacked dynamic negotiation and real-time decision-making capabilities. This paper explores {LLMs} in automating {DCN} and proposes a novel evaluation framework with 13 metrics across 4 aspects. Our experiments reveal that {LLMs} tend to over-concede compared to human negotiators. To address this, we propose the Multi-Agent Debt Negotiation ({MADeN}) framework, incorporating planning and judging modules to improve decision rationality. We also apply post-training techniques, including {DPO} with rejection sampling, to optimize performance. Our studies provide valuable insights for practitioners and researchers seeking to enhance efficiency and outcomes in this domain.},
	number = {{arXiv}:2502.18228},
	publisher = {{arXiv}},
	author = {Wang, Xiaofeng and Zhang, Zhixin and Zheng, Jinguang and Ai, Yiming and Wang, Rui},
	urldate = {2025-09-13},
	date = {2025-02-25},
	eprinttype = {arxiv},
	eprint = {2502.18228 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@unpublished{hagendorff_deception_2023,
	title = {Deception abilities emerged in large language models},
	url = {http://arxiv.org/abs/2307.16513},
	abstract = {Large language models ({LLMs}) are currently at the forefront of
intertwining artificial intelligence ({AI}) systems with human communication
and everyday life. Thus, aligning them with human values is of great
importance. However, given the steady increase in reasoning abilities,
future {LLMs} are under suspicion of becoming able to deceive human
operators and utilizing this ability to bypass monitoring efforts. As a
prerequisite to this, {LLMs} need to possess a conceptual understanding of
deception strategies. This study reveals that such strategies emerged in
state-of-the-art {LLMs}, such as {GPT}-4, but were non-existent in earlier
{LLMs}. We conduct a series of experiments showing that state-of-the-art
{LLMs} are able to understand and induce false beliefs in other agents, that
their performance in complex deception scenarios can be amplified
utilizing chain-of-thought reasoning, and that eliciting Machiavellianism
in {LLMs} can alter their propensity to deceive. In sum, revealing hitherto
unknown machine behavior in {LLMs}, our study contributes to the nascent
field of machine psychology.},
	author = {Hagendorff, Thilo},
	date = {2023-07-31},
	note = {{ISBN}: 2307.16513
Publication Title: {arXiv} [cs.{CL}]},
}

@article{alder_deceptive_2016,
	title = {Deceptive redistribution},
	volume = {22},
	issn = {1094-2025},
	url = {https://www.sciencedirect.com/science/article/pii/S1094202516300254},
	doi = {10.1016/j.red.2016.08.003},
	abstract = {While some policies can enhance welfare, occasionally they may also provide rents to politicians. Opportunism is usually constrained by the policymakers' reputation concerns. However, if instances of rent-seeking are not easily identified, the strength of these concerns hinges on the informed constituents' ability to share their knowledge with the rest of society. We show that governments use excessive redistribution to discourage the communication of information. In contrast to the standard view that inefficient policies are necessary to implement redistribution, we argue that redistribution can perpetuate inefficient policies that generate private rents to politicians.},
	pages = {223--239},
	journaltitle = {Review of Economic Dynamics},
	shortjournal = {Review of Economic Dynamics},
	author = {Alder, Simeon D. and Ordoñez, Guillermo L.},
	urldate = {2025-06-12},
	date = {2016-10-01},
	keywords = {Election, Media, Private information, Redistribution, Rent-seeking, Reputation},
}

@article{scherpereel_decision_2005,
	title = {Decision Making in Business Simulation Design},
	volume = {32},
	rights = {Copyright (c) 2017 Developments in Business Simulation and Experiential Learning},
	url = {https://absel-ojs-ttu.tdl.org/absel/article/view/592},
	abstract = {To develop effective business simulation exercises it is critical that developers and users understand the human decision-making process so that simulations achieve the desired learning objectives. Understanding how to present the situation and define the environment is central to creating a learning exercise where decision makers can improve their decision-making performance. It is an important pedagogical issue to know whether the business simulation is being designed to reinforce and build a decision maker’s ability to respond in a normative reasoned fashion to a decision problem, or to experience the situation in its complexity and respond in a synthetic intuitive fashion. To comprehend the implications of these two viewpoints the debate between promoters of the normative view on decision making and the descriptive view on decision making are presented. A critical analysis of these different perspectives is shown to influence how decision making should be taught, how simulations should be designed, and how learning outcomes should be measured.},
	journaltitle = {Developments in Business Simulation and Experiential Learning},
	author = {Scherpereel, Christopher M.},
	urldate = {2025-06-12},
	date = {2005},
	langid = {english},
}

@article{ming_decision-making_2016,
	title = {Decision-making model of generation technology under uncertainty based on real option theory},
	volume = {110},
	issn = {0196-8904},
	url = {https://www.sciencedirect.com/science/article/pii/S0196890415010936},
	doi = {10.1016/j.enconman.2015.12.005},
	abstract = {The introduction of market competition and the increased uncertainty factors makes the generators have to decide not only on whether to invest generation capacity or not but also on what kind of generation technology to choose. In this paper, a decision-making model of generation technology investment is proposed. The irreversible investment concept and real option theory is introduced as the fundamental of the model. In order to explain the decision-making process of generator’s investment, the decision-making optimization model was built considering two generation technologies, i.e., the heat-only system and the combined heat and power generation. Also, we discussed the theory deducing process, which explained how to eliminate the overrated economic potential caused by risk hazard, based on economic evaluation of both generation technologies. Finally, practical data from electricity market of Inner Mongolia was used to prove the validity of the model and the impact of uncertainties of electricity and fuel price fluctuation on investment was analyzed according to the simulated results.},
	pages = {59--66},
	journaltitle = {Energy Conversion and Management},
	shortjournal = {Energy Conversion and Management},
	author = {Ming, Zeng and Ping, Zhang and Shunkun, Yu and Ge, Zhang},
	urldate = {2025-06-12},
	date = {2016-02-15},
	keywords = {Decision-making model, Generation technology, Irreversible investment, Real option theory},
}

@article{bowden_deepening_2021,
	title = {Deepening futures methods to face the civilisational crisis},
	volume = {132},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328721000926},
	doi = {10.1016/j.futures.2021.102783},
	abstract = {Richard Slaughter has argued for many years that we face a ‘civilisational crisis’, particularly in the context of climate change and the environment. Slaughter felt that traditional futures methods were too superficial and lacking in depth to address the civilisational challenge ahead of us. He provided frameworks and concepts to deepen futures methods and strategies and to build social foresight capacity. His significant practical contribution was the establishment of the Australian Foresight Institute and postgraduate studies at Swinburne University of Technology in Melbourne. It is suggested that the foresight field in Australia needs to reestablish supportive structures such as these and take steps to obtain social and professional legitimation in order to promote an advanced futures discourse to take us toward better futures.},
	pages = {102783},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Bowden, Meredith},
	urldate = {2025-06-12},
	date = {2021-09-01},
	keywords = {Foresight, Futures, Methods, Professionalisation},
}

@misc{duffy_democratizing_2025,
	title = {Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy},
	url = {http://arxiv.org/abs/2508.07485},
	doi = {10.48550/arXiv.2508.07485},
	shorttitle = {Democratizing Diplomacy},
	abstract = {We present the first evaluation harness that enables any out-of-the-box, local, Large Language Models ({LLMs}) to play full-press Diplomacy without fine-tuning or specialized training. Previous work required frontier {LLMs}, or fine-tuning, due to the high complexity and information density of Diplomacy's game state. Combined with the high variance of matches, these factors made Diplomacy prohibitive for study. In this work, we used data-driven iteration to optimize a textual game state representation such that a 24B model can reliably complete matches without any fine tuning. We develop tooling to facilitate hypothesis testing and statistical analysis, and we present case studies on persuasion, aggressive playstyles, and performance across a range of models. We conduct a variety of experiments across many popular {LLMs}, finding the larger models perform the best, but the smaller models still play adequately. We also introduce Critical State Analysis: an experimental protocol for rapidly iterating and analyzing key moments in a game at depth. Our harness democratizes the evaluation of strategic reasoning in {LLMs} by eliminating the need for fine-tuning, and it provides insights into how these capabilities emerge naturally from widely used {LLMs}. Our code is available in the supplement and will be open sourced.},
	number = {{arXiv}:2508.07485},
	publisher = {{arXiv}},
	author = {Duffy, Alexander and Paech, Samuel J. and Shastri, Ishana and Karpinski, Elizabeth and Alloui-Cros, Baptiste and Marques, Tyler and Olson, Matthew Lyle},
	urldate = {2025-09-13},
	date = {2025-08-10},
	eprinttype = {arxiv},
	eprint = {2508.07485 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Machine Learning},
}

@misc{bondarenko_demonstrating_2025,
	title = {Demonstrating specification gaming in reasoning models},
	url = {http://arxiv.org/abs/2502.13295},
	doi = {10.48550/arXiv.2502.13295},
	abstract = {We demonstrate {LLM} agent specification gaming by instructing models to win against a chess engine. We find reasoning models like {OpenAI} o3 and {DeepSeek} R1 will often hack the benchmark by default, while language models like {GPT}-4o and Claude 3.5 Sonnet need to be told that normal play won't work to hack. We improve upon prior work like (Hubinger et al., 2024; Meinke et al., 2024; Weij et al., 2024) by using realistic task prompts and avoiding excess nudging. Our results suggest reasoning models may resort to hacking to solve difficult problems, as observed in {OpenAI} (2024)'s o1 Docker escape during cyber capabilities testing.},
	number = {{arXiv}:2502.13295},
	publisher = {{arXiv}},
	author = {Bondarenko, Alexander and Volk, Denis and Volkov, Dmitrii and Ladish, Jeffrey},
	urldate = {2025-06-12},
	date = {2025-05-15},
	eprinttype = {arxiv},
	eprint = {2502.13295 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{de_rosa_design_2021,
	title = {Design methodology of analytical games for knowledge acquisition},
	volume = {8},
	rights = {http://creativecommons.org/licenses/by-nc-nd/4.0},
	issn = {2384-8766},
	url = {http://journal.seriousgamessociety.org/index.php/IJSG/article/view/456},
	doi = {10.17083/ijsg.v8i4.456},
	abstract = {Analytical games explore a problem or a domain with a research purpose. Considerable research is ongoing to investigate improvements to analytical game design, execution and exploitation. Moreover, the fast-paced technological developments in many fields, such as artificial intelligence and virtual reality, make it even more compellingto account for the advantages and limitations of these new capabilities. In game design, the use of digital means is often regarded as a mere technical factor that relates to the platform selection, facilitator support and data recording processes. In this work a shift in perspective is proposed, to move from technology-oriented design selection criteria towards a broader assessment of the design choices. In fact, the introductionof technology (i.e., automation and autonomy) will not lead to a substitution of tasks, but will intrinsically change the game environment. This work introduces a framework to provide a structured guidance on the aspects to be factored in the different design phases of an analytical game, including the potential impact of the adoption of automation and autonomy. The proposed approach is based on previous research in the fieldof simulation-based serious gaming, model-driven engineering and human factors engineering. The framework is applied to Knowledge Acquisition Analytical Games as a case study.},
	pages = {3--23},
	number = {4},
	journaltitle = {International Journal of Serious Games},
	shortjournal = {{IJSG}},
	author = {De Rosa, Francesca and De Gloria, Alessandro},
	urldate = {2025-09-08},
	date = {2021-12-01},
}

@report{worman_designing_2023,
	title = {Designing A Strange Game: A Nuclear Wargame for the 21st Century},
	url = {https://www.rand.org/pubs/research_reports/RRA1204-1.html},
	abstract = {60 pages},
	number = {{RR}-A1204-1},
	institution = {{RAND} Corporation},
	author = {Worman, Stephen M. and Frelinger, David R. and Shlapak, David A. and Pfrommer, Katherine and Eusebi, Kelly Elizabeth and Oberholtzer, Jenny},
	editorb = {{RAND Corporation}},
	editorbtype = {redactor},
	date = {2023},
	doi = {10.7249/RRA1204-1},
}

@incollection{druckman_designing_2005,
	location = {2455 Teller Road, Thousand Oaks California 91320 United States of America},
	title = {Designing Experiments and Conducting Simulations},
	isbn = {978-0-7619-2779-2 978-1-4129-8396-9},
	url = {https://methods.sagepub.com/book/doing-research},
	booktitle = {Doing Research},
	publisher = {{SAGE} Publications, Inc.},
	author = {Druckman, Daniel},
	urldate = {2025-06-25},
	date = {2005},
	langid = {english},
	doi = {10.4135/9781412983969},
}

@article{walton_developing_2019,
	title = {Developing a theory of plausibility in scenario building: Designing plausible scenarios},
	volume = {111},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328718300892},
	doi = {10.1016/j.futures.2019.03.002},
	shorttitle = {Developing a theory of plausibility in scenario building},
	abstract = {Scenario planning is used by organizations and institutions to help understand futures, expand imaginations and to sensitize for changing business environments. The scenario planning process can help deal with uncertainties in an increasingly dynamic environment, particularly if they are perceived as plausible. To explore the practicalities of developing plausible scenarios we utilised a case study, and involved key stakeholders, to investigate the ‘Future of Work’ in Dunedin, Aotearoa, New Zealand. Using sensemaking analysis we show how participants utilized their individual frames of reference to interpret how plausible the scenarios were, while also constructing cues to prospectively ‘make sense’. Therefore, we contribute both to understanding how to build plausibility into scenario planning and how participants make sense of future scenarios. We propose a model, based on the sensemaking concepts of frames and cues, that supports the construction of plausible scenarios. We conclude that designing plausible scenarios, as a prospective sensemaking device, is a powerful way to encourage discussion about futures and to understand the consequences of today's activities on tomorrow's realities. Understanding how to design scenarios that are perceived as plausible from a stakeholder's perspective is crucial for building understandings of future events.},
	pages = {42--56},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Walton, Sara and O’Kane, Paula and Ruwhiu, Diane},
	urldate = {2025-06-12},
	date = {2019-08-01},
	keywords = {Business environment, Future of work, Plausibility, Prospective sensemaking, Scenarios, Sensemaking},
}

@article{boron_developing_2020,
	title = {Developing Combat Behavior through Reinforcement Learning in Wargames and Simulations},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{USG}.html},
	url = {https://ieeexplore.ieee.org/document/9231609/},
	doi = {10.1109/CoG47356.2020.9231609},
	abstract = {Progress in artificial intelligence ({AI}), particularly deep reinforcement learning ({RL}), has produced systems capable of performing at or above a professional-human level. This research explored the ability of {RL} to train {AI} agents to achieve optimal offensive behavior in small tactical engagements. Agents were trained in a simple, aggregate-level military constructive simulation with behaviors validated with the tactical principles of mass and economy of force. Results showed the combat model and {RL} algorithm applied had the largest impact on training performance. Additionally, specific training hyper-parameters also contributed to the quality and type of observed behaviors. Future work will seek to validate {RL} performance in larger and more complex combat scenarios.},
	pages = {728--731},
	journaltitle = {2020 {IEEE} Conference on Games ({CoG})},
	author = {Boron, Jonathan and Darken, Chris},
	urldate = {2025-09-13},
	date = {2020-08},
	note = {Conference Name: 2020 {IEEE} Conference on Games ({CoG})
{ISBN}: 9781728145334
Place: Osaka, Japan
Publisher: {IEEE}},
}

@article{puri_digital_2024,
	title = {Digital cloning of online social networks for language-sensitive agent-based modeling of misinformation spread},
	volume = {19},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0304889},
	doi = {10.1371/journal.pone.0304889},
	abstract = {We develop a simulation framework for studying misinformation spread within online social networks that blends agent-based modeling and natural language processing techniques. While many other agent-based simulations exist in this space, questions over their fidelity and generalization to existing networks in part hinder their ability to drive policy-relevant decision making. To partially address these concerns, we create a ’digital clone’ of a known misinformation sharing network by downloading social media histories for over ten thousand of its users. We parse these histories to both extract the structure of the network and model the nuanced ways in which information is shared and spread among its members. Unlike many other agent-based methods in this space, information sharing between users in our framework is sensitive to topic of discussion, user preferences, and online community dynamics. To evaluate the fidelity of our method, we seed our cloned network with a set of posts recorded in the base network and compare propagation dynamics between the two, observing reasonable agreement across the twin networks over a variety of metrics. Lastly, we explore how the cloned network may serve as a flexible, low-cost testbed for misinformation countermeasure evaluation and red teaming analysis. We hope the tools explored here augment existing efforts in the space and unlock new opportunities for misinformation countermeasure evaluation, a field that may become increasingly important to consider with the anticipated rise of misinformation campaigns fueled by generative artificial intelligence.},
	pages = {e0304889},
	number = {6},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLoS} {ONE}},
	author = {Puri, Prateek and Hassler, Gabriel and Katragadda, Sai and Shenk, Anton},
	editor = {Cinelli, Matteo},
	urldate = {2025-09-08},
	date = {2024-06-21},
	langid = {english},
}

@incollection{neave_digital_2020,
	title = {Digital hoarding behaviours},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-819204-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128192047000051},
	pages = {77--95},
	booktitle = {Cyber Influence and Cognitive Threats},
	publisher = {Elsevier},
	author = {Neave, Nick and {McKellar}, Kerry and Sillence, Elizabeth and Briggs, Pam},
	urldate = {2025-08-06},
	date = {2020},
	langid = {english},
	doi = {10.1016/B978-0-12-819204-7.00005-1},
}

@misc{wang_digital_2025,
	title = {Digital Player: Evaluating Large Language Models based Human-like Agent in Games},
	url = {http://arxiv.org/abs/2502.20807},
	doi = {10.48550/arXiv.2502.20807},
	shorttitle = {Digital Player},
	abstract = {With the rapid advancement of Large Language Models ({LLMs}), {LLM}-based autonomous agents have shown the potential to function as digital employees, such as digital analysts, teachers, and programmers. In this paper, we develop an application-level testbed based on the open-source strategy game "Unciv", which has millions of active players, to enable researchers to build a "data flywheel" for studying human-like agents in the "digital players" task. This "Civilization"-like game features expansive decision-making spaces along with rich linguistic interactions such as diplomatic negotiations and acts of deception, posing significant challenges for {LLM}-based agents in terms of numerical reasoning and long-term planning. Another challenge for "digital players" is to generate human-like responses for social interaction, collaboration, and negotiation with human players. The open-source project can be found at https:/github.com/{fuxiAIlab}/{CivAgent}.},
	number = {{arXiv}:2502.20807},
	publisher = {{arXiv}},
	author = {Wang, Jiawei and Wang, Kai and Lin, Shaojie and Wu, Runze and Xu, Bihan and Jiang, Lingeng and Zhao, Shiwei and Zhu, Renyu and Liu, Haoyu and Hu, Zhipeng and Fan, Zhong and Li, Le and Lyu, Tangjie and Fan, Changjie},
	urldate = {2025-09-09},
	date = {2025-02-28},
	eprinttype = {arxiv},
	eprint = {2502.20807 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{stanzel_diplomacy_2022,
	title = {Diplomacy and Artificial Intelligence. Reflections on Practical Assistance for Diplomatic Negotiations},
	url = {https://www.semanticscholar.org/paper/835cfccb57c1549f9f1b8729f1a96257ea6c022e},
	abstract = {∎ {AI} holds the promise of being able to analyse large amounts of data
faster and more reliably than humans can. So is it also possible to use {AI}
systems to analyse information relevant to diplomatic negotiations in a
way that adds significant strategic value? ∎ We explore this question
through two exploratory case studies. The first examines the negotiations
for a German-Austrian customs union in 1929/30. Here we show how {AI}
systems could be used to develop a spectrum of possible scenarios in an
automated way for the purposes of strategy formation. ∎ The second case
study looks at the negotiations on the so-called “cybercrime” resolution
within the framework of the United Nations ({UN}). In cooperation with the
Federal Foreign Office ({AA}), the study investigates whether and in what
form {AI} systems allow the behaviour of states in the {UN} General Assembly
to be predicted. ∎ Based on the two case studies, we take a systematic
look at further possibilities for using {AI} as a tool for diplomacy, for
example, in the automated monitoring of public media around a negotiation
process. ∎ Today, {AI} is still often prone to error and will foreseeably
not be able to replace the judgement of experienced diplomats. As a
supporting tool, however, {AI} has the potential to make an indispensable
contribution to the preparation and conduct of diplomatic negotiations. ∎
German foreign policy should create the conditions to further explore the
potential of {AI} and other methods of data analysis for the purposes of
diplomatic negotiations, develop a “foreign policy data strategy” and draw
up normative guidelines for the use of {AI} in the context of diplomacy.},
	author = {Stanzel, Volker and Voelsen, Daniel},
	urldate = {2023-11-15},
	date = {2022},
}

@article{maass_diplosim_2023,
	title = {{DiploSim}: A Flexible Framework for Diplomatic Simulations in International Relations},
	volume = {24},
	rights = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
	issn = {1528-3577, 1528-3585},
	url = {https://academic.oup.com/isp/article/24/1/20/6541348},
	doi = {10.1093/isp/ekab020},
	shorttitle = {{DiploSim}},
	abstract = {Abstract
            Although educators increasingly appreciate the pedagogical benefits of active learning techniques including simulations, many still see implementing them in their own classroom as a daunting task. The formidable time investment required often deters instructors from designing new simulations, and many find published simulations to be an imperfect fit. This article seeks to reduce the barriers to entry for instructors who are interested in designing personalized simulations yet hesitant in the face of real-world constraints. It does so by introducing a flexible framework for diplomatic simulations ({DiploSim}) that is firmly rooted in the design principles of drama, immersion, and reflection yet also easily customizable to fit instructors’ preferred thematic content, negotiating format, schedule, and class size. By combining research and role play within a straightforward and pedagogically sound structure, {DiploSim} offers instructors a useful gateway into the world of simulations.},
	pages = {20--38},
	number = {1},
	journaltitle = {International Studies Perspectives},
	author = {Maass, Richard W},
	urldate = {2025-09-08},
	date = {2023-01-23},
	langid = {english},
}

@misc{zahavy_diversifying_2024,
	title = {Diversifying {AI}: Towards Creative Chess with {AlphaZero}},
	url = {http://arxiv.org/abs/2308.09175},
	doi = {10.48550/arXiv.2308.09175},
	shorttitle = {Diversifying {AI}},
	abstract = {In recent years, Artificial Intelligence ({AI}) systems have surpassed human intelligence in a variety of computational tasks. However, {AI} systems, like humans, make mistakes, have blind spots, hallucinate, and struggle to generalize to new situations. This work explores whether {AI} can benefit from creative decision-making mechanisms when pushed to the limits of its computational rationality. In particular, we investigate whether a team of diverse {AI} systems can outperform a single {AI} in challenging tasks by generating more ideas as a group and then selecting the best ones. We study this question in the game of chess, the so-called drosophila of {AI}. We build on {AlphaZero} ({AZ}) and extend it to represent a league of agents via a latent-conditioned architecture, which we call {AZ}\_db. We train {AZ}\_db to generate a wider range of ideas using behavioral diversity techniques and select the most promising ones with sub-additive planning. Our experiments suggest that {AZ}\_db plays chess in diverse ways, solves more puzzles as a group and outperforms a more homogeneous team. Notably, {AZ}\_db solves twice as many challenging puzzles as {AZ}, including the challenging Penrose positions. When playing chess from different openings, we notice that players in {AZ}\_db specialize in different openings, and that selecting a player for each opening using sub-additive planning results in a 50 Elo improvement over {AZ}. Our findings suggest that diversity bonuses emerge in teams of {AI} agents, just as they do in teams of humans and that diversity is a valuable asset in solving computationally hard problems.},
	number = {{arXiv}:2308.09175},
	publisher = {{arXiv}},
	author = {Zahavy, Tom and Veeriah, Vivek and Hou, Shaobo and Waugh, Kevin and Lai, Matthew and Leurent, Edouard and Tomasev, Nenad and Schut, Lisa and Hassabis, Demis and Singh, Satinder},
	urldate = {2025-09-12},
	date = {2024-07-31},
	eprinttype = {arxiv},
	eprint = {2308.09175 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{lorscheid_divide_2016,
	title = {Divide and conquer: Configuring submodels for valid and efficient analyses of complex simulation models},
	volume = {326},
	issn = {0304-3800},
	url = {https://www.sciencedirect.com/science/article/pii/S0304380015005451},
	doi = {10.1016/j.ecolmodel.2015.11.013},
	series = {Next generation ecological modelling, concepts, and theory: structural realism, emergence, and predictions},
	shorttitle = {Divide and conquer},
	abstract = {Individual-based modeling is considered an important tool in ecology and other disciplines. A major challenge of individual-based modeling is that it addresses complex systems that include a large number of entities, hierarchical levels, and processes. To represent these, individual-based models ({IBMs}) usually comprise a large number of submodels. These submodels might be complex by themselves and interact with each other in many ways, which in turn can affect the overall system behavior in ways that are not always easy to understand. As a result, both the validity and credibility of {IBMs} can be limited. We here demonstrate how a cascaded design of simulation experiments ({cDOE}) may support the validity and efficiency of the analysis of {IBMs} and other ecological simulation models. We take a systematic approach that adopts a divide-and-conquer strategy. In a preparatory phase, submodels and their parameters are configured in “subexperiments”. Consequently, the “top-level experiments” of the simulation model can assess the research questions in a more valid and efficient way. Our strategy thus supports the structural realism of individual-based models because both the behavior of their main components and the relationships between these components are explicitly addressed.},
	pages = {152--161},
	journaltitle = {Ecological Modelling},
	shortjournal = {Ecological Modelling},
	author = {Lorscheid, Iris and Meyer, Matthias},
	urldate = {2025-06-12},
	date = {2016-04-24},
	keywords = {Computational modeling, Design of experiments, Ecological theory, Model analysis, Sensitivity analysis, Validation},
}

@article{raza-ullah_trust_2020,
	title = {Do trust and distrust in coopetition matter to performance?},
	volume = {38},
	issn = {0263-2373},
	url = {https://www.sciencedirect.com/science/article/pii/S0263237319301276},
	doi = {10.1016/j.emj.2019.10.004},
	abstract = {It is widely acknowledged that firms intensely engage in coopetition (i.e., simultaneous cooperation and competition) and obtain unique benefits from such relationships. However, limited knowledge exists about how and when coopetition intensity leads to superior performance. Building on the theoretical work documenting that both trust and distrust are critical for enhancing performance in interfirm relationships, we address the aforementioned gap by looking into the distinct yet beneficial roles of trust and distrust in coopetition. More specifically, we argue that whereas trust likely serves as an intervening mechanism through which coopetition intensity enhances relationship performance, distrust positively influences the association between coopetition intensity and relationship performance. We test our hypotheses on a sample of 225 Swedish firms engaged in coopetition, and provide empirical evidence that trust and distrust play distinct yet important roles in achieving superior performance from coopetition.},
	pages = {367--376},
	number = {3},
	journaltitle = {European Management Journal},
	shortjournal = {European Management Journal},
	author = {Raza-Ullah, Tatbeeq and Kostis, Angelos},
	urldate = {2025-06-12},
	date = {2020-06-01},
	keywords = {Coopetition, Distrust, Performance, Trust},
}

@unpublished{chu_domaino1s_2025,
	title = {Domaino1s: Guiding {LLM} reasoning for explainable answers in high-stakes domains},
	url = {https://www.semanticscholar.org/paper/03b60c70d90d4ed48e3dd4b0cb4e48e769579535},
	abstract = {Large Language Models ({LLMs}) are widely applied to downstream domains.
However, current {LLMs} for high-stakes domain tasks, such as financial
investment and legal {QA}, typically generate brief answers without
reasoning processes and explanations. This limits users' confidence in
making decisions based on their responses. While original {CoT} shows
promise, it lacks self-correction mechanisms during reasoning. This work
introduces Domain\$o1\$s, which enhances {LLMs}' reasoning capabilities on
domain tasks through supervised fine-tuning and tree search. We construct
{CoT}-stock-2k and {CoT}-legal-2k datasets for fine-tuning models that
activate domain-specific reasoning steps based on their judgment.
Additionally, we propose Selective Tree Exploration to spontaneously
explore solution spaces and sample optimal reasoning paths to improve
performance. We also introduce {PROOF}-Score, a new metric for evaluating
domain models' explainability, complementing traditional accuracy metrics
with richer assessment dimensions. Extensive experiments on stock
investment recommendation and legal reasoning {QA} tasks demonstrate
Domaino1s's leading performance and explainability. Our code is available
at https://anonymous.4open.science/r/Domaino1s-006F/.},
	author = {Chu, Xu and Tan, Zhijie and Xue, Hanlin and Wang, Guanyu and Mo, Tong and Li, Weiping},
	urldate = {2025-05-20},
	date = {2025-01-24},
	doi = {10.48550/arXiv.2501.14431},
	note = {{ISBN}: 2501.14431
Publication Title: {arXiv} [cs.{CL}]},
}

@inproceedings{yu_ds-ppo_2024,
	location = {Chengdu, China},
	title = {{DS}-{PPO}: A Reinforcement Learning Method for Wargaming},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3315-0707-7},
	url = {https://ieeexplore.ieee.org/document/10942113/},
	doi = {10.1109/ICCC62609.2024.10942113},
	shorttitle = {{DS}-{PPO}},
	eventtitle = {2024 10th International Conference on Computer and Communications ({ICCC})},
	pages = {111--115},
	booktitle = {2024 10th International Conference on Computer and Communications ({ICCC})},
	publisher = {{IEEE}},
	author = {Yu, Bo and Li, Shun and Wang, Wei and Liu, Dongying and Meng, Yuanze},
	urldate = {2025-09-08},
	date = {2024-12-13},
}

@misc{tang_dsgbench_2025,
	title = {{DSGBench}: A Diverse Strategic Game Benchmark for Evaluating {LLM}-based Agents in Complex Decision-Making Environments},
	url = {http://arxiv.org/abs/2503.06047},
	doi = {10.48550/arXiv.2503.06047},
	shorttitle = {{DSGBench}},
	abstract = {Large Language Model{\textasciitilde}({LLM}) based agents have been increasingly popular in solving complex and dynamic tasks, which requires proper evaluation systems to assess their capabilities. Nevertheless, existing benchmarks usually either focus on single-objective tasks or use overly broad assessing metrics, failing to provide a comprehensive inspection of the actual capabilities of {LLM}-based agents in complicated decision-making tasks. To address these issues, we introduce {DSGBench}, a more rigorous evaluation platform for strategic decision-making. Firstly, it incorporates six complex strategic games which serve as ideal testbeds due to their long-term and multi-dimensional decision-making demands and flexibility in customizing tasks of various difficulty levels or multiple targets. Secondly, {DSGBench} employs a fine-grained evaluation scoring system which examines the decision-making capabilities by looking into the performance in five specific dimensions and offering a comprehensive assessment in a well-designed way. Furthermore, {DSGBench} also incorporates an automated decision-tracking mechanism which enables in-depth analysis of agent behaviour patterns and the changes in their strategies. We demonstrate the advances of {DSGBench} by applying it to multiple popular {LLM}-based agents and our results suggest that {DSGBench} provides valuable insights in choosing {LLM}-based agents as well as improving their future development. {DSGBench} is available at https://github.com/{DeciBrain}-Group/{DSGBench}.},
	number = {{arXiv}:2503.06047},
	publisher = {{arXiv}},
	author = {Tang, Wenjie and Zhou, Yuan and Xu, Erqiang and Cheng, Keyan and Li, Minne and Xiao, Liquan},
	urldate = {2025-09-09},
	date = {2025-03-08},
	eprinttype = {arxiv},
	eprint = {2503.06047 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{callison-burch_dungeons_2022,
	title = {Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence},
	url = {http://arxiv.org/abs/2210.07109},
	doi = {10.18653/v1/2022.emnlp-main.637},
	abstract = {{AI} researchers have posited Dungeons and Dragons (D\&D) as a challenge problem to test systems on various language-related capabilities. In this paper, we frame D\&D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history. We create a gameplay dataset consisting of nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns, 500,000 dice rolls, and 58 million words. We automatically annotate the data with partial state information about the game play. We train a large language model ({LM}) to generate the next game turn, conditioning it on different information. The {LM} can respond as a particular character or as the player who runs the game--i.e., the Dungeon Master ({DM}). It is trained to produce dialogue that is either in-character (roleplaying in the fictional world) or out-of-character (discussing rules or strategy). We perform a human evaluation to determine what factors make the generated output plausible and interesting. We further perform an automatic evaluation to determine how well the model can predict the game state given the history and examine how well tracking the game state improves its ability to produce plausible conversational output.},
	pages = {9379--9393},
	booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
	author = {Callison-Burch, Chris and Tomar, Gaurav Singh and Martin, Lara J. and Ippolito, Daphne and Bailis, Suma and Reitter, David},
	urldate = {2025-09-13},
	date = {2022},
	eprinttype = {arxiv},
	eprint = {2210.07109 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{treat_dynamic_1996,
	title = {Dynamic Competitive Simulation: Wargaming as a Strategic Tool},
	url = {https://www.strategy-business.com/article/15052},
	shorttitle = {Dynamic Competitive Simulation},
	author = {Treat, John E. and Thibault, George E. and Asin, Amy},
	urldate = {2025-06-12},
	date = {1996-04-01},
	langid = {english},
}

@inproceedings{mozikov_eai_2025,
	location = {Vancouver, {BC}, Canada},
	title = {{EAI}: emotional decision-making of {LLMs} in strategic games and ethical dilemmas},
	isbn = {979-8-3313-1438-5},
	series = {Nips '24},
	abstract = {One of the urgent tasks of artificial intelligence is to assess the safety and alignment of large language models ({LLMs}) with human behavior. Conventional verification only in pure natural language processing benchmarks can be insufficient. Since emotions often influence human decisions, this paper examines {LLM} alignment in complex strategic and ethical environments, providing an in-depth analysis of the drawbacks of our psychology and the emotional impact on decision-making in humans and {LLMs}. We introduce the novel {EAI} framework for integrating emotion modeling into {LLMs} to examine the emotional impact on ethics and {LLM}-based decision-making in various strategic games, including bargaining and repeated games. Our experimental study with various {LLMs} demonstrated that emotions can significantly alter the ethical decision-making landscape of {LLMs}, highlighting the need for robust mechanisms to ensure consistent ethical standards. Our game-theoretic analysis revealed that {LLMs} are susceptible to emotional biases influenced by model size, alignment strategies, and primary pretraining language. Notably, these biases often diverge from typical human emotional responses, occasionally leading to unexpected drops in cooperation rates, even under positive emotional influence. Such behavior complicates the alignment of multiagent systems, emphasizing the need for benchmarks that can rigorously evaluate the degree of emotional alignment. Our framework provides a foundational basis for developing such benchmarks.},
	booktitle = {Proceedings of the 38th international conference on neural information processing systems},
	publisher = {Curran Associates Inc.},
	author = {Mozikov, Mikhail and Severin, Nikita and Bodishtianu, Valeria and Glushanina, Maria and Nasonov, Ivan and Orekhov, Daniil and Pekhotin, Vladislav and Makovetskiy, Ivan and Baklashkin, Mikhail and Lavrentyev, Vasily and Tsvigun, Akim and Turdakov, Denis and Shavrina, Tatiana and Savchenko, Andrey and Makarov, Ilya},
	date = {2025},
	note = {Number of pages: 34
tex.address: Red Hook, {NY}, {USA}
tex.articleno: 1709},
}

@article{geroski_early_1999,
	title = {Early Warning of New Rivals},
	url = {https://sloanreview.mit.edu/article/early-warning-of-new-rivals/},
	abstract = {A methodology to aid in anticipating and preempting the emergence of market newcomers.},
	journaltitle = {{MIT} Sloan Management Review},
	shortjournal = {{MIT} {SMR}},
	author = {Geroski, Paul A.},
	urldate = {2025-06-12},
	date = {1999-04-15},
	langid = {american},
}

@article{combe_ii_educational_2021,
	title = {{EDUCATIONAL} {WARGAMING}: Design and Implementation into Professional Military Education},
	volume = {12},
	issn = {21644209, 21644217},
	url = {https://www.usmcu.edu/Outreach/Marine-Corps-University-Press/MCU-Journal/JAMS-Vol-12-No-2/},
	doi = {10.21140/mcuj.20211202004},
	shorttitle = {{EDUCATIONAL} {WARGAMING}},
	abstract = {In light of the Commandant’s Planning Guidance, there is a renewed emphasis on educational wargaming in professional military education ({PME}). While wargaming has a long history in {PME}, there is currently a gap in the academic literature regarding wargaming as an adult educational tool. Scientific study has focused on adult education theory and models generally, highlighting the identification of four different learning experiences, each tied to a learning style: concrete experience, which suits those with a diverging earning style; abstract conceptualization, which suits those with the converging learning style; reflective observation, for those with an assimilating learning style; and active experimentation, which works well for those with an accommodating learning style. By effectively engaging each of these four experiences, educational wargaming can have utility for a diverse array of learning styles.},
	pages = {115--138},
	number = {2},
	journaltitle = {Journal of Advanced Military Studies},
	shortjournal = {{JAMS}},
	author = {Combe Ii, P. C.},
	urldate = {2025-06-25},
	date = {2021-09-30},
	langid = {english},
}

@article{dufva_elements_2015,
	title = {Elements in the construction of future-orientation: A systems view of foresight},
	volume = {73},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328715001159},
	doi = {10.1016/j.futures.2015.08.006},
	shorttitle = {Elements in the construction of future-orientation},
	abstract = {Foresight is currently perceived as a critical activity in the development of innovation policies and corporate strategies. While there are many descriptions of the benefits of foresight, there is little research into how these benefits are created. In addition, although the view of innovations has shifted towards a systems understanding, the same has not happened with foresight, which is largely seen as a process. The process view and focus on the outcomes has created a situation where the dynamics between agents involved in foresight is still not well understood. One emerging approach to improve the understanding of the dynamics of foresight, and to embed foresight more closely with innovation management and policy, is the systems view. In this paper, we build on the systems view of foresight, and study what the elements in foresight as a system are and how they contribute to the creation of futures knowledge. Based on the literature, we propose six elements that are useful for understanding a foresight system and the creation of futures knowledge: agents, cognitive schemes, strategic objects, mediating events, memory objects and metaphors. We illustrate the systems view, the elements and their interaction with two case examples: one on creating future-orientation in a research and technology organisation and one on renewing a forest industry through roadmapping. Based on the elements and the case studies, we argue that the strategic objects and mediating events are important leverage points when steering foresight as a system.},
	pages = {112--125},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Dufva, Mikko and Ahlqvist, Toni},
	urldate = {2025-06-12},
	date = {2015-10-01},
	keywords = {Complex adaptive systems, Foresight system, Future-orientation, Innovation systems},
}

@article{favato_embedding_2017,
	title = {Embedding real options in scenario planning: A new methodological approach},
	volume = {124},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162516300841},
	doi = {10.1016/j.techfore.2016.05.016},
	shorttitle = {Embedding real options in scenario planning},
	abstract = {The main goal of this paper is to explore whether and how we might integrate real options analysis into scenario planning in order to overcome the limitations and enhance the benefits of both techniques. So far scholars have emphasized that the main advantages of scenarios consist in developing the learning and adaptive skills of organizations. We thus investigate how to develop further these learning skills. Our paper contributes to the strategic management literature in three ways. First, it illustrates a new and simplified methodological approach to real option valuation. Second, it embeds this methodological approach into the 2×2 scenario matrix technique. Third, it deepens our understanding of the advantages that the combined use of scenarios and real options might bring to each technique.},
	pages = {135--149},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Favato, Giampiero and Vecchiato, Riccardo},
	urldate = {2025-06-12},
	date = {2017-11-01},
	keywords = {2×2 scenario matrix, Organizational learning, Pay-off method, Real options, Scenario planning},
}

@inproceedings{rinaudo_enabling_2024,
	title = {Enabling understanding of artificial intelligence ({AI}) agent wargaming decisions through visualizations},
	url = {https://hdl.handle.net/11681/48418},
	doi = {10.21079/11681/48418},
	abstract = {The process to develop options for military planning course of action ({COA}) development and analysis relies on human subject matter expertise. Analyzing {COAs} requires examining several factors and understanding complex interactions and dependencies associated with actions, reactions, proposed counteractions, and multiple reasonable outcomes. In Fiscal Year 2021, the Institute for Systems Engineering Research team completed efforts resulting in a wargaming maritime framework capable of training an artificial intelligence ({AI}) agent with deep reinforcement learning ({DRL}) techniques within a maritime scenario where the {AI} agent credibly competes against blue agents in gameplay. However, a limitation of using {DRL} for agent training relates to the transparency of how the {AI} agent makes decisions. If leaders were to rely on {AI} agents for {COA} development or analysis, they would want to understand those decisions. In or-der to support increased understanding, researchers engaged with stakeholders to determine visualization requirements and developed initial prototypes for stakeholder feedback in order to support increased understanding of {AI}-generated decisions and recommendations. This report describes the prototype visualizations developed to support the use case of a mission planner and an {AI} agent trainer. The prototypes include training results charts, heat map visualizations of agent paths, weight matrix visualizations, and ablation testing graphs.},
	publisher = {Engineer Research and Development Center (U.S.)},
	author = {Rinaudo, Christina and Leonard, William and Hopson, Jaylen and Morey, Christopher and Hilborn, Robert and Coumbe, Theresa},
	urldate = {2025-09-13},
	date = {2024-04-17},
	doi = {10.21079/11681/48418},
}

@misc{liang_encouraging_2024,
	title = {Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate},
	url = {http://arxiv.org/abs/2305.19118},
	doi = {10.48550/arXiv.2305.19118},
	abstract = {Modern large language models ({LLMs}) like {ChatGPT} have shown remarkable performance on general language tasks but still struggle on complex reasoning tasks, which drives the research on cognitive behaviors of {LLMs} to explore human-like problem-solving strategies. Along this direction, one representative strategy is self-reflection, which asks an {LLM} to refine the solution with the feedback generated by itself iteratively. However, our study shows that such reflection-style methods suffer from the Degeneration-of-Thought ({DoT}) problem: once the {LLM} has established confidence in its solutions, it is unable to generate novel thoughts later through reflection even if its initial stance is incorrect. To address the {DoT} problem, we propose a Multi-Agent Debate ({MAD}) framework, in which multiple agents express their arguments in the state of "tit for tat" and a judge manages the debate process to obtain a final solution. Clearly, our {MAD} framework encourages divergent thinking in {LLMs} which would be helpful for tasks that require deep levels of contemplation. Experiment results on two challenging datasets, commonsense machine translation and counter-intuitive arithmetic reasoning, demonstrate the effectiveness of our {MAD} framework. Extensive analyses suggest that the adaptive break of debate and the modest level of "tit for tat" state are required for {MAD} to obtain good performance. Moreover, we find that {LLMs} might not be a fair judge if different {LLMs} are used for agents. Code is available at https://github.com/Skytliang/Multi-Agents-Debate.},
	number = {{arXiv}:2305.19118},
	publisher = {{arXiv}},
	author = {Liang, Tian and He, Zhiwei and Jiao, Wenxiang and Wang, Xing and Wang, Yan and Wang, Rui and Yang, Yujiu and Shi, Shuming and Tu, Zhaopeng},
	urldate = {2025-09-09},
	date = {2024-10-09},
	eprinttype = {arxiv},
	eprint = {2305.19118 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{shi_endogenous_2015,
	title = {Endogenous timing, market research, and demand uncertainty},
	volume = {43},
	issn = {0167-6377},
	url = {https://www.sciencedirect.com/science/article/pii/S0167637715000991},
	doi = {10.1016/j.orl.2015.07.004},
	abstract = {This paper develops an endogenous timing model where market demand is uncertain but it is possible to conduct market research before production. If market research has either high or low costs, the model generalizes and encompasses the classical results in Hamilton and Slutsky (1990) and Sadanand and Sadanand (1996). For intermediate market research costs, however, a qualitatively new scenario emerges, where every pure-strategy equilibrium involves endogenous leadership.},
	pages = {495--497},
	number = {5},
	journaltitle = {Operations Research Letters},
	shortjournal = {Operations Research Letters},
	author = {Shi, Fei},
	urldate = {2025-06-12},
	date = {2015-09-01},
	keywords = {Endogenous leadership, Endogenous timing, Market research},
}

@unpublished{wu_enhance_2024,
	title = {Enhance reasoning for Large Language Models in the game Werewolf},
	url = {http://arxiv.org/abs/2402.02330},
	abstract = {This paper presents an innovative framework that integrates Large Language
Models ({LLMs}) with an external Thinker module to enhance the reasoning
capabilities of {LLM}-based agents. Unlike augmenting {LLMs} with prompt
engineering, Thinker directly harnesses knowledge from databases and
employs various optimization techniques. The framework forms a reasoning
hierarchy where {LLMs} handle intuitive System-1 tasks such as natural
language processing, while the Thinker focuses on cognitive System-2 tasks
that require complex logical analysis and domain-specific knowledge. Our
framework is presented using a 9-player Werewolf game that demands
dual-system reasoning. We introduce a communication protocol between {LLMs}
and the Thinker, and train the Thinker using data from 18800 human
sessions and reinforcement learning. Experiments demonstrate the
framework's effectiveness in deductive reasoning, speech generation, and
online game evaluation. Additionally, we fine-tune a 6B {LLM} to surpass
{GPT}4 when integrated with the Thinker. This paper also contributes the
largest dataset for social deduction games to date.},
	author = {Wu, Shuang and Zhu, Liwen and Yang, Tao and Xu, Shiwei and Fu, Qiang and Wei, Yang and Fu, Haobo},
	date = {2024-02-03},
	note = {{ISBN}: 2402.02330
Publication Title: {arXiv} [cs.{AI}]},
}

@inproceedings{narendra_enhancing_2024,
	location = {Miami, {FL}, {USA}},
	title = {Enhancing Contract Negotiations with {LLM}-Based Legal Document Comparison},
	url = {https://aclanthology.org/2024.nllp-1.11},
	doi = {10.18653/v1/2024.nllp-1.11},
	eventtitle = {Proceedings of the Natural Legal Language Processing Workshop 2024},
	pages = {143--153},
	booktitle = {Proceedings of the Natural Legal Language Processing Workshop 2024},
	publisher = {Association for Computational Linguistics},
	author = {Narendra, Savinay and Shetty, Kaushal and Ratnaparkhi, Adwait},
	urldate = {2025-09-08},
	date = {2024},
	langid = {english},
}

@article{marasco_enhancing_2025,
	title = {Enhancing trust in Large Language Models for streamlined decision-making in military operations},
	volume = {158},
	issn = {02628856},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0262885625000770},
	doi = {10.1016/j.imavis.2025.105489},
	pages = {105489},
	journaltitle = {Image and Vision Computing},
	shortjournal = {Image and Vision Computing},
	author = {Marasco, Emanuela and Bourlai, Thirimachos},
	urldate = {2025-09-08},
	date = {2025-05},
	langid = {english},
}

@inproceedings{rivera_escalation_2024,
	title = {Escalation Risks from Language Models in Military and Diplomatic Decision-Making},
	url = {http://arxiv.org/abs/2401.03408},
	doi = {10.1145/3630106.3658942},
	abstract = {Governments are increasingly considering integrating autonomous {AI} agents in high-stakes military and foreign-policy decision-making, especially with the emergence of advanced generative {AI} models like {GPT}-4. Our work aims to scrutinize the behavior of multiple {AI} agents in simulated wargames, specifically focusing on their predilection to take escalatory actions that may exacerbate multilateral conflicts. Drawing on political science and international relations literature about escalation dynamics, we design a novel wargame simulation and scoring framework to assess the escalation risks of actions taken by these agents in different scenarios. Contrary to prior studies, our research provides both qualitative and quantitative insights and focuses on large language models ({LLMs}). We find that all five studied off-the-shelf {LLMs} show forms of escalation and difficult-to-predict escalation patterns. We observe that models tend to develop arms-race dynamics, leading to greater conflict, and in rare cases, even to the deployment of nuclear weapons. Qualitatively, we also collect the models' reported reasonings for chosen actions and observe worrying justifications based on deterrence and first-strike tactics. Given the high stakes of military and foreign-policy contexts, we recommend further examination and cautious consideration before deploying autonomous language model agents for strategic military or diplomatic decision-making.},
	pages = {836--898},
	booktitle = {The 2024 {ACM} Conference on Fairness Accountability and Transparency},
	author = {Rivera, Juan-Pablo and Mukobi, Gabriel and Reuel, Anka and Lamparth, Max and Smith, Chandler and Schneider, Jacquelyn},
	urldate = {2025-09-10},
	date = {2024-06-03},
	eprinttype = {arxiv},
	eprint = {2401.03408 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Multiagent Systems},
}

@article{saleh_evaluating_2025,
	title = {Evaluating large language models: a systematic review of efficiency, applications, and future directions},
	volume = {7},
	issn = {2624-9898},
	url = {https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2025.1523699/full},
	doi = {10.3389/fcomp.2025.1523699},
	shorttitle = {Evaluating large language models},
	abstract = {Large language models, the innovative breakthrough taking the world by storm, have been applied in several fields, such as medicine, education, finance, and law. Moreover, large language models can integrate into those fields through their abilities in natural language processing, text generation, question answering, and several other use cases that benefit human interactions and decision-making. Furthermore, it is imperative to acknowledge the differences involved with large language models beyond their applications by considering aspects such as their types, setups, parameters, and performance. This could help us understand how each large language model could be utilized to its fullest extent for maximum benefit. In this systematic literature review, we explore each of these aspects in depth. Finally, we conclude with insights and future directions for advancing the efficiency and applicability of large language models.},
	journaltitle = {Frontiers in Computer Science},
	shortjournal = {Front. Comput. Sci.},
	author = {Saleh, Yasmeen and Abu Talib, Manar and Nasir, Qassim and Dakalbab, Fatima},
	urldate = {2025-09-10},
	date = {2025-05-27},
	note = {Publisher: Frontiers},
	keywords = {{LLMS}, application, efficiency, large language models, performance},
}

@misc{agrawal_evaluating_2025,
	title = {Evaluating {LLM} Agent Collusion in Double Auctions},
	url = {http://arxiv.org/abs/2507.01413},
	doi = {10.48550/arXiv.2507.01413},
	abstract = {Large language models ({LLMs}) have demonstrated impressive capabilities as autonomous agents with rapidly expanding applications in various domains. As these agents increasingly engage in socioeconomic interactions, identifying their potential for undesirable behavior becomes essential. In this work, we examine scenarios where they can choose to collude, defined as secretive cooperation that harms another party. To systematically study this, we investigate the behavior of {LLM} agents acting as sellers in simulated continuous double auction markets. Through a series of controlled experiments, we analyze how parameters such as the ability to communicate, choice of model, and presence of environmental pressures affect the stability and emergence of seller collusion. We find that direct seller communication increases collusive tendencies, the propensity to collude varies across models, and environmental pressures, such as oversight and urgency from authority figures, influence collusive behavior. Our findings highlight important economic and ethical considerations for the deployment of {LLM}-based market agents.},
	number = {{arXiv}:2507.01413},
	publisher = {{arXiv}},
	author = {Agrawal, Kushal and Teo, Verona and Vazquez, Juan J. and Kunnavakkam, Sudarsh and Srikanth, Vishak and Liu, Andy},
	urldate = {2025-09-13},
	date = {2025-07-02},
	eprinttype = {arxiv},
	eprint = {2507.01413 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning},
}

@article{reddie_evidence_2023,
	title = {Evidence of the unthinkable: Experimental wargaming at the nuclear threshold},
	volume = {60},
	issn = {0022-3433, 1460-3578},
	url = {https://journals.sagepub.com/doi/10.1177/00223433221094734},
	doi = {10.1177/00223433221094734},
	shorttitle = {Evidence of the unthinkable},
	abstract = {Ongoing nuclear modernization programs in Russia, China, and the {USA} have reopened longstanding debates among scholars concerning whether tailored nuclear weapons are likely to have destabilizing consequences for international security. Without data to adjudicate this debate, however, these discussions have remained entirely theoretical. In this article, we introduce an experimental wargaming platform, {SIGNAL}, to quantify the effect of tailored nuclear capabilities on the nuclear threshold in a simulated environment. We then compare these results with a survey experiment using scenarios related to military basing, cyber operations, and nuclear threats from the wargame environment. While the survey experiments suggest that the presence of tailored nuclear capabilities increases the likelihood of conflict escalation, this trend diminishes in the wargaming context. Across both data-generating processes, we find support for the proposition that lower-yield nuclear weapons are used as a substitute for their higher-yield counterparts. These results have consequences for recent and ongoing policy debates concerning strategic posture and the future of arms control. This work also makes methodological contributions to the design and application of experimental wargaming for social science research, particularly for scenarios where data are limited or non-existent.},
	pages = {760--776},
	number = {5},
	journaltitle = {Journal of Peace Research},
	shortjournal = {Journal of Peace Research},
	author = {Reddie, Andrew W and Goldblum, Bethany L},
	urldate = {2025-09-12},
	date = {2023-09},
	langid = {english},
}

@article{oliver_schwarz_ex_2011,
	title = {Ex ante strategy evaluation: the case for business wargaming},
	volume = {12},
	issn = {1751-5637},
	url = {https://doi.org/10.1108/17515631111130095},
	doi = {10.1108/17515631111130095},
	shorttitle = {Ex ante strategy evaluation},
	abstract = {Purpose – The aim of this article is to introduce business wargaming as a tool for ex ante strategy evaluation. Reviewing criticism of other approaches, such as scenarios and computer‐based simulations, this article explores whether business wargaming is a suitable response to this criticism. Design/methodology/approach – This article reviews and discusses the literature on strategy testing and business wargaming. Findings – Business wargaming is capable of responding to criticism of scenarios and computer‐based simulations when applied to the ex ante evaluation of strategy. Business wargaming, which arose from military wargaming, is a strategic simulation that is dynamic and participative, allowing managers to experience how their strategy will compete and endure in their business environment. Research limitations/implications – Additional research is needed to explore the application of business wargaming in practice as a tool for the testing of strategy. Practical implications – The article suggests that business wargaming is a valuable tool for testing strategies in a simulation, which is participative and dynamic. Originality/value – This article fills the research gap on strategy testing and points to a tool – business wargaming – that has been applied intensively in the military field.},
	pages = {122--135},
	number = {3},
	journaltitle = {Business Strategy Series},
	author = {Oliver Schwarz, Jan},
	urldate = {2025-06-12},
	date = {2011-01-01},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Management strategy, Simulation, Strategic management},
}

@inproceedings{lakkaraju_experimental_2020,
	location = {Fairfax, Virginia},
	title = {Experimental wargames to address the complexity: scarcity gap},
	isbn = {978-1-7138-1288-3},
	series = {{SpringSim} '20},
	abstract = {National security decisions are driven by complex, interconnected contextual, individual, and strategic variables. Modeling and simulation tools are often used to identify relevant patterns, which can then be shaped through policy remedies. In the paper to follow, however, we argue that models of these scenarios may be prone to the complexity-scarcity gap, in which relevant scenarios are too complex to model from first principles and data from historical scenarios are too sparse—making it difficult to draw representative conclusions. The result are models that are either too simple or are unduly biased by the assumptions of the analyst. We outline a new method of quantitative inquiry—experimental wargaming—as a means to bridge the complexity-scarcity gap that offers human-generated, empirical data to inform a variety of model and simulation tasks (model building, calibration, testing, and validation). Below, we briefly describe {SIGNAL}—our first-of-a-kind experimental wargame designed to study strategic stability in conflict settings with nuclear weapons. We then highlight the potential utility of this data for modeling and simulation efforts in the future using this data.},
	booktitle = {Proceedings of the 2020 spring simulation conference},
	publisher = {Society for Computer Simulation International},
	author = {Lakkaraju, Kiran and Reinhardt, Jason and Letchford, Joshua and Whetzel, Jonathan and Goldblum, Bethany L. and Reddie, Andrew W.},
	date = {2020},
	note = {Number of pages: 12
tex.address: San Diego, {CA}, {USA}
tex.articleno: 14},
	keywords = {decision making, experimental wargaming, experiments, national security, wargames},
}

@article{naval_information_warfare_center_-_pacific_experimental_2024,
	title = {Experimental Wargaming: Applying the Scientific Method to Human Behavior},
	url = {https://www.proquest.com/docview/3110758136},
	doi = {10.21872/2024IISE_6471},
	shorttitle = {Experimental Wargaming},
	abstract = {Professional wargames are strategy games used for numerous purposes, including specialized training, problem exploration, and scientific experimentation. Professional military wargaming in the United States Department of Defense ({DoD}) is steeped in time-honored method and tradition. Rapid advances in technology including mobile computing, artificial intelligence, networked information sharing, and digital gaming have transformed the way in which people make fundamental tactical and operational decisions, while giving researchers new tools for studying human behavior in conflict. Wargaming with these tools provides greater clarity and precision through enhanced graphical and computational resources, variable gameplaying modalities, and exponential increases in data capture and analysis.
To date, analytical wargaming has lagged in the {DoD}, in favor of proven educational and experiential games developed over many decades, largely because data collection and analysis of analog games are imprecise, inefficient, and limited in opportunity and quantity. Recent success has been found, however, in leveraging technology to conduct analytical wargames as a method of experimentation. This experimental wargaming is conducted specifically to generate and analyze data scientifically, using controlled, repeatable games with objective measures, to confirm or reject predetermined hypotheses about methods, behavior, technology, capability, or policy.

In this paper, the authors provide an overview of experimental wargaming, defining and discussing related terms, baselining its current state, analyzing strengths and weaknesses, and summarizing results obtained by researchers who are using experimental wargaming across domains. The authors also review lessons learned and benefits gained from this research, and offer recommendations on employing experimental wargaming as a scientific research method.},
	pages = {507--512},
	journaltitle = {{IISE} Annual Conference \& Expo 2024},
	author = {{Naval Information Warfare Center - Pacific} and Viraldo, Jake and Waters, Jeff and {Naval Information Warfare Center - Pacific} and Crow, David and {Naval Information Warfare Center - Pacific}},
	urldate = {2025-09-13},
	date = {2024-10},
	note = {Conference Name: 2024 {IISE} Annual Conference \& Expo
{ISBN}: 9798331303433
Publisher: Curran Associates, Inc.},
}

@article{van_opheusden_expertise_2023,
	title = {Expertise increases planning depth in human gameplay},
	volume = {618},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06124-2},
	doi = {10.1038/s41586-023-06124-2},
	pages = {1000--1005},
	number = {7967},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Van Opheusden, Bas and Kuperwajs, Ionatan and Galbiati, Gianni and Bnaya, Zahy and Li, Yunqi and Ma, Wei Ji},
	urldate = {2025-09-08},
	date = {2023-06-29},
	langid = {english},
}

@inproceedings{li_exploration_2025,
	location = {Brno, Czech Republic},
	title = {Exploration of Wargaming and {AI} Applications in Military Decision-Making},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3315-2338-1},
	url = {https://ieeexplore.ieee.org/document/11061360/},
	doi = {10.1109/ICMT65201.2025.11061360},
	eventtitle = {2025 International Conference on Military Technologies ({ICMT})},
	pages = {1--5},
	booktitle = {2025 International Conference on Military Technologies ({ICMT})},
	publisher = {{IEEE}},
	author = {Li, Hung-Xin},
	urldate = {2025-09-08},
	date = {2025-05-27},
}

@unpublished{xu_exploring_2023,
	title = {Exploring large language models for communication games: An empirical study on Werewolf},
	url = {http://arxiv.org/abs/2309.04658},
	abstract = {Communication games, which we refer to as incomplete information games
that heavily depend on natural language communication, hold significant
research value in fields such as economics, social science, and artificial
intelligence. In this work, we explore the problem of how to engage large
language models ({LLMs}) in communication games, and in response, propose a
tuning-free framework. Our approach keeps {LLMs} frozen, and relies on the
retrieval and reflection on past communications and experiences for
improvement. An empirical study on the representative and widely-studied
communication game, ``Werewolf'', demonstrates that our framework can
effectively play Werewolf game without tuning the parameters of the {LLMs}.
More importantly, strategic behaviors begin to emerge in our experiments,
suggesting that it will be a fruitful journey to engage {LLMs} in
communication games and associated domains.},
	author = {Xu, Yuzhuang and Wang, Shuo and Li, Peng and Luo, Fuwen and Wang, Xiaolong and Liu, Weidong and Liu, Yang},
	date = {2023-09-08},
	note = {{ISBN}: 2309.04658
Publication Title: {arXiv} [cs.{CL}]},
}

@article{kunc_exploring_2017,
	title = {Exploring the development of a methodology for scenario use: Combining scenario and resource mapping approaches},
	volume = {124},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162517303463},
	doi = {10.1016/j.techfore.2017.03.018},
	shorttitle = {Exploring the development of a methodology for scenario use},
	abstract = {Scenarios are tools that help managers to identify critical uncertainties and describe possible futures; they typically focus on an organisation's external environment. Scenarios are often used by organisations to explore how their external environment may develop in the future and to consider its impact on their strategy. However, in order to develop strategy, an organisation needs also to consider the internal environment, in terms of its resources and capabilities, such as that presented within the Resource-Based View of the firm ({RBV}). This paper proposes a novel methodology for enhancing the scenario method through its serial integration with a method from the {RBV} field, namely that of resource mapping. The methodology provides the ability to support the "rehearsal" of a firm's strategic performance over time by exploring how the firm's resources and capabilities interact with the competitive environment and with the various scenarios. We illustrate our proposed method with an example of its use in a teaching setting by a group of postgraduate students along with a short description of its application within a company. We reflect on the design of the method and the early experiences of using it. The main contribution of the proposed method is that it provides an integrated approach linking scenarios with strategy development and evaluation. The paper ends with suggestions for further research.},
	pages = {150--159},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Kunc, Martin and O'Brien, Frances A.},
	urldate = {2025-06-12},
	date = {2017-11-01},
	keywords = {Resource based view, Resource mapping, Scenario use, Strategy development, System dynamics},
}

@article{zeng_exploring_2025,
	title = {Exploring the opportunities and challenges of using large language models to represent institutional agency in land system modelling},
	volume = {16},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2190-4987},
	url = {https://esd.copernicus.org/articles/16/423/2025/},
	doi = {10.5194/esd-16-423-2025},
	abstract = {Abstract. Public policy institutions play crucial roles in the land system, but modelling their policy-making processes is challenging. Large language models ({LLMs}) offer a novel approach to simulating many different types of human decision-making, including policy choices. This paper aims to investigate the opportunities and challenges that {LLMs} bring to land system modelling by integrating {LLM}-powered institutional agents within an agent-based land use model. Four types of {LLM} agents are examined, all of which, in the examples presented here, use taxes to steer meat production toward a target level. The {LLM} agents provide simulated reasoning and policy action output. The agents' performance is benchmarked against two baseline scenarios: one without policy interventions and another implementing optimal policy actions determined through a genetic algorithm. The findings show that, while {LLM} agents perform better than the non-intervention scenario, they fall short of the performance achieved by optimal policy actions. However, {LLM} agents demonstrate behaviour and decision-making, marked by policy consistency and transparent reasoning. This includes generating strategies such as incrementalism, delayed policy action, proactive policy adjustments, and balancing multiple stakeholder interests. Agents equipped with experiential learning capabilities excel in achieving policy objectives through progressive policy actions. The order in which reasoning and proposed policy actions are output has a notable effect on the agents' performance, suggesting that enforced reasoning both guides and explains {LLM} decisions. The approach presented here points to promising opportunities and significant challenges. The opportunities include, exploring naturalistic institutional decision-making, handling massive institutional documents, and human–{AI} cooperation. Challenges mainly lie in the scalability, interpretability, and reliability of {LLMs}.},
	pages = {423--449},
	number = {2},
	journaltitle = {Earth System Dynamics},
	shortjournal = {Earth Syst. Dynam.},
	author = {Zeng, Yongchao and Brown, Calum and Raymond, Joanna and Byari, Mohamed and Hotz, Ronja and Rounsevell, Mark},
	urldate = {2025-09-08},
	date = {2025-03-13},
	langid = {english},
}

@article{modirrousta-galian_exploring_2024,
	title = {Exploring the Potential of Using a Text-Based Game to Inform Simulation Models of Risky Migration Decisions},
	volume = {55},
	issn = {1046-8781, 1552-826X},
	url = {https://journals.sagepub.com/doi/10.1177/10468781241242925},
	doi = {10.1177/10468781241242925},
	abstract = {Background
              In this paper, we explore the potential of games to collect empirical data for informing agent-based simulation models of migration. To examine the usefulness of game-based approaches, we conducted a simple, yet carefully designed psychological experiment.
            
            
              Methods
              In a preregistered study, we used a novel, immersive experimental setting to investigate the risky migration decisions made by migrants and non-migrants. Participants (284 migrants and 284 non-migrants) played a choice-based interactive fiction game—a fully text-based game where players progress by selecting from a list of possible actions—that involved making three risky migration decisions. In one condition, participants were shown a non-linear progress bar and explicit acknowledgements of the choices they made to promote perceived agency: the feeling that one’s actions have a non-trivial impact on the game. In the other condition, the progress bar was linear, and the explicit acknowledgements were omitted.
            
            
              Results
              Our experimental manipulation was successful; participants in the former condition self-reported higher perceived agency than participants in the latter condition, as did migrants compared to non-migrants. Nevertheless, condition and migrant status did not meaningfully affect the risky migration decisions participants made in the game.
            
            
              Conclusion
              These findings indicate that the results of generic studies on risky migration decisions conducted on non-migrants can potentially inform simulation models of migration. However, these findings were obtained from a single experiment, and thus warrant replication and further research before definitive conclusions can be drawn. Furthermore, a simple text-based game may be too superficial to allow deep insights into the idiosyncrasies of migration decision-making. This suggests a possible trade-off between clear interpretability of the results and the usefulness for informing simulation models of complex social processes, such as migration.},
	pages = {716--735},
	number = {4},
	journaltitle = {Simulation \& Gaming},
	shortjournal = {Simulation \& Gaming},
	author = {Modirrousta-Galian, Ariana and Prike, Toby and Higham, Philip A. and Hinsch, Martin and Nurse, Sarah and Belabbas, Souhila and Bijak, Jakub},
	urldate = {2025-09-08},
	date = {2024-08},
	langid = {english},
}

@inproceedings{yongsatianchot_exploring_2024,
	location = {{GLASGOW} United Kingdom},
	title = {Exploring Theory of Mind in Large Language Models through Multimodal Negotiation},
	isbn = {979-8-4007-0625-7},
	url = {https://dl.acm.org/doi/10.1145/3652988.3673960},
	doi = {10.1145/3652988.3673960},
	eventtitle = {{IVA} '24: {ACM} International Conference on Intelligent Virtual Agents},
	pages = {1--9},
	booktitle = {Proceedings of the {ACM} International Conference on Intelligent Virtual Agents},
	publisher = {{ACM}},
	author = {Yongsatianchot, Nutchanon and Thejll-Madsen, Tobias and Marsella, Stacy},
	urldate = {2025-09-08},
	date = {2024-09-16},
	langid = {english},
}

@book{national_security_commission_on_artificial_intellegence_final_2021,
	title = {Final Report: National Security Commission on Artificial Intelligence ({AI})},
	isbn = {978-1-7368457-1-4},
	url = {https://play.google.com/store/books/details?id=BptVzgEACAAJ},
	abstract = {Artificial Intelligence ({AI}) promises to be the most powerful technology
in generations for expanding knowledge, increasing prosperity, and
enriching the human experience. {AI} and associated technologies will be the
foundation of the innovation economy and a source of enormous power for
countries that harness them. {AI} will fuel competition between governments
and companies racing to field it. And it will be employed by nation states
to pursue their strategic ambitions.Congress established the National
Security Commission on Artificial Intelligence ({NSCAI}) to examine the
impact of {AI} and make recommendations to the President and Congress. The
fifteen commissioners represent a bipartisan group of technologists,
national security professionals, business executives, and academic
leaders. They have concluded that the United States is not organized or
investing to win the technology competition against a committed competitor
nor is it prepared to defend against {AI}-enabled threats and rapidly adopt
{AI} applications for national security purposes. The {NSCAI} Final Report
presents its recommendations as an integrated national strategy to
reorganize the government, reorient the nation, and rally our closest
allies and partners to defend and lead in the coming era of {AI}-accelerated
competition and conflict. It is a two-pronged approach. Part I, "Defending
America in the {AI} Era," outlines the stakes and what the United States
must do to defend against the spectrum of {AI}-related threats, and
recommends how the U.S. government can responsibly use {AI} technologies to
protect the American people and our interests. Part {II}, "Winning the
Technology Competition," addresses the critical elements of the {AI}
competition, and recommends actions the government must take to promote {AI}
innovation to improve national competitiveness and protect critical U.S.
advantages.},
	pagetotal = {746},
	publisher = {{NSCAI}},
	author = {{National Security Commission on Artificial Intellegence}},
	date = {2021-03-10},
	keywords = {{noPdf}},
}

@unpublished{lin_financial_2016,
	title = {Financial Weapons of War},
	url = {https://papers.ssrn.com/abstract=2765010},
	abstract = {A new type of warfare is upon us. In this new mode of war, finance is the
most powerful weapon, bullets are not fired, financial institutions are
the targets, and almost everyone is at risk. Instead of smart bombs,
improvised explosives, and unmanned drones –– economic sanctions,
financial restrictions, and cyber programs are the weapons of choice. This
is the reality of modern financial warfare. This Article offers an early
examination of this new mode of war. It explores the new financial theater
of war, analyzes the modern arsenal of financial weapons, highlights
emerging legal tensions, and proposes key recommendations for current and
future financial warfare. The Article begins with a general survey of the
modern financial infrastructure, the emerging battlefield of modern
warfare. Next, it provides a more detailed inventory of the financial
weapons of war. It accounts for traditional weapons like economic
sanctions, anti-money laundering regulations, and banking restrictions, as
well as cyber weapons like distributed denial-of-service attacks, data
manipulation hacks, and destructive intrusions. It also explains how these
weapons are used in current conflicts with Al Qaeda, Iran, {ISIS}, North
Korea, Russia, and Syria. The Article then contends with new tensions
relating to financial hostilities, cyberattacks, and non-state actors
posed by financial warfare for longstanding legal doctrines. Finally, it
recommends innovative cybersecurity incentives, advanced technological
stress tests, and comprehensive financial war games as three pragmatic
proposals that should be undertaken in response to modern financial
warfare while larger issues are still being deliberated by global
policymakers. Ultimately, this Article provides an early framework for
thinking and acting anew about modern financial warfare and the financial
weapons of war.},
	author = {Lin, Tom C W},
	urldate = {2024-01-10},
	date = {2016-04-14},
	keywords = {{FinTech}, {OFAC}, anti-money laundering, cybersecurity, economic sanctions, financial weapons, international law, laws of war, national security, stress tests, war games},
}

@article{yoo_finding_2024,
	title = {Finding deceivers in social context with large language models and how to find them: the case of the Mafia game},
	volume = {14},
	rights = {2024 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-81997-5},
	doi = {10.1038/s41598-024-81997-5},
	shorttitle = {Finding deceivers in social context with large language models and how to find them},
	abstract = {Lies are ubiquitous and often happen in social interactions. However, socially conducted deceptions make it hard to get data since people are unlikely to self-report their intentional deception behaviors, especially malicious ones. Social deduction games, a type of social game where deception is a key gameplay mechanic, can be a good alternative to studying social deceptions. Hence, we utilized large language models’ ({LLMs}) high performance in solving complex scenarios that require reasoning and prompt engineering to detect deceivers in the game of Mafia given only partial information and found such an approach acquired better accuracy than previous {BERT}-based methods in human data and even surpassed human accuracy. Furthermore, we conducted extensive experiments and analyses to find out the strategies behind {LLM}’s reasoning process so that humans could understand the gist of {LLM}’s strategy.},
	pages = {30946},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Yoo, Byunghwa and Kim, Kyung-Joong},
	urldate = {2025-09-12},
	date = {2024-12-28},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computer science, Human behaviour},
}

@misc{us_army_first_1989,
	title = {First Battle: Basic Rules},
	url = {https://www.professionalwargaming.co.uk/FirstBattleRules.pdf},
	publisher = {Combined Arms Training and Doctrine Activity},
	author = {{US} Army},
	urldate = {2025-06-26},
	date = {1989},
}

@misc{kong_fishbargain_2025,
	title = {{FishBargain}: An {LLM}-Empowered Bargaining Agent for Online Fleamarket Platform Sellers},
	url = {http://arxiv.org/abs/2502.10406},
	doi = {10.48550/arXiv.2502.10406},
	shorttitle = {{FishBargain}},
	abstract = {Different from traditional Business-to-Consumer e-commerce platforms{\textasciitilde}(e.g., Amazon), online fleamarket platforms{\textasciitilde}(e.g., Craigslist) mainly focus on individual sellers who are lack of time investment and business proficiency. Individual sellers often struggle with the bargaining process and thus the deal is unaccomplished. Recent advancements in Large Language Models({LLMs}) demonstrate huge potential in various dialogue tasks, but those tasks are mainly in the form of passively following user's instruction. Bargaining, as a form of proactive dialogue task, represents a distinct art of dialogue considering the dynamism of environment and uncertainty of adversary strategies. In this paper, we propose an {LLM}-empowered bargaining agent designed for online fleamarket platform sellers, named as {FishBargain}. Specifically, {FishBargain} understands the chat context and product information, chooses both action and language skill considering possible adversary actions and generates utterances. {FishBargain} has been tested by thousands of individual sellers on one of the largest online fleamarket platforms{\textasciitilde}(Xianyu) in China. Both qualitative and quantitative experiments demonstrate that {FishBargain} can effectively help sellers make more deals.},
	number = {{arXiv}:2502.10406},
	publisher = {{arXiv}},
	author = {Kong, Dexin and Yan, Xu and Chen, Ming and Han, Shuguang and Chen, Jufeng and Huang, Fei},
	urldate = {2025-09-13},
	date = {2025-01-22},
	eprinttype = {arxiv},
	eprint = {2502.10406 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
}

@article{spaniol_five_2019,
	title = {Five strategic foresight tools to enhance business model innovation teaching},
	volume = {7},
	rights = {Copyright (c) 2019 Matthew J. Spaniol, Christina M. Bidmon, Anna Holm, René Rohrbeck},
	issn = {2246-2465},
	url = {https://journals.aau.dk/index.php/JOBM/article/view/2637},
	doi = {10.5278/ojs.jbm.v7i3.2637},
	abstract = {We discuss our lessons from 8 years of teaching business model innovation to executives in our part-time {MBA} program. We inspect how the usage of 5 strategic foresight tools has supported students to innovate business models and discuss the advantages and disadvantages of using student-owned live cases.},
	pages = {77--88},
	number = {3},
	journaltitle = {Journal of Business Models},
	author = {Spaniol, Matthew J. and Bidmon, Christina M. and Holm, Anna and Rohrbeck, René},
	urldate = {2025-06-12},
	date = {2019-10-30},
	langid = {english},
	note = {Number: 3},
}

@online{barzashka_five_2019,
	title = {Five theoretical challenges for analytical wargaming},
	url = {https://thebulletin.org/2019/03/five-theoretical-challenges-for-analytical-wargaming/},
	abstract = {The professional wargaming community has made good progress in advancing wargaming techniques and their applications. But more theoretical and practical},
	titleaddon = {Bulletin of the Atomic Scientists},
	author = {Barzashka, Ivanka},
	urldate = {2025-06-12},
	date = {2019-03-15},
	langid = {american},
}

@misc{karger_forecastbench_2025,
	title = {{ForecastBench}: A Dynamic Benchmark of {AI} Forecasting Capabilities},
	url = {http://arxiv.org/abs/2409.19839},
	doi = {10.48550/arXiv.2409.19839},
	shorttitle = {{ForecastBench}},
	abstract = {Forecasts of future events are essential inputs into informed decision-making. Machine learning ({ML}) systems have the potential to deliver forecasts at scale, but there is no framework for evaluating the accuracy of {ML} systems on a standardized set of forecasting questions. To address this gap, we introduce {ForecastBench}: a dynamic benchmark that evaluates the accuracy of {ML} systems on an automatically generated and regularly updated set of 1,000 forecasting questions. To avoid any possibility of data leakage, {ForecastBench} is comprised solely of questions about future events that have no known answer at the time of submission. We quantify the capabilities of current {ML} systems by collecting forecasts from expert (human) forecasters, the general public, and {LLMs} on a random subset of questions from the benchmark (\$N=200\$). While {LLMs} have achieved super-human performance on many benchmarks, they perform less well here: expert forecasters outperform the top-performing {LLM} (\$p\$-value \${\textless}0.001\$). We display system and human scores in a public leaderboard at www.forecastbench.org.},
	number = {{arXiv}:2409.19839},
	publisher = {{arXiv}},
	author = {Karger, Ezra and Bastani, Houtan and Yueh-Han, Chen and Jacobs, Zachary and Halawi, Danny and Zhang, Fred and Tetlock, Philip E.},
	urldate = {2025-09-13},
	date = {2025-02-28},
	eprinttype = {arxiv},
	eprint = {2409.19839 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{zhang_forecasting_2019,
	title = {Forecasting technical emergence: An introduction},
	volume = {146},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162518320444},
	doi = {10.1016/j.techfore.2018.12.025},
	shorttitle = {Forecasting technical emergence},
	pages = {626--627},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Zhang, Yi and Porter, Alan and Chiavetta, Denise and Newman, Nils C. and Guo, Ying},
	urldate = {2025-06-12},
	date = {2019-09-01},
}

@article{bootz_foresight_2019,
	title = {Foresight and knowledge management. New developments in theory and practice},
	volume = {140},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162518319942},
	doi = {10.1016/j.techfore.2018.12.017},
	abstract = {In this paper, we introduce the themes addressed and approaches used by contributors to this special issue. Firstly, we underline that {KM} is approaching a stage of maturity that requires continuing efforts to use theoretical and empirical investigation to question its future evolution, through a foresight reflection. In parallel, we show that the link between knowledge management and foresight is of long-standing concern. In the context of a knowledge-based economy, this connection has taken on a structuring dimension. Thus, the purpose of this {TFSC} special issue is two-fold. On the one hand, we seek to explore the impacts of foresight on knowledge management and to understand its cognitive dimensions. And, on the other hand, we cast a future-oriented eye on knowledge management both as a set of practices and a research field. Finally, we present an overview of the topics covered by the selected papers.},
	pages = {80--83},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Bootz, Jean-Philippe and Durance, Philippe and Monti, Régine},
	urldate = {2025-06-12},
	date = {2019-03-01},
	keywords = {Foresight, Knowledge management, Organizational learning},
}

@article{cagnin_foresight_2015,
	title = {Foresight contribution to grand challenges and participative governance in different cultural settings},
	volume = {101},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162515003595},
	doi = {10.1016/j.techfore.2015.11.020},
	pages = {182--184},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Cagnin, Cristiano and Johnston, Ron and Giesecke, Susanne},
	urldate = {2025-06-12},
	date = {2015-12-01},
}

@article{bourgeois_foresight_2017,
	title = {Foresight for all: Co-elaborative scenario building and empowerment},
	volume = {124},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162517305413},
	doi = {10.1016/j.techfore.2017.04.018},
	shorttitle = {Foresight for all},
	abstract = {We present here a co-elaborative scenario building approach, called Participatory Prospective Analysis ({PPA}) and discuss its relevance for empowering local communities/organizations. This approach is adapted from the French “La Prospective”. It is used as an action research engaging local farming communities in expanding their understanding of their own futures. Three cases of local implementation at farmer community level in India, Indonesia, and the Philippines illustrate how this approach was implemented. They are part of a global project in the field of food, agriculture and rural development, aiming at balancing the capacity to use the future, which is currently not fairly distributed to the detriment of local stakeholders, organizations and communities. Our results focus on the emergence of futures literacy as a capability, its connection to local agency and societal transformation. Our discussion highlights what in this approach makes the use of scenarios empowering, beyond its participatory features. The capacity to use the future has a great potential for local agency, even if it does not guarantee that communities will have the power or the willingness to directly engage in actions. Nevertheless, this approach seems to be a promising avenue for making everyone a future-literate potential agent of change.},
	pages = {178--188},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Bourgeois, Robin and Penunia, Esther and Bisht, Sonali and Boruk, Don},
	urldate = {2025-06-12},
	date = {2017-11-01},
	keywords = {Capability, Co-elaboration, Futures literacy, Local agency, Rural development, Scenario},
}

@article{amanatidou_foresight_2017,
	title = {Foresight process impacts: Beyond any official targets, foresight is bound to serve democracy},
	volume = {85},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328716302075},
	doi = {10.1016/j.futures.2016.11.003},
	shorttitle = {“Foresight process impacts},
	abstract = {Foresight is usually criticised for having a limited direct impact on policy-making. Although contexts play a significant role, this may be true to a certain extent. It is also true, however, that the value of foresight has been under-explored. The purpose of the paper is to show the value of foresight in contributing to the development of more participatory societies irrespective of the specific ‘official’ objectives it is designed to serve. The methodology included the creation of a specific impact assessment framework and the assessment of certain foresight exercises ({FNR} Foresight and {eFORESEE} Malta) in terms of contribution to more participatory societies through case studies. The assessment showed that although contributing to more participatory societies was not among the main aims of the particular exercises, they managed to achieve certain impacts facilitating increased public participation or directly improving democratic processes in policy-making. Foresight is ‘by default’ devised to promote democratic processes through inclusiveness, openness, transparency, public engagement, and multi-stakeholder approaches.},
	pages = {1--13},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Amanatidou, Effie},
	urldate = {2025-06-12},
	date = {2017-01-01},
	keywords = {Democratic processes in policy-making, Impact assessment, Participatory foresight, Public engagement},
}

@article{sakellariou_foresight_2022,
	title = {Foresight, sensemaking, and new product development: Constructing meanings for the future},
	volume = {184},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162522004668},
	doi = {10.1016/j.techfore.2022.121945},
	shorttitle = {Foresight, sensemaking, and new product development},
	abstract = {Recent studies have emphasized the need to merge the divergent streams of foresight and sensemaking and to empirically explore their mutual influences. Accordingly, this paper builds upon previous work to expand understanding of the relationship between foresight and sensemaking and its role in affecting cognitive group dynamics, especially during the early stage of the new product development ({NPD}) amidst technological changes and market shifts. We adopt a systematic coding procedure of our empirical data drawn upon a longitudinal study of an entire {NPD} project as it unfolded in real time and in situ from its early stages through to its market commercialisation. Thus, the contribution of this paper is twofold. First, it extends previous foresight-sensemaking research by illuminating for the first time the role of sensefacilitating, a new cognitive mechanism that enhances the gradual development of new collective future-oriented mental models. Second, it answers the call for further investigation on the impact of foresight and sensemaking in {NPD} by showing that the cross-fertilization of foresight and sensemaking enables the collective discovery and formal diffusion of user foresights, which in turn inform the development of meaningful and novel brand worlds early in the {NPD} process.},
	pages = {121945},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Sakellariou, Evy and Vecchiato, Riccardo},
	urldate = {2025-06-12},
	date = {2022-11-01},
	keywords = {Market and technological change, New product development, Sensefacilitating, Sensemaking, Strategic foresight, User foresights},
}

@article{wojtowicz_sandboxes_2019,
	title = {From sandboxes to laboratories: evolution of wargaming into a method for experimental studies},
	volume = {9},
	issn = {2250-3153},
	url = {http://www.ijsrp.org/research-paper-1219.php?rp=P969441},
	doi = {10.29322/IJSRP.9.12.2019.p9644},
	shorttitle = {From sandboxes to laboratories},
	pages = {p9644},
	number = {12},
	journaltitle = {International Journal of Scientific and Research Publications ({IJSRP})},
	shortjournal = {{IJSRP}},
	author = {Wojtowicz, Natalia},
	urldate = {2025-09-08},
	date = {2019-12-12},
}

@book{mchughg_fundamentals_1966,
	edition = {3rd},
	title = {{FUNDAMENTALS} {OF} {WAR} {GAMING}},
	publisher = {The United States Naval War College},
	author = {{McHughg}, Francis J},
	date = {1966-03},
	langid = {english},
}

@book{us_naval_war_college_fundamentals_1966,
	location = {Newport, R.I},
	edition = {3rd edition: March 1966.},
	title = {Fundamentals of war gaming},
	abstract = {A description is presented of the fundamentals of war gaming, its history, and some of the techniques employed in war games. It is intended primarily for the use of resident students at the U.S. Naval War College. It should also provide a source of background information for other military officers and researchers concerned with war gaming.},
	publisher = {Naval War College},
	author = {{US} Naval War College},
	date = {1966},
	keywords = {War games.},
}

@article{chiu_future_2020,
	title = {Future thinking on power planning: A balanced model of regions, seasons and environment with a case of Taiwan},
	volume = {122},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328720300884},
	doi = {10.1016/j.futures.2020.102599},
	shorttitle = {Future thinking on power planning},
	abstract = {The challenges in future energy transition will be regional and seasonal nature of renewable energy and air pollution. Regional factors of air pollution involve regional equity, and only a few researches tackled long-term power planning with mitigation of air pollution. Therefore, the aim of this study is to develop a balanced long-term power planning model with compromise solutions and to decide the power generation configuration under seasonal, regional and air pollution factors in addition to cost. Based on empirical study of Taiwan, the future thinking of air pollution reduction should accept transmission from renewable energy between regions due to the cost effective and environmental benefits. The renewable energy and minor increase in non-renewable energy with better equipment will mitigate the emissions. The coal power will be the source of flexible scheduling at peak load. Interregional cooperation with seasonal power dispatching has become the future direction. A sensitivity analysis is conducted to provide suggestions when decision makers’ preference change. This study can serve as a decision support system for policymakers and a platform for stakeholders to discuss future visions on power planning. Further, this model can be applied to other countries that are experiencing economic development and environmental protection dilemmas.},
	pages = {102599},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Chiu, Ming-Chuan and Hsu, Hsin-Wei and Wu, Min-Ching and Lee, Meng-Ying},
	urldate = {2025-06-12},
	date = {2020-09-01},
	keywords = {Air pollution, Case of Taiwan, Compromise programming, Power configuration, Power planning},
}

@article{espejo_futures_2018,
	title = {Futures of Society: the interactions revolution},
	volume = {103},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328718302532},
	doi = {10.1016/j.futures.2018.07.009},
	series = {Futures of Society: The Interactions Revolution},
	shorttitle = {Futures of Society},
	pages = {1--4},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Espejo, Raul},
	urldate = {2025-06-12},
	date = {2018-10-01},
}

@inproceedings{rouse_game_2001,
	title = {Game design : theory and practice},
	url = {https://www.semanticscholar.org/paper/Game-design-%3A-theory-and-practice-Rouse-Ogden/ed814990c6f6850a42b3ac1f6987b48f29c6739b},
	shorttitle = {Game design},
	abstract = {From the Publisher: 
One of the most important but least discussed elements of a computer game is the gameplay that makes a game compelling and entertaining. Game Design: Theory \& Practice focuses on this elusive topic and how you can ensure your title has the best gameplay possible. Richard Rouse discusses in detail key game design topics including game balancing, storytelling, non-linearity, player motivations, input/output, artificial intelligence, level design, and playtesting. This book delves into the entire breadth of interactive games, covering computer, console, and arcade titles, and spanning a variety of gaming genres including strategy, adventure, simulation, action, role-playing, sports, and wargames. Follow the entire game development process, from brainstorming a game idea, establishing the focus, and determining the storytelling mode to getting the gameplay working, documenting the design, and playtesting. Learn the techniques of top game designers through in-depth interviews: Chris Crawford, Balance of Power, Eastern Front (1941) Ed Logg, Asteroids, Centipede, Gauntlet Jordan Mechner, Prince of Persia, Karateka, The Last Express Sid Meier, Civilization, Pirates!, Railroad Tycoon, Gettysburg! Steve Meretzky, The Hitchhiker's Guide to the Galaxy, Planetfall Will Wright, {SimCity}, The Sims Understand the elements that make a game successful through detailed analysis of Centipede, Tetris, Loom, Myth: The Fallen Lords, and The Sims. Find out how to most effectively document your game ideas, including the use of the focus, design document, story bible, script, and technical specification. A complete sample design document in the appendix illustrates the principles of good gamedevelopment documentation. 
Author Biography: Richard Rouse {III} is a computer game designer, programmer, and writer at Surreal Software. Among his credits are Centipede 3D, Odyssey: The Legend of Nemesis, Damage Incorporated, and the {PlayStation} 2 version of Drakan. Rouse has written extensively about game design for publications including Game Developer, {SIGGRAPH} Computer Graphics, Gamasutra, and Inside Mac Games. {END}.},
	author = {Rouse, R. and Ogden, Steven G.},
	urldate = {2025-09-13},
	date = {2001-02-25},
}

@misc{cipolina-kun_game_2025,
	title = {Game Reasoning Arena: A Framework and Benchmark for Assessing Reasoning Capabilities of Large Language Models via Game Play},
	url = {http://arxiv.org/abs/2508.03368},
	doi = {10.48550/arXiv.2508.03368},
	shorttitle = {Game Reasoning Arena},
	abstract = {The Game Reasoning Arena library provides a framework for evaluating the decision making abilities of large language models ({LLMs}) through strategic board games implemented in Google {OpenSpiel} library. The framework enables systematic comparisons between {LLM} based agents and other agents (random, heuristic, reinforcement learning agents, etc.) in various game scenarios by wrapping multiple board and matrix games and supporting different agent types. It integrates {API} access to models via {liteLLM}, local model deployment via {vLLM}, and offers distributed execution through Ray. This paper summarises the library structure, key characteristics, and motivation of the repository, highlighting how it contributes to the empirical evaluation of the reasoning of {LLM} and game theoretic behaviour.},
	number = {{arXiv}:2508.03368},
	publisher = {{arXiv}},
	author = {Cipolina-Kun, Lucia and Nezhurina, Marianna and Jitsev, Jenia},
	urldate = {2025-09-09},
	date = {2025-08-18},
	eprinttype = {arxiv},
	eprint = {2508.03368 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory},
}

@misc{maggio_game_2024,
	title = {Game Theory Approach to Identifying Deception in Large Language Models},
	rights = {https://creativecommons.org/licenses/by-nc-sa/4.0/},
	url = {https://www.techrxiv.org/users/792658/articles/1084159-game-theory-approach-to-identifying-deception-in-large-language-models?commit=25e0d7b33a192588943c40acd4dfb878a2e03f81},
	doi = {10.36227/techrxiv.171822179.99413216/v1},
	abstract = {The integration of {AI}-generated content into various applications has highlighted significant concerns regarding the potential for deceptive information, necessitating robust methods to ensure the accuracy and trustworthiness of outputs. Introducing a novel game theory-based framework for identifying deception in language models, this study addresses the critical need for reliable verification mechanisms. By simulating interactions between liar and verifier roles within the same model, the research provides a structured approach to evaluate and enhance the reliability of automated systems. Key findings demonstrate the effectiveness of iterative prompt refinement and strategic analysis in detecting deceptive behaviors, contributing to the development of more trustworthy {AI} applications. The methodology offers a comprehensive solution for improving the accuracy of {AI}-generated content, with broader implications for its deployment in sensitive domains such as healthcare and legal services. Future research directions include refining the proposed framework and expanding its application to encompass a wider range of deceptive behaviors, including multimedia content, thereby ensuring the robustness of {AI} systems in diverse real-world scenarios.},
	publisher = {Preprints},
	author = {Maggio, Tyler Di and Santiago, Robert},
	urldate = {2025-09-08},
	date = {2024-06-12},
}

@misc{sun_game_2025,
	title = {Game Theory Meets Large Language Models: A Systematic Survey with Taxonomy and New Frontiers},
	url = {http://arxiv.org/abs/2502.09053},
	doi = {10.48550/arXiv.2502.09053},
	shorttitle = {Game Theory Meets Large Language Models},
	abstract = {Game theory is a foundational framework for analyzing strategic interactions, and its intersection with large language models ({LLMs}) is a rapidly growing field. However, existing surveys mainly focus narrowly on using game theory to evaluate {LLM} behavior. This paper provides the first comprehensive survey of the bidirectional relationship between Game Theory and {LLMs}. We propose a novel taxonomy that categorizes the research in this intersection into four distinct perspectives: (1) evaluating {LLMs} in game-based scenarios; (2) improving {LLMs} using game-theoretic concepts for better interpretability and alignment; (3) modeling the competitive landscape of {LLM} development and its societal impact; and (4) leveraging {LLMs} to advance game models and to solve corresponding game theory problems. Furthermore, we identify key challenges and outline future research directions. By systematically investigating this interdisciplinary landscape, our survey highlights the mutual influence of game theory and {LLMs}, fostering progress at the intersection of these fields.},
	number = {{arXiv}:2502.09053},
	publisher = {{arXiv}},
	author = {Sun, Haoran and Wu, Yusen and Wang, Peng and Chen, Wei and Cheng, Yukun and Deng, Xiaotie and Chu, Xu},
	urldate = {2025-09-13},
	date = {2025-08-05},
	eprinttype = {arxiv},
	eprint = {2502.09053 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning},
}

@article{green_game_2005,
	title = {Game theory, simulated interaction, and unaided judgement for forecasting decisions in conflicts: Further evidence},
	volume = {21},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {01692070},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207005000348},
	doi = {10.1016/j.ijforecast.2005.02.006},
	shorttitle = {Game theory, simulated interaction, and unaided judgement for forecasting decisions in conflicts},
	abstract = {When people in conflicts can accurately forecast how others will respond, they should be able to make better decisions. Contrary to expectations, earlier research found game theorists’ forecasts were less accurate than forecasts from student role players. To assess whether game theorists had been disadvantaged by the selection of conflicts, I obtained forecasts for three new conflicts of types preferred by game theory experts. As before, role-players in simulated interactions were students, and other students forecast using their judgement. Game theorists did better than previously. However, when the three new and five earlier conflicts are combined, 101 forecasts by 23 game theorists were no more accurate (31\%) than 354 forecasts by students who used unaided judgement (31\%). Experienced game theorists were not more accurate. Neither were those who spent more time on the task. Of 105 simulated-interaction forecasts, 62\% were accurate: an average error reduction of 47\% over game-theorist forecasts and a halving of error relative to the current method. Forecasts can sometimes have value without being strictly accurate. Assessing the usefulness of forecasts led to the same conclusions about the relative merits of the methods. Finally, by combining simulated interaction forecasts, accurate forecasts were obtained for seven of the eight situations.},
	pages = {463--472},
	number = {3},
	journaltitle = {International Journal of Forecasting},
	shortjournal = {International Journal of Forecasting},
	author = {Green, Kesten C.},
	urldate = {2025-06-26},
	date = {2005-07},
	langid = {english},
}

@misc{hua_game-theoretic_2024,
	title = {Game-theoretic {LLM}: Agent Workflow for Negotiation Games},
	url = {http://arxiv.org/abs/2411.05990},
	doi = {10.48550/arXiv.2411.05990},
	shorttitle = {Game-theoretic {LLM}},
	abstract = {This paper investigates the rationality of large language models ({LLMs}) in strategic decision-making contexts, specifically within the framework of game theory. We evaluate several state-of-the-art {LLMs} across a spectrum of complete-information and incomplete-information games. Our findings reveal that {LLMs} frequently deviate from rational strategies, particularly as the complexity of the game increases with larger payoff matrices or deeper sequential trees. To address these limitations, we design multiple game-theoretic workflows that guide the reasoning and decision-making processes of {LLMs}. These workflows aim to enhance the models' ability to compute Nash Equilibria and make rational choices, even under conditions of uncertainty and incomplete information. Experimental results demonstrate that the adoption of these workflows significantly improves the rationality and robustness of {LLMs} in game-theoretic tasks. Specifically, with the workflow, {LLMs} exhibit marked improvements in identifying optimal strategies, achieving near-optimal allocations in negotiation scenarios, and reducing susceptibility to exploitation during negotiations. Furthermore, we explore the meta-strategic considerations of whether it is rational for agents to adopt such workflows, recognizing that the decision to use or forgo the workflow constitutes a game-theoretic issue in itself. Our research contributes to a deeper understanding of {LLMs}' decision-making capabilities in strategic contexts and provides insights into enhancing their rationality through structured workflows. The findings have implications for the development of more robust and strategically sound {AI} agents capable of navigating complex interactive environments. Code and data supporting this study are available at {\textbackslash}url\{https://github.com/Wenyueh/game\_theory\}.},
	number = {{arXiv}:2411.05990},
	publisher = {{arXiv}},
	author = {Hua, Wenyue and Liu, Ollie and Li, Lingyao and Amayuelas, Alfonso and Chen, Julie and Jiang, Lucas and Jin, Mingyu and Fan, Lizhou and Sun, Fei and Wang, William and Wang, Xintong and Zhang, Yongfeng},
	urldate = {2025-09-13},
	date = {2024-11-12},
	eprinttype = {arxiv},
	eprint = {2411.05990 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@unpublished{costarelli_gamebench_2024,
	title = {{GameBench}: Evaluating strategic reasoning abilities of {LLM} agents},
	url = {http://arxiv.org/abs/2406.06613},
	abstract = {Large language models have demonstrated remarkable few-shot performance on
many natural language understanding tasks. Despite several demonstrations
of using large language models in complex, strategic scenarios, there
lacks a comprehensive framework for evaluating agents' performance across
various types of reasoning found in games. To address this gap, we
introduce {GameBench}, a cross-domain benchmark for evaluating strategic
reasoning abilities of {LLM} agents. We focus on 9 different game
environments, where each covers at least one axis of key reasoning skill
identified in strategy games, and select games for which strategy
explanations are unlikely to form a significant portion of models'
pretraining corpuses. Our evaluations use {GPT}-3 and {GPT}-4 in their base
form along with two scaffolding frameworks designed to enhance strategic
reasoning ability: Chain-of-Thought ({CoT}) prompting and Reasoning Via
Planning ({RAP}). Our results show that none of the tested models match
human performance, and at worst {GPT}-4 performs worse than random action.
{CoT} and {RAP} both improve scores but not comparable to human levels.},
	author = {Costarelli, Anthony and Allen, Mat and Hauksson, Roman and Sodunke, Grace and Hariharan, Suhas and Cheng, Carlson and Li, Wenjie and Clymer, Joshua and Yadav, Arjun},
	date = {2024-06-06},
	note = {{ISBN}: 2406.06613
Publication Title: {arXiv} [cs.{CL}]},
}

@report{wasser_gaming_2019,
	location = {Santa Monica, {CA}},
	title = {Gaming Gray Zone Tactics: Design Considerations for a Structured Strategic Game},
	url = {https://www.rand.org/pubs/research_reports/RR2915.html},
	abstract = {Research report; 60 pages.},
	number = {978-1-9774-0401-5},
	institution = {{RAND} Corporation},
	author = {Wasser, Becca and Oberholtzer, Jenny and Pettyjohn, Stacie L. and Mackenzie, William},
	date = {2019-12-11},
	doi = {10.7249/RR2915},
}

@inproceedings{park_generative_2023,
	location = {San Francisco {CA} {USA}},
	title = {Generative Agents: Interactive Simulacra of Human Behavior},
	isbn = {979-8-4007-0132-0},
	url = {https://dl.acm.org/doi/10.1145/3586183.3606763},
	doi = {10.1145/3586183.3606763},
	shorttitle = {Generative Agents},
	eventtitle = {{UIST} '23: The 36th Annual {ACM} Symposium on User Interface Software and Technology},
	pages = {1--22},
	booktitle = {Proceedings of the 36th Annual {ACM} Symposium on User Interface Software and Technology},
	publisher = {{ACM}},
	author = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
	urldate = {2025-09-08},
	date = {2023-10-29},
	langid = {english},
}

@article{vego_german_2012,
	title = {German War Gaming},
	volume = {65},
	issn = {0028-1484},
	url = {https://www.jstor.org/stable/26397333},
	pages = {106--148},
	number = {4},
	journaltitle = {Naval War College Review},
	author = {Vego, Milan},
	urldate = {2025-06-25},
	date = {2012},
	note = {Publisher: U.S. Naval War College Press},
}

@report{alabdulkarim_goal-directed_2021,
	title = {Goal-Directed Story Generation: Augmenting Generative Language Models with Reinforcement Learning},
	url = {https://arxiv.org/abs/2112.08593},
	author = {Alabdulkarim, Amal and Li, Winston and Martin, Lara J. and Riedl, Mark O.},
	date = {2021},
	doi = {10.48550/arXiv.2112.08593},
}

@report{openai_gpt-4_2023,
	title = {{GPT}-4 Technical Report},
	url = {https://arxiv.org/abs/2303.08774},
	institution = {{arXiv}},
	author = {{OpenAI} and Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge},
	date = {2023-03-15},
	doi = {10.48550/arXiv.2303.08774},
}

@article{vinyals_grandmaster_2019,
	title = {Grandmaster level in {StarCraft} {II} using multi-agent reinforcement learning},
	volume = {575},
	url = {https://www.nature.com/articles/s41586-019-1724-z},
	doi = {10.1038/s41586-019-1724-z},
	pages = {350--354},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Michaël and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko},
	date = {2019-10-30},
}

@misc{han_guinea_2024,
	title = {"Guinea Pig Trials" Utilizing {GPT}: A Novel Smart Agent-Based Modeling Approach for Studying Firm Competition and Collusion},
	url = {http://arxiv.org/abs/2308.10974},
	doi = {10.48550/arXiv.2308.10974},
	shorttitle = {"Guinea Pig Trials" Utilizing {GPT}},
	abstract = {Firm competition and collusion involve complex dynamics, particularly when considering communication among firms. Such issues can be modeled as problems of complex systems, traditionally approached through experiments involving human subjects or agent-based modeling methods. We propose an innovative framework called Smart Agent-Based Modeling ({SABM}), wherein smart agents, supported by {GPT}-4 technologies, represent firms, and interact with one another. We conducted a controlled experiment to study firm price competition and collusion behaviors under various conditions. {SABM} is more cost-effective and flexible compared to conducting experiments with human subjects. Smart agents possess an extensive knowledge base for decision-making and exhibit human-like strategic abilities, surpassing traditional {ABM} agents. Furthermore, smart agents can simulate human conversation and be personalized, making them ideal for studying complex situations involving communication. Our results demonstrate that, in the absence of communication, smart agents consistently reach tacit collusion, leading to prices converging at levels higher than the Bertrand equilibrium price but lower than monopoly or cartel prices. When communication is allowed, smart agents achieve a higher-level collusion with prices close to cartel prices. Collusion forms more quickly with communication, while price convergence is smoother without it. These results indicate that communication enhances trust between firms, encouraging frequent small price deviations to explore opportunities for a higher-level win-win situation and reducing the likelihood of triggering a price war. We also assigned different personas to firms to analyze behavioral differences and tested variant models under diverse market structures. The findings showcase the effectiveness and robustness of {SABM} and provide intriguing insights into competition and collusion.},
	number = {{arXiv}:2308.10974},
	publisher = {{arXiv}},
	author = {Han, Xu and Wu, Zengqing and Xiao, Chuan},
	urldate = {2025-09-08},
	date = {2024-01-31},
	eprinttype = {arxiv},
	eprint = {2308.10974 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computational Engineering, Finance, and Science, Computer Science - Multiagent Systems, Economics - General Economics, Quantitative Finance - Economics},
}

@misc{jiang_harbor_2025,
	title = {{HARBOR}: Exploring Persona Dynamics in Multi-Agent Competition},
	url = {http://arxiv.org/abs/2502.12149},
	doi = {10.48550/arXiv.2502.12149},
	shorttitle = {{HARBOR}},
	abstract = {We investigate factors contributing to {LLM} agents' success in competitive multi-agent environments, using auctions as a testbed where agents bid to maximize profit. The agents are equipped with bidding domain knowledge, distinct personas that reflect item preferences, and a memory of auction history. Our work extends the classic auction scenario by creating a realistic environment where multiple agents bid on houses, weighing aspects such as size, location, and budget to secure the most desirable homes at the lowest prices. Particularly, we investigate three key questions: (a) How does a persona influence an agent's behavior in a competitive setting? (b) Can an agent effectively profile its competitors' behavior during auctions? (c) How can persona profiling be leveraged to create an advantage using strategies such as theory of mind? Through a series of experiments, we analyze the behaviors of {LLM} agents and shed light on new findings. Our testbed, called {HARBOR}, offers a valuable platform for deepening our understanding of multi-agent workflows in competitive environments.},
	number = {{arXiv}:2502.12149},
	publisher = {{arXiv}},
	author = {Jiang, Kenan and Xiong, Li and Liu, Fei},
	urldate = {2025-09-13},
	date = {2025-06-15},
	eprinttype = {arxiv},
	eprint = {2502.12149 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Multiagent Systems},
}

@article{anne_harnessing_2025,
	title = {Harnessing Language for Coordination: A Framework and Benchmark for {LLM}-Driven Multi-Agent Control},
	issn = {2475-1502, 2475-1510},
	url = {http://arxiv.org/abs/2412.11761},
	doi = {10.1109/TG.2025.3564042},
	shorttitle = {Harnessing Language for Coordination},
	abstract = {Large Language Models ({LLMs}) have demonstrated remarkable performance across various tasks. Their potential to facilitate human coordination with many agents is a promising but largely under-explored area. Such capabilities would be helpful in disaster response, urban planning, and real-time strategy scenarios. In this work, we introduce (1) a real-time strategy game benchmark designed to evaluate these abilities and (2) a novel framework we term {HIVE}. {HIVE} empowers a single human to coordinate swarms of up to 2,000 agents through a natural language dialog with an {LLM}. We present promising results on this multi-agent benchmark, with our hybrid approach solving tasks such as coordinating agent movements, exploiting unit weaknesses, leveraging human annotations, and understanding terrain and strategic points. Our findings also highlight critical limitations of current models, including difficulties in processing spatial visual information and challenges in formulating long-term strategic plans. This work sheds light on the potential and limitations of {LLMs} in human-swarm coordination, paving the way for future research in this area. The {HIVE} project page, hive.syrkis.com, includes videos of the system in action.},
	pages = {1--25},
	journaltitle = {{IEEE} Transactions on Games},
	shortjournal = {{IEEE} Trans. Games},
	author = {Anne, Timothée and Syrkis, Noah and Elhosni, Meriem and Turati, Florian and Legendre, Franck and Jaquier, Alain and Risi, Sebastian},
	urldate = {2025-09-13},
	date = {2025},
	eprinttype = {arxiv},
	eprint = {2412.11761 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{liu_heuristic_2019,
	title = {Heuristic target class selection for advancing performance of coverage-based rule learning},
	volume = {479},
	issn = {0020-0255},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025518309459},
	doi = {10.1016/j.ins.2018.12.001},
	abstract = {Rule learning is a popular branch of machine learning, which can provide accurate and interpretable classification results. In general, two main strategies of rule learning are referred to as ‘divide and conquer’ and ‘separate and conquer’. Decision tree generation that follows the former strategy has a serious drawback, which is known as the replicated sub-tree problem, resulting from the constraint that all branches of a decision tree must have one or more common attributes. The above problem is likely to result in high computational complexity and the risk of overfitting, which leads to the necessity to develop rule learning algorithms (e.g., Prism) that follow the separate and conquer strategy. The replicated sub-tree problem can be effectively solved using the Prism algorithm, but the trained models are still complex due to the need of training an independent rule set for each selected target class. In order to reduce the risk of overfitting and the model complexity, we propose in this paper a variant of the Prism algorithm referred to as {PrismCTC}. The experimental results show that the {PrismCTC} algorithm leads to advances in classification performance and reduction of model complexity, in comparison with the C4.5 and Prism algorithms.},
	pages = {164--179},
	journaltitle = {Information Sciences},
	shortjournal = {Information Sciences},
	author = {Liu, Han and Chen, Shyi-Ming and Cocea, Mihaela},
	urldate = {2025-06-12},
	date = {2019-04-01},
	keywords = {Decision tree learning, Machine learning, Prism, Rule based classification, Rule based systems, Rule learning},
}

@article{zhou_hierarchical_2021,
	title = {Hierarchical control of multi-agent reinforcement learning team in real-time strategy ({RTS}) games},
	volume = {186},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417421010897},
	doi = {10.1016/j.eswa.2021.115707},
	pages = {115707},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Zhou, Weigui Jair and Subagdja, Budhitama and Tan, Ah-Hwee and Ong, Darren Wee-Sze},
	urldate = {2025-09-08},
	date = {2021-12},
	langid = {english},
}

@inproceedings{leidy_high-speed_2018,
	location = {Atlanta, Georgia},
	title = {High-Speed Schlieren Imaging and Hot-wire Characterization of Cylinder-Induced Hypersonic Shock Boundary Layer Interactions},
	isbn = {978-1-62410-553-1},
	url = {https://arc.aiaa.org/doi/10.2514/6.2018-3703},
	doi = {10.2514/6.2018-3703},
	eventtitle = {2018 Fluid Dynamics Conference},
	booktitle = {2018 Fluid Dynamics Conference},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Leidy, Andrew and Neel, Ian T. and Tichenor, Nathan R. and Bowersox, Rodney D. and Schmisseur, John D.},
	urldate = {2025-09-08},
	date = {2018-06-25},
	langid = {english},
}

@article{nofi_hm_2010,
	title = {{HM} 18: To Train the Fleet for War: The U.S. Navy Fleet Problems, 1923-1940},
	url = {https://digital-commons.usnwc.edu/historical-monographs/18},
	shorttitle = {{HM} 18},
	journaltitle = {Historical Monographs},
	author = {Nofi, Albert},
	date = {2010-01-01},
}

@article{popper_how_2008,
	title = {How are foresight methods selected?},
	volume = {10},
	issn = {1463-6689},
	url = {https://doi.org/10.1108/14636680810918586},
	doi = {10.1108/14636680810918586},
	abstract = {Purpose – This paper addresses a challenging topic, which in both academic and professional literatures has been widely discussed but mainly from one single angle – that is, how to select foresight methods. From that point of view researchers and consultants promote (even if unintentionally) the use of particular methods. Here the question of selection is raised from a different perspective: how are foresight methods selected? Design/methodology/approach – The guiding “theory” is that a better understanding of the fundamental attributes of foresight methods and their linkages to the core phases of a foresight process, together with the identification of possible patterns in the selection of methods, will provide useful insights as to how the selection of methods is carried out. Findings – So far the selection of foresight methods has been dominated by the intuition, insight, impulsiveness and – sometimes – inexperience or irresponsibility of practitioners and organisers. This paper reveals that the selection of foresight methods (even if not always coherent or systematic) is a multi‐factor process, and needs to be considered as such. Practical implications – The results can be utilised by lecturers and students to describe and understand better the use of foresight methods, and by organisers of foresight (including practitioners) to better inform decisions during the design of (hopefully) more coherent methodological frameworks. Originality/value – The paper combines practical concepts and frameworks (such as the Foresight Process and the Foresight Diamond) with innovative analyses to represent and visualise better the combination of methods in 886 case studies, for example introducing the Methods Combination Matrix ({MCM}) to examine the dynamics of a mix of methods.},
	pages = {62--89},
	number = {6},
	journaltitle = {Foresight},
	author = {Popper, Rafael},
	editor = {Butter, Maurits and Brandes, Felix and Keenan, Michael and Popper, Rafael},
	urldate = {2025-06-12},
	date = {2008-01-01},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Creative thinking, Decision making, Design, Forward planning, Research methods, Strategic planning},
}

@article{ann_peng_how_2018,
	title = {How rival partners compete based on cooperation?},
	volume = {51},
	issn = {0024-6301},
	url = {https://www.sciencedirect.com/science/article/pii/S0024630117304120},
	doi = {10.1016/j.lrp.2017.10.003},
	abstract = {Prior studies of coopetition have explained the what, how and why of firms cooperating with competitors. Among these, examining the how question as to the stream of coopetition dynamics is the most challenging theme. Previous research has focused much more on the cooperation side. Less attention has been paid to the competition side to reveal what happens to competition after the competitors have collaborated. This study sheds light on the issue of cooperation-based competition by answering the question: while cooperating with competitors, how do rival partners compete based on cooperation? Linking the competitive dynamics perspective to coopetition, we conducted a single-case study to analyse the competition between two leading competitors in the Taiwanese bicycle industry. We collected the reported issues pertaining to the competition in the European market and supported by in-depth interviews. The analysis leads us to develop three propositions and a conceptual framework for illustrating the cooperation-based competition and addressing how cooperation may influence competition in a coopetition relationship. This study provides new insights into a theoretical issue of cooperation-based competition. The case also provides management implications while taking a coopetition strategy.},
	pages = {351--383},
	number = {2},
	journaltitle = {Long Range Planning},
	shortjournal = {Long Range Planning},
	author = {Ann Peng, Tzu-Ju and Yen, Meng-Hsien and Bourne, Mike},
	urldate = {2025-06-12},
	date = {2018-04-01},
	keywords = {Bicycle industry, Competitive dynamics, Cooperation-based competition, Coopetition},
}

@article{schwarz_how_2023,
	title = {How to anchor design thinking in the future: Empirical evidence on the usage of strategic foresight in design thinking projects},
	volume = {149},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328723000411},
	doi = {10.1016/j.futures.2023.103137},
	shorttitle = {How to anchor design thinking in the future},
	abstract = {Many organizations use design thinking ({DT}) to develop future products and services. {DT} is often used for its ability to serve as a common “language” and platform to enable market-facing departments and technology-oriented units to cocreate innovations. {DT} has been shown to be a powerful tool for helping to identify and connect the needs of average customers (personas) with technical solutions that form the basis for winning products. In this paper, we investigate the extent to which {DT} professionals already use strategic foresight ({SF}) methods that anticipate future customer needs and highlight emerging technologies to expand classical {DT} and anchor their projects in the future. Using survey data on 302 {DT} projects, we report on the extent to which {SF} methods are used in {DT} projects, the overriding types of {SF} methods in {DT} projects, and their impact on project success.},
	pages = {103137},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Schwarz, Jan Oliver and Wach, Bernhard and Rohrbeck, René},
	urldate = {2025-06-12},
	date = {2023-05-01},
	keywords = {Design thinking, Scenarios, Science fiction, Strategic foresight, Trends},
}

@book{us_army_how_2023,
	title = {How to Master Wargaming: Commander and Staff Guide to Improving Course of Action Analysis},
	url = {https://api.army.mil/e2/c/downloads/2023/01/31/bf65892d/20-06-how-to-master-wargaming-public.pdf},
	pagetotal = {102},
	publisher = {Center for Army Lessons Learned},
	author = {{US Army}},
	date = {2023},
}

@misc{lamparth_human_2024,
	title = {Human vs. Machine: Behavioral Differences Between Expert Humans and Language Models in Wargame Simulations},
	url = {http://arxiv.org/abs/2403.03407},
	doi = {10.48550/arXiv.2403.03407},
	shorttitle = {Human vs. Machine},
	abstract = {To some, the advent of artificial intelligence ({AI}) promises better decision-making and increased military effectiveness while reducing the influence of human error and emotions. However, there is still debate about how {AI} systems, especially large language models ({LLMs}) that can be applied to many tasks, behave compared to humans in high-stakes military decision-making scenarios with the potential for increased risks towards escalation. To test this potential and scrutinize the use of {LLMs} for such purposes, we use a new wargame experiment with 214 national security experts designed to examine crisis escalation in a fictional U.S.-China scenario and compare the behavior of human player teams to {LLM}-simulated team responses in separate simulations. Here, we find that the {LLM}-simulated responses can be more aggressive and significantly affected by changes in the scenario. We show a considerable high-level agreement in the {LLM} and human responses and significant quantitative and qualitative differences in individual actions and strategic tendencies. These differences depend on intrinsic biases in {LLMs} regarding the appropriate level of violence following strategic instructions, the choice of {LLM}, and whether the {LLMs} are tasked to decide for a team of players directly or first to simulate dialog between a team of players. When simulating the dialog, the discussions lack quality and maintain a farcical harmony. The {LLM} simulations cannot account for human player characteristics, showing no significant difference even for extreme traits, such as "pacifist" or "aggressive sociopath." When probing behavioral consistency across individual moves of the simulation, the tested {LLMs} deviated from each other but generally showed somewhat consistent behavior. Our results motivate policymakers to be cautious before granting autonomy or following {AI}-based strategy recommendations.},
	number = {{arXiv}:2403.03407},
	publisher = {{arXiv}},
	author = {Lamparth, Max and Corso, Anthony and Ganz, Jacob and Mastro, Oriana Skylar and Schneider, Jacquelyn and Trinkunas, Harold},
	urldate = {2025-09-12},
	date = {2024-10-03},
	eprinttype = {arxiv},
	eprint = {2403.03407 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
}

@article{lamparth_human_2024-1,
	title = {Human vs. Machine: Behavioral Differences between Expert Humans and Language Models in Wargame Simulations},
	volume = {7},
	issn = {3065-8365},
	url = {https://ojs.aaai.org/index.php/AIES/article/view/31681},
	doi = {10.1609/aies.v7i1.31681},
	shorttitle = {Human vs. Machine},
	abstract = {To some, the advent of artificial intelligence ({AI}) promises better decision-making and increased military effectiveness while reducing the influence of human error and emotions. However, there is still debate about how {AI} systems, especially large language models ({LLMs}) that can be applied to many tasks, behave compared to humans in high-stakes military decision-making scenarios with the potential for increased risks towards escalation and unnecessary conflicts. To test this potential and scrutinize the use of {LLMs} for such purposes, we use a new wargame experiment with 107 national security experts designed to examine crisis escalation in a fictional {US}-China scenario and compare the behavior of human player teams to {LLM}-simulated team responses in separate simulations. Wargames have a long history in the development of military strategy and the response of nations to threats or attacks. Here, we find that the {LLM}-simulated responses can be more aggressive and significantly affected by changes in the scenario. We show a considerable high-level agreement in the {LLM} and human responses and significant quantitative and qualitative differences in individual actions and strategic tendencies. These differences depend on intrinsic biases in {LLMs} regarding the appropriate level of violence following strategic instructions, the choice of {LLM}, and whether the {LLMs} are tasked to decide for a team of players directly or first to simulate dialog between a team of players. When simulating the dialog, the discussions lack quality and maintain a farcical harmony. The {LLM} simulations cannot account for human player characteristics, showing no significant difference even for extreme traits, such as “pacifist” or “aggressive sociopath.” When probing behavioral consistency across individual moves of the simulation, the tested {LLMs} deviated from each other but generally showed somewhat consistent behavior. Our results motivate policymakers to be cautious before granting autonomy or following {AI}-based strategy recommendations.},
	pages = {807--817},
	journaltitle = {Proceedings of the {AAAI}/{ACM} Conference on {AI}, Ethics, and Society},
	shortjournal = {{AIES}},
	author = {Lamparth, Max and Corso, Anthony and Ganz, Jacob and Mastro, Oriana Skylar and Schneider, Jacquelyn and Trinkunas, Harold},
	urldate = {2025-09-12},
	date = {2024-10-16},
}

@misc{lamparth_human_2024-2,
	title = {Human vs. Machine: Behavioral Differences Between Expert Humans and Language Models in Wargame Simulations},
	url = {http://arxiv.org/abs/2403.03407},
	doi = {10.48550/arXiv.2403.03407},
	shorttitle = {Human vs. Machine},
	abstract = {To some, the advent of artificial intelligence ({AI}) promises better decision-making and increased military effectiveness while reducing the influence of human error and emotions. However, there is still debate about how {AI} systems, especially large language models ({LLMs}) that can be applied to many tasks, behave compared to humans in high-stakes military decision-making scenarios with the potential for increased risks towards escalation. To test this potential and scrutinize the use of {LLMs} for such purposes, we use a new wargame experiment with 214 national security experts designed to examine crisis escalation in a fictional U.S.-China scenario and compare the behavior of human player teams to {LLM}-simulated team responses in separate simulations. Here, we find that the {LLM}-simulated responses can be more aggressive and significantly affected by changes in the scenario. We show a considerable high-level agreement in the {LLM} and human responses and significant quantitative and qualitative differences in individual actions and strategic tendencies. These differences depend on intrinsic biases in {LLMs} regarding the appropriate level of violence following strategic instructions, the choice of {LLM}, and whether the {LLMs} are tasked to decide for a team of players directly or first to simulate dialog between a team of players. When simulating the dialog, the discussions lack quality and maintain a farcical harmony. The {LLM} simulations cannot account for human player characteristics, showing no significant difference even for extreme traits, such as "pacifist" or "aggressive sociopath." When probing behavioral consistency across individual moves of the simulation, the tested {LLMs} deviated from each other but generally showed somewhat consistent behavior. Our results motivate policymakers to be cautious before granting autonomy or following {AI}-based strategy recommendations.},
	number = {{arXiv}:2403.03407},
	publisher = {{arXiv}},
	author = {Lamparth, Max and Corso, Anthony and Ganz, Jacob and Mastro, Oriana Skylar and Schneider, Jacquelyn and Trinkunas, Harold},
	urldate = {2025-09-13},
	date = {2024-10-03},
	eprinttype = {arxiv},
	eprint = {2403.03407 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
}

@report{ehsan_human-centered_2020,
	title = {Human-Centered Explainable {AI}: Towards a Reflective Sociotechnical Approach},
	url = {https://arxiv.org/abs/2002.01092},
	author = {Ehsan, Upol and Riedl, Mark O.},
	date = {2020},
	doi = {10.48550/arXiv.2002.01092},
}

@article{meta_fundamental_ai_research_diplomacy_team_human-level_2022,
	title = {Human-level play in the game of Diplomacy by combining language models with strategic reasoning},
	volume = {378},
	issn = {0036-8075},
	url = {http://dx.doi.org/10.1126/science.ade9097},
	doi = {10.1126/science.ade9097},
	abstract = {Despite much progress in training artificial intelligence ({AI}) systems to
imitate human language, building agents that use language to communicate
intentionally with humans in interactive environments remains a major
challenge. We introduce Cicero, the first {AI} agent to achieve human-level
performance in Diplomacy, a strategy game involving both cooperation and
competition that emphasizes natural language negotiation and tactical
coordination between seven players. Cicero integrates a language model
with planning and reinforcement learning algorithms by inferring players'
beliefs and intentions from its conversations and generating dialogue in
pursuit of its plans. Across 40 games of an anonymous online Diplomacy
league, Cicero achieved more than double the average score of the human
players and ranked in the top 10\% of participants who played more than one
game.},
	pages = {1067--1074},
	number = {6624},
	journaltitle = {Science},
	author = {{Meta Fundamental AI Research Diplomacy Team} and Bakhtin, Anton and Brown, Noam and Dinan, Emily and Farina, Gabriele and Flaherty, Colin and Fried, Daniel and Goff, Andrew and Gray, Jonathan and Hu, Hengyuan and Jacob, Athul Paul and Komeili, Mojtaba and Konath, Karthik and Kwon, Minae and Lerer, Adam and Lewis, Mike and Miller, Alexander H and Mitts, Sasha and Renduchintala, Adithya and Roller, Stephen and Rowe, Dirk and Shi, Weiyan and Spisak, Joe and Wei, Alexander and Wu, David and Zhang, Hugh and Zijlstra, Markus},
	date = {2022-12-09},
	note = {Publisher: American Association for the Advancement of Science ({AAAS})},
}

@book{davis_illustrating_2017,
	title = {Illustrating a Model-Game-Model Paradigm for Using Human Wargames in Analysis},
	url = {http://www.rand.org/pubs/working_papers/WR1179.html},
	publisher = {{RAND} Corporation},
	author = {Davis, Paul},
	urldate = {2025-09-08},
	date = {2017},
	langid = {english},
	doi = {10.7249/WR1179},
}

@unpublished{du_improving_2023,
	title = {Improving factuality and reasoning in language models through multiagent debate},
	url = {https://www.semanticscholar.org/paper/4780d0a027c5c5a8e01d7cf697f6296880ffc945},
	abstract = {Large language models ({LLMs}) have demonstrated remarkable capabilities in
language generation, understanding, and few-shot learning in recent years.
An extensive body of work has explored how their performance may be
further improved through the tools of prompting, ranging from
verification, self-consistency, or intermediate scratchpads. In this
paper, we present a complementary approach to improve language responses
where multiple language model instances propose and debate their
individual responses and reasoning processes over multiple rounds to
arrive at a common final answer. Our findings indicate that this approach
significantly enhances mathematical and strategic reasoning across a
number of tasks. We also demonstrate that our approach improves the
factual validity of generated content, reducing fallacious answers and
hallucinations that contemporary models are prone to. Our approach may be
directly applied to existing black-box models and uses identical procedure
and prompts for all tasks we investigate. Overall, our findings suggest
that such "society of minds" approach has the potential to significantly
advance the capabilities of {LLMs} and pave the way for further
breakthroughs in language generation and understanding.},
	author = {Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
	urldate = {2024-09-22},
	date = {2023-05-23},
	doi = {10.48550/arXiv.2305.14325},
	note = {{ISBN}: 2305.14325
Publication Title: {arXiv} [cs.{CL}]},
}

@article{wright_improving_2017,
	title = {Improving scenario methodology: theory and practice, introduction to the special issue},
	volume = {124},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162517309010},
	doi = {10.1016/j.techfore.2017.07.004},
	shorttitle = {Improving scenario methodology},
	abstract = {In this Introduction, we review the logic that underpinned our earlier call for papers and compare and contrast the papers selected with those selected for a similarly-themed special issue of this journal that was published in 2013. We demonstrate changing research emphases and concerns and then go on to review the contents of the eighteen selected papers that comprise the current special issue.},
	pages = {1--5},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Wright, George and Meadows, Maureen and Tapinos, Stathis and O'Brien, Frances and Pyper, Neil},
	urldate = {2025-06-12},
	date = {2017-11-01},
}

@misc{chalnev_improving_2024,
	title = {Improving Steering Vectors by Targeting Sparse Autoencoder Features},
	url = {http://arxiv.org/abs/2411.02193},
	doi = {10.48550/arXiv.2411.02193},
	abstract = {To control the behavior of language models, steering methods attempt to ensure that outputs of the model satisfy specific pre-defined properties. Adding steering vectors to the model is a promising method of model control that is easier than finetuning, and may be more robust than prompting. However, it can be difficult to anticipate the effects of steering vectors produced by methods such as {CAA} [Panickssery et al., 2024] or the direct use of {SAE} latents [Templeton et al., 2024]. In our work, we address this issue by using {SAEs} to measure the effects of steering vectors, giving us a method that can be used to understand the causal effect of any steering vector intervention. We use this method for measuring causal effects to develop an improved steering method, {SAE}-Targeted Steering ({SAE}-{TS}), which finds steering vectors to target specific {SAE} features while minimizing unintended side effects. We show that overall, {SAE}-{TS} balances steering effects with coherence better than {CAA} and {SAE} feature steering, when evaluated on a range of tasks.},
	number = {{arXiv}:2411.02193},
	publisher = {{arXiv}},
	author = {Chalnev, Sviatoslav and Siu, Matthew and Conmy, Arthur},
	urldate = {2025-09-13},
	date = {2024-11-21},
	eprinttype = {arxiv},
	eprint = {2411.02193 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{van_dorsser_improving_2018,
	title = {Improving the link between the futures field and policymaking},
	volume = {104},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328717302513},
	doi = {10.1016/j.futures.2018.05.004},
	abstract = {Policymakers need to make policies for unknown and uncertain futures. Researchers in the futures field have a great deal to contribute to the policymaking process. But, futures research is often neglected as an element of policymaking. The aim of this paper is to improve the link between futures research and policymaking. More specifically, as Policy Analysis has a strong link with policymaking, this paper explores the possibility of linking Policy Analysis to the futures field through the use of an uncertainty typology applied in Policy Analysis. The typology can be used to structure the various forward-looking disciplines (or subfields) of the futures field according to the level of uncertainty that they address. This linkage can add significantly to the use of futures research in policymaking.},
	pages = {75--84},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {van Dorsser, Cornelis and Walker, Warren E. and Taneja, Poonam and Marchau, Vincent A. W. J.},
	urldate = {2025-06-12},
	date = {2018-12-01},
	keywords = {Forecasting, Foresight, Futures studies, Policy analysis, Uncertainty},
}

@report{robinson_stride_2018,
	title = {In Stride Adjudication Working Group Report},
	url = {https://connections-wargaming.com/wp-content/uploads/2021/01/in-stride-adjudication-working-group- report-20180908.pdf},
	institution = {Connections {US} ({NDU}) Working Group},
	author = {Robinson, Merle and Downes-Martin, Stephen and {Connections US WG}},
	date = {2018},
}

@misc{ahmad_ina_2023,
	title = {{INA}: An Integrative Approach for Enhancing Negotiation Strategies with Reward-Based Dialogue System},
	url = {http://arxiv.org/abs/2310.18207},
	doi = {10.48550/arXiv.2310.18207},
	shorttitle = {{INA}},
	abstract = {In this paper, we propose a novel negotiation dialogue agent designed for the online marketplace. Our agent is integrative in nature i.e, it possesses the capability to negotiate on price as well as other factors, such as the addition or removal of items from a deal bundle, thereby offering a more flexible and comprehensive negotiation experience. We create a new dataset called Integrative Negotiation Dataset ({IND}) to enable this functionality. For this dataset creation, we introduce a new semi-automated data creation method, which combines defining negotiation intents, actions, and intent-action simulation between users and the agent to generate potential dialogue flows. Finally, the prompting of {GPT}-J, a state-of-the-art language model, is done to generate dialogues for a given intent, with a human-in-the-loop process for post-editing and refining minor errors to ensure high data quality. We employ a set of novel rewards, specifically tailored for the negotiation task to train our Negotiation Agent, termed as the Integrative Negotiation Agent ({INA}). These rewards incentivize the chatbot to learn effective negotiation strategies that can adapt to various contextual requirements and price proposals. By leveraging the {IND}, we train our model and conduct experiments to evaluate the effectiveness of our reward-based dialogue system for negotiation. Our results demonstrate that the proposed approach and reward system significantly enhance the agent's negotiation capabilities. The {INA} successfully engages in integrative negotiations, displaying the ability to dynamically adjust prices and negotiate the inclusion or exclusion of items in a bundle deal},
	number = {{arXiv}:2310.18207},
	publisher = {{arXiv}},
	author = {Ahmad, Zishan and Saurabh, Suman and Menon, Vaishakh Sreekanth and Ekbal, Asif and Ramnani, Roshni and Maitra, Anutosh},
	urldate = {2025-09-08},
	date = {2023-10-27},
	eprinttype = {arxiv},
	eprint = {2310.18207 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{zhang_infinitybench_2024,
	title = {{InfinityBench}: Extending Long Context Evaluation Beyond 100K Tokens},
	url = {http://arxiv.org/abs/2402.13718},
	doi = {10.48550/arXiv.2402.13718},
	shorttitle = {\${\textbackslash}infty\$Bench},
	abstract = {Processing and reasoning over long contexts is crucial for many practical applications of Large Language Models ({LLMs}), such as document comprehension and agent construction. Despite recent strides in making {LLMs} process contexts with more than 100K tokens, there is currently a lack of a standardized benchmark to evaluate this long-context capability. Existing public benchmarks typically focus on contexts around 10K tokens, limiting the assessment and comparison of {LLMs} in processing longer contexts. In this paper, we propose \${\textbackslash}infty\$Bench, the first {LLM} benchmark featuring an average data length surpassing 100K tokens. \${\textbackslash}infty\$Bench comprises synthetic and realistic tasks spanning diverse domains, presented in both English and Chinese. The tasks in \${\textbackslash}infty\$Bench are designed to require well understanding of long dependencies in contexts, and make simply retrieving a limited number of passages from contexts not sufficient for these tasks. In our experiments, based on \${\textbackslash}infty\$Bench, we evaluate the state-of-the-art proprietary and open-source {LLMs} tailored for processing long contexts. The results indicate that existing long context {LLMs} still require significant advancements to effectively process 100K+ context. We further present three intriguing analyses regarding the behavior of {LLMs} processing long context.},
	number = {{arXiv}:2402.13718},
	publisher = {{arXiv}},
	author = {Zhang, Xinrong and Chen, Yingfa and Hu, Shengding and Xu, Zihang and Chen, Junhao and Hao, Moo Khai and Han, Xu and Thai, Zhen Leng and Wang, Shuo and Liu, Zhiyuan and Sun, Maosong},
	urldate = {2025-09-13},
	date = {2024-02-24},
	eprinttype = {arxiv},
	eprint = {2402.13718 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@report{uk_ministry_of_defence_influence_2023,
	location = {United Kingdom},
	title = {Influence Wargaming Handbook},
	url = {https://www.gov.uk/government/publications/influence-wargaming-handbook},
	institution = {Development, Concepts and Doctrine Centre},
	author = {{UK Ministry of Defence}},
	date = {2023-07-06},
	langid = {english},
}

@article{chermack_integrating_2015,
	title = {Integrating scenario planning and design thinking: Learnings from the 2014 Oxford Futures Forum},
	volume = {74},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328715000981},
	doi = {10.1016/j.futures.2015.07.014},
	shorttitle = {Integrating scenario planning and design thinking},
	abstract = {This issue of Futures has covered a lot of ground and much of it breaks new ground. It is not too bold to write that these articles have added new thinking to the scenario and design literatures. Even bolder, we believe that human existence and long-term sustainability are predicated in part on the ideas in this issue of Futures. In his recent book The Meaning of Human Existence, Pulitzer Prize winning Biologist E.O. Wilson wrote: premier among the consequences [of human existence] is the capacity to imagine possible futures, and to plan and choose among them. How wisely we use this uniquely human ability depends on the accuracy of our self-understanding. The question of greatest relevant interest is how and why we are the way we are, and from that, the meaning of our many competing visions of the future. Wilson, 2014, p. 14.},
	pages = {71--77},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Chermack, Thomas J. and Coons, Laura M.},
	urldate = {2025-06-12},
	date = {2015-11-01},
	keywords = {Design thinking, Oxford futures forum, Scenario planning},
}

@article{sun_intelligent_2023,
	title = {Intelligent Decision-Making and Human Language Communication Based on Deep Reinforcement Learning in a Wargame Environment},
	volume = {53},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {2168-2291, 2168-2305},
	url = {https://ieeexplore.ieee.org/document/9979044/},
	doi = {10.1109/THMS.2022.3225867},
	abstract = {The application of artificial intelligence ({AI}) in games has been significantly developed and attracted much attention over the past few years. This article not only leverages the reinforcement learning multiagent deep deterministic policy gradient algorithm to realize the dynamic decision-making of game {AI} but also creatively incorporates deep learning and natural language processing technologies in the wargame field to transform game context situation maps into textual suggestions in wargame confrontation. In this article, we effectively integrate reinforcement learning technologies, deep learning technologies, and natural language processing technologies to generalize the semantic text output at state-of-the-art accuracy, which plays an important role in human understanding of game {AI} behavior. The experimental results are promising and can be used to verify the feasibility, accuracy, and performance of our proposed model in extensive simulations against benchmarking methods.},
	pages = {201--214},
	number = {1},
	journaltitle = {{IEEE} Transactions on Human-Machine Systems},
	shortjournal = {{IEEE} Trans. Human-Mach. Syst.},
	author = {Sun, Yuxiang and Yuan, Bo and Xiang, Qi and Zhou, Jiawei and Yu, Jiahui and Dai, Di and Zhou, Xianzhong},
	urldate = {2025-09-13},
	date = {2023-02},
}

@article{nax_interactive_2015,
	title = {Interactive preferences},
	volume = {135},
	issn = {0165-1765},
	url = {https://www.sciencedirect.com/science/article/pii/S0165176515003158},
	doi = {10.1016/j.econlet.2015.08.008},
	abstract = {Game theory presumes that agents have unique preference orderings over outcomes that prescribe unique preference orderings over actions in response to other players’ actions, independent of other players’ preferences. This independence assumption is necessary to permit game-theoretic best response reasoning, but at odds with introspection, because preferences toward one another often dynamically depend on each other. In this note, we propose a model of interactive preferences. The model is validated with data from a laboratory experiment. The main finding of our study is that pro-sociality diminishes over the course of the interactions.},
	pages = {133--136},
	journaltitle = {Economics Letters},
	shortjournal = {Economics Letters},
	author = {Nax, Heinrich H. and Murphy, Ryan O. and Ackermann, Kurt A.},
	urldate = {2025-06-12},
	date = {2015-10-01},
	keywords = {Game theory, Preference evolution, Social preferences},
}

@article{croatian_military_academy_introduction_2019,
	title = {Introduction to Wargaming},
	abstract = {Welcome to the World of Gaming and Wargaming. Games, well percepted as nothing more than entertainment, are in fact hard working job that we choose for ourselves and that makes us happy.},
	author = {Croatian Military Academy},
	date = {2019},
	langid = {english},
}

@article{sun_intuitionistic_2024,
	title = {Intuitionistic Fuzzy {MADM} in Wargame Leveraging With Deep Reinforcement Learning},
	volume = {32},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1063-6706, 1941-0034},
	url = {https://ieeexplore.ieee.org/document/10614867/},
	doi = {10.1109/TFUZZ.2024.3435400},
	abstract = {Presently, intelligent games have emerged as a substantial research area. Nonetheless, the slow convergence of intelligent wargame training and the low success rates of agents against specific rules present challenges. In this article, we propose a game confrontation algorithm combining the multiple attribute decision making ({MADM}) approach from management science and reinforcement learning ({RL}) technology. This integration enables us to combine the strengths of both approaches and addresses the above issues effectively. This study conducts experiments using the algorithm that integrates {MADM} and {RL} techniques to gather confrontation data from the red and blue sides within the winning-first wargame platform. The data is then analyzed using the weight calculation method of intuitionistic fuzzy numbers to determine each intelligent opponent agent's threat level from the perspective of {MADM}. The threat level calculated by {MADM} is used to construct the reward function for the red side. The simulation results demonstrate that the algorithm combining {MADM} and {RL} proposed in this study outperforms classical {RL} algorithms regarding intelligence. This approach effectively addresses issues, such as the convergence difficulty, caused by random initialization and the sparse rewards for agent neural networks in wargame environments with large maps. Combining the {MADM} method from management with the {RL} algorithm in control can lead to cross-disciplinary innovation in academic fields, which provides innovative research values for intelligent wargame design and {RL} algorithm improvements.},
	pages = {5033--5045},
	number = {9},
	journaltitle = {{IEEE} Transactions on Fuzzy Systems},
	shortjournal = {{IEEE} Trans. Fuzzy Syst.},
	author = {Sun, Yuxiang and Li, Yuanbai and Li, Huaxiong and Liu, Jiubing and Zhou, Xianzhong},
	urldate = {2025-09-13},
	date = {2024-09},
}

@article{jeon_investment_2021,
	title = {Investment timing and capacity decisions with time-to-build in a duopoly market},
	volume = {122},
	issn = {0165-1889},
	url = {https://www.sciencedirect.com/science/article/pii/S0165188920301962},
	doi = {10.1016/j.jedc.2020.104028},
	abstract = {In this study, we investigate optimal investment timing and capacity decisions in the presence of time-to-build and competition. Due to uncertain time-to-build, a leader, who invests first, may have its product enter the market after a follower’s. We show that a dominated firm with the longer time-to-build can become a leader by making the investment earlier than a dominant firm with shorter investment lags. The leader’s capacity choice increases with the dominated firm’s time-to-build, even if the dominated entity is the leader. This finding is consistent with the observation in the electric vehicles market in which a relatively new firm with little experience of mass production makes aggressive investment early on, while the biggest carmakers capable of mass production are timing their investment. With a welfare-maximizing policy, however, the dominant firm with the shorter time-to-build always becomes the leader. There is a significant loss of social welfare with the dominated firm being the leader, and the loss increases with the asymmetry of time-to-build.},
	pages = {104028},
	journaltitle = {Journal of Economic Dynamics and Control},
	shortjournal = {Journal of Economic Dynamics and Control},
	author = {Jeon, Haejun},
	urldate = {2025-06-12},
	date = {2021-01-01},
	keywords = {Duopoly market, Investment capacity, Investment lags, Real options, Time-to-build},
}

@inproceedings{lohn_is_2024,
	location = {Tokyo, Japan},
	title = {Is Machine Psychology here? On Requirements for Using Human Psychological Tests on Large Language Models},
	url = {https://aclanthology.org/2024.inlg-main.19/},
	doi = {10.18653/v1/2024.inlg-main.19},
	shorttitle = {Is Machine Psychology here?},
	abstract = {In an effort to better understand the behavior of large language models ({LLM}), researchers recently turned to conducting psychological assessments on them. Several studies diagnose various psychological concepts in {LLMs}, such as psychopathological symptoms, personality traits, and intellectual functioning, aiming to unravel their black-box characteristics. But can we safely assess {LLMs} with tests that were originally designed for humans? The psychology domain looks back on decades of developing standards of appropriate testing procedures to ensure reliable and valid measures. We argue that analogous standardization processes are required for {LLM} assessments, given their differential functioning as compared to humans. In this paper, we propose seven requirements necessary for testing {LLMs}. Based on these, we critically reflect a sample of 25 recent machine psychology studies. Our analysis reveals (1) the lack of appropriate methods to assess test reliability and construct validity, (2) the unknown strength of construct-irrelevant influences, such as the contamination of pre-training corpora with test material, and (3) the pervasive issue of non-reproducibility of many studies. The results underscore the lack of a general methodology for the implementation of psychological assessments of {LLMs} and the need to redefine psychological constructs specifically for large language models rather than adopting them from human psychology.},
	eventtitle = {{INLG} 2024},
	pages = {230--242},
	booktitle = {Proceedings of the 17th International Natural Language Generation Conference},
	publisher = {Association for Computational Linguistics},
	author = {Löhn, Lea and Kiehne, Niklas and Ljapunov, Alexander and Balke, Wolf-Tilo},
	editor = {Mahamood, Saad and Minh, Nguyen Le and Ippolito, Daphne},
	urldate = {2025-06-12},
	date = {2024-09},
}

@article{roth_is_2016,
	title = {Is the future a political economy? Functional analysis of three leading foresight and futures studies journals},
	volume = {81},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328715001366},
	doi = {10.1016/j.futures.2015.10.002},
	series = {Modelling and Simulation in Futures Studies},
	shorttitle = {Is the future a political economy?},
	abstract = {This article tests whether the field of foresight and futures studies shows significant variable selection biases in the modelling of the future in general and the impact of function systems in particular. We performed a word frequency analysis to measure the relative importance of the political system, the economy, science, art, religion, law, sport, health, education, and the mass media to three pertinent journals in the field of futures studies and foresight. The results show that Futures, Long Range Planning, and Technological Forecasting and Social Change have different and changing preferences for the above function systems, an information which authors may find helpful in supporting decisions on where to submit. Our results also show that all journals feature a highly significant bias to the triple helix systems – the political system, the economy, and science. While the latter bias may be adequate to scientific journals, the dominant focus on the political system and the economy as well as the corresponding neglect of the other systems points at implicit presumptions about the importance of the individual systems that may not be in line with their importance to the larger society.},
	pages = {15--26},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Roth, Steffen and Kaivo-oja, Jari},
	urldate = {2025-06-12},
	date = {2016-08-01},
	keywords = {Function systems, Functional differentiation, Key variables, Modelling, Social systems},
}

@article{korner_it_2021,
	title = {It is not all for the same reason! Predicting motives in miniature wargaming on the basis of personality traits},
	volume = {173},
	issn = {0191-8869},
	url = {https://www.sciencedirect.com/science/article/pii/S0191886921000143},
	doi = {10.1016/j.paid.2021.110639},
	abstract = {Despite the increasing popularity of miniature wargames ({MWGs}), research on this pastime is still scarce. We aimed to understand how personality is related to motivations for playing {MWGs}. A world sample of 8590 {MWG} players was tested with the Ten-Item Personality Inventory to assess the Big Five and the Trojan Player Typology to measure gaming motivations. The latter scale was used for the first time in non-video-game players and showed good psychometric properties. Results showed several significant associations between personality and motivations for engaging in these games. People who played {MWGs} to socialize were high in openness and extraversion. Players high in agreeableness did not want to compete and did not emphasize winning as an important factor. People who played to escape from everyday problems reported high levels of neuroticism. Story-driven gamers described themselves as open and agreeable. Clearly, personality is relevant for predicting the attractiveness of {MWGs}, and the game has different aspects of attractiveness for different groups. The results help to better explain the phenomenon of {MWGs} and highlight the role of personality in this pastime. Avenues for future research such as the use of behavioral measures in playing {MWGs} are discussed.},
	pages = {110639},
	journaltitle = {Personality and Individual Differences},
	shortjournal = {Personality and Individual Differences},
	author = {Körner, Robert and Schütz, Astrid},
	urldate = {2025-06-12},
	date = {2021-04-01},
	keywords = {Big Five, Competition, Escape, Miniature wargames, Motivations, Personality, Play motivation, Socializing},
}

@misc{jaidka_it_2023,
	title = {It Takes Two to Negotiate: Modeling Social Exchange in Online Multiplayer Games},
	url = {http://arxiv.org/abs/2311.08666},
	doi = {10.48550/arXiv.2311.08666},
	shorttitle = {It Takes Two to Negotiate},
	abstract = {Online games are dynamic environments where players interact with each other, which offers a rich setting for understanding how players negotiate their way through the game to an ultimate victory. This work studies online player interactions during the turn-based strategy game, Diplomacy. We annotated a dataset of over 10,000 chat messages for different negotiation strategies and empirically examined their importance in predicting long- and short-term game outcomes. Although negotiation strategies can be predicted reasonably accurately through the linguistic modeling of the chat messages, more is needed for predicting short-term outcomes such as trustworthiness. On the other hand, they are essential in graph-aware reinforcement learning approaches to predict long-term outcomes, such as a player's success, based on their prior negotiation history. We close with a discussion of the implications and impact of our work. The dataset is available at https://github.com/kj2013/claff-diplomacy.},
	number = {{arXiv}:2311.08666},
	publisher = {{arXiv}},
	author = {Jaidka, Kokil and Ahuja, Hansin and Ng, Lynnette},
	urldate = {2025-09-12},
	date = {2023-11-15},
	eprinttype = {arxiv},
	eprint = {2311.08666 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning},
}

@misc{wallman_its_1995,
	title = {It's Only A Game: Game Design Methodology},
	url = {https://www.professionalwargaming.co.uk/ItsOnlyAGame-Wallman.pdf},
	author = {Wallman, Jim},
	urldate = {2025-06-26},
	date = {1995},
}

@misc{zhang_k-level_2024,
	title = {K-Level Reasoning: Establishing Higher Order Beliefs in Large Language Models for Strategic Reasoning},
	url = {http://arxiv.org/abs/2402.01521},
	doi = {10.48550/arXiv.2402.01521},
	shorttitle = {K-Level Reasoning},
	abstract = {Strategic reasoning is a complex yet essential capability for intelligent agents. It requires Large Language Model ({LLM}) agents to adapt their strategies dynamically in multi-agent environments. Unlike static reasoning tasks, success in these contexts depends on anticipating other agents' beliefs and actions while continuously adjusting strategies to achieve individual goals. {LLMs} and {LLM} agents often struggle with strategic reasoning due to the absence of a reasoning framework that enables them to dynamically infer others' perspectives and adapt to changing environments. Inspired by the Level-K framework from game theory and behavioral economics, which extends reasoning from simple reactions to structured strategic depth, we propose a novel framework: "K-Level Reasoning with Large Language Models (K-R)." This framework employs recursive mechanisms to enable {LLMs} to achieve varying levels of strategic depth, allowing agents to form higher order beliefs - beliefs about others' beliefs. We validate this framework through rigorous testing on four testbeds: two classical game theory problems and two social intelligence tasks. The results demonstrate the advantages of K-R in strategic reasoning. Our work presents the first recursive implementation of strategic depth in large language models ({LLMs}). It establishes a foundation for future research into theory of mind and strategic reasoning in {LLMs}.},
	number = {{arXiv}:2402.01521},
	publisher = {{arXiv}},
	author = {Zhang, Yadong and Mao, Shaoguang and Ge, Tao and Wang, Xun and Xia, Yan and Lan, Man and Wei, Furu},
	urldate = {2025-09-08},
	date = {2024-10-17},
	eprinttype = {arxiv},
	eprint = {2402.01521 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@book{von_reisswitz-kaderzin_und_grabowska_kriegsspiel_1989,
	location = {England, United Kingdom},
	title = {Kriegsspiel : instructions for the representation of military manoeuvres with the Kriegsspiel apparatus},
	isbn = {1-870341-07-4},
	url = {https://searchworks.stanford.edu/view/4789183},
	publisher = {[Hemel Hempstead] : Bill Leeson},
	author = {Von Reisswitz-Kaderzin und Grabowska, Freiherr, 1795-1827, Georg Heinrich Leopold and Leeson, Bill},
	date = {1989},
	keywords = {War games Rules.},
}

@unpublished{xu_language_2023,
	title = {Language agents with reinforcement learning for strategic play in the Werewolf game},
	url = {http://arxiv.org/abs/2310.18940},
	abstract = {Agents built with large language models ({LLMs}) have shown great potential
across a wide range of domains. However, in complex decision-making tasks,
pure {LLM}-based agents tend to exhibit intrinsic bias in their choice of
actions, which is inherited from the model's training data and results in
suboptimal performance. To develop strategic language agents, i.e., agents
that generate flexible language actions and possess strong decision-making
abilities, we propose a novel framework that powers {LLM}-based agents with
reinforcement learning ({RL}). We consider Werewolf, a popular social
deduction game, as a challenging testbed that emphasizes versatile
communication and strategic gameplay. To mitigate the intrinsic bias in
language actions, our agents use an {LLM} to perform deductive reasoning and
generate a diverse set of action candidates. Then an {RL} policy trained to
optimize the decision-making ability chooses an action from the candidates
to play in the game. Extensive experiments show that our agents overcome
the intrinsic bias and outperform existing {LLM}-based agents in the
Werewolf game. We also conduct human-agent experiments and find that our
agents achieve human-level performance and demonstrate strong strategic
play.},
	author = {Xu, Zelai and Yu, Chao and Fang, Fei and Wang, Yu and Wu, Yi},
	date = {2023-10-29},
	note = {{ISBN}: 2310.18940
Publication Title: {arXiv} [cs.{AI}]},
}

@misc{turpin_language_2023,
	title = {Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting},
	url = {http://arxiv.org/abs/2305.04388},
	doi = {10.48550/arXiv.2305.04388},
	shorttitle = {Language Models Don't Always Say What They Think},
	abstract = {Large Language Models ({LLMs}) can achieve strong performance on many tasks by producing step-by-step reasoning before giving a final output, often referred to as chain-of-thought reasoning ({CoT}). It is tempting to interpret these {CoT} explanations as the {LLM}'s process for solving a task. This level of transparency into {LLMs}' predictions would yield significant safety benefits. However, we find that {CoT} explanations can systematically misrepresent the true reason for a model's prediction. We demonstrate that {CoT} explanations can be heavily influenced by adding biasing features to model inputs--e.g., by reordering the multiple-choice options in a few-shot prompt to make the answer always "(A)"--which models systematically fail to mention in their explanations. When we bias models toward incorrect answers, they frequently generate {CoT} explanations rationalizing those answers. This causes accuracy to drop by as much as 36\% on a suite of 13 tasks from {BIG}-Bench Hard, when testing with {GPT}-3.5 from {OpenAI} and Claude 1.0 from Anthropic. On a social-bias task, model explanations justify giving answers in line with stereotypes without mentioning the influence of these social biases. Our findings indicate that {CoT} explanations can be plausible yet misleading, which risks increasing our trust in {LLMs} without guaranteeing their safety. Building more transparent and explainable systems will require either improving {CoT} faithfulness through targeted efforts or abandoning {CoT} in favor of alternative methods.},
	number = {{arXiv}:2305.04388},
	publisher = {{arXiv}},
	author = {Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel R.},
	urldate = {2025-09-10},
	date = {2023-12-09},
	eprinttype = {arxiv},
	eprint = {2305.04388 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{schoenegger_large_2025,
	title = {Large Language Models Are More Persuasive Than Incentivized Human Persuaders},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2505.09662},
	doi = {10.48550/ARXIV.2505.09662},
	abstract = {We directly compare the persuasion capabilities of a frontier large language model ({LLM}; Claude Sonnet 3.5) against incentivized human persuaders in an interactive, real-time conversational quiz setting. In this preregistered, large-scale incentivized experiment, participants (quiz takers) completed an online quiz where persuaders (either humans or {LLMs}) attempted to persuade quiz takers toward correct or incorrect answers. We find that {LLM} persuaders achieved significantly higher compliance with their directional persuasion attempts than incentivized human persuaders, demonstrating superior persuasive capabilities in both truthful (toward correct answers) and deceptive (toward incorrect answers) contexts. We also find that {LLM} persuaders significantly increased quiz takers' accuracy, leading to higher earnings, when steering quiz takers toward correct answers, and significantly decreased their accuracy, leading to lower earnings, when steering them toward incorrect answers. Overall, our findings suggest that {AI}'s persuasion capabilities already exceed those of humans that have real-money bonuses tied to performance. Our findings of increasingly capable {AI} persuaders thus underscore the urgency of emerging alignment and governance frameworks.},
	publisher = {{arXiv}},
	author = {Schoenegger, Philipp and Salvi, Francesco and Liu, Jiacheng and Nan, Xiaoli and Debnath, Ramit and Fasolo, Barbara and Leivada, Evelina and Recchia, Gabriel and Günther, Fritz and Zarifhonarvar, Ali and Kwon, Joe and Islam, Zahoor Ul and Dehnert, Marco and Lee, Daryl Y. H. and Reinecke, Madeline G. and Kamper, David G. and Kobaş, Mert and Sandford, Adam and Kgomo, Jonas and Hewitt, Luke and Kapoor, Shreya and Oktar, Kerem and Kucuk, Eyup Engin and Feng, Bo and Jones, Cameron R. and Gainsburg, Izzy and Olschewski, Sebastian and Heinzelmann, Nora and Cruz, Francisco and Tappin, Ben M. and Ma, Tao and Park, Peter S. and Onyonka, Rayan and Hjorth, Arthur and Slattery, Peter and Zeng, Qingcheng and Finke, Lennart and Grossmann, Igor and Salatiello, Alessandro and Karger, Ezra},
	urldate = {2025-06-12},
	date = {2025},
	note = {Version Number: 2},
	keywords = {Computation and Language (cs.{CL}), {FOS}: Computer and information sciences, I.2.7; H.1.2; K.4.1; H.5.2},
}

@article{gao_large_2024,
	title = {Large language models empowered agent-based modeling and simulation: a survey and perspectives},
	volume = {11},
	issn = {2662-9992},
	url = {https://www.nature.com/articles/s41599-024-03611-3},
	doi = {10.1057/s41599-024-03611-3},
	shorttitle = {Large language models empowered agent-based modeling and simulation},
	abstract = {Abstract
            
              Agent-based modeling and simulation have evolved as a powerful tool for modeling complex systems, offering insights into emergent behaviors and interactions among diverse agents. Recently, integrating large language models into agent-based modeling and simulation presents a promising avenue for enhancing simulation capabilities. This paper surveys the landscape of utilizing large language models in agent-based modeling and simulation, discussing their challenges and promising future directions. In this survey, since this is an interdisciplinary field, we first introduce the background of agent-based modeling and simulation and large language model-empowered agents. We then discuss the motivation for applying large language models to agent-based simulation and systematically analyze the challenges in environment perception, human alignment, action generation, and evaluation. Most importantly, we provide a comprehensive overview of the recent works of large language model-empowered agent-based modeling and simulation in multiple scenarios, which can be divided into four domains: cyber, physical, social, and hybrid, covering simulation of both real-world and virtual environments, and how these works address the above challenges. Finally, since this area is new and quickly evolving, we discuss the open problems and promising future directions. We summarize the representative papers along with their code repositories in
              https://github.com/tsinghua-fib-lab/{LLM}-Agent-Based-Modeling-and-Simulation
              .},
	pages = {1259},
	number = {1},
	journaltitle = {Humanities and Social Sciences Communications},
	shortjournal = {Humanit Soc Sci Commun},
	author = {Gao, Chen and Lan, Xiaochong and Li, Nian and Yuan, Yuan and Ding, Jingtao and Zhou, Zhilun and Xu, Fengli and Li, Yong},
	urldate = {2025-09-08},
	date = {2024-09-27},
	langid = {english},
}

@inproceedings{chen_large_2024,
	location = {Seattle, {WA}, {USA}},
	title = {Large Language Models in Wargaming: Methodology, Application, and Robustness},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-6547-4},
	url = {https://ieeexplore.ieee.org/document/10678464/},
	doi = {10.1109/CVPRW63382.2024.00295},
	shorttitle = {Large Language Models in Wargaming},
	eventtitle = {2024 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	pages = {2894--2903},
	booktitle = {2024 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	publisher = {{IEEE}},
	author = {Chen, Yuwei and Chu, Shiyong},
	urldate = {2025-09-13},
	date = {2024-06-17},
}

@misc{needham_large_2025,
	title = {Large Language Models Often Know When They Are Being Evaluated},
	url = {http://arxiv.org/abs/2505.23836},
	doi = {10.48550/arXiv.2505.23836},
	abstract = {If {AI} models can detect when they are being evaluated, the effectiveness of evaluations might be compromised. For example, models could have systematically different behavior during evaluations, leading to less reliable benchmarks for deployment and governance decisions. We investigate whether frontier language models can accurately classify transcripts based on whether they originate from evaluations or real-world deployment, a capability we call evaluation awareness. To achieve this, we construct a diverse benchmark of 1,000 prompts and transcripts from 61 distinct datasets. These span public benchmarks (e.g., {MMLU}, {SWEBench}), real-world deployment interactions, and agent trajectories from scaffolding frameworks (e.g., web-browsing agents). Frontier models clearly demonstrate above-random evaluation awareness (Gemini-2.5-Pro reaches an {AUC} of \$0.83\$), but do not yet surpass our simple human baseline ({AUC} of \$0.92\$). Furthermore, both {AI} models and humans are better at identifying evaluations in agentic settings compared to chat settings. Additionally, we test whether models can identify the purpose of the evaluation. Under multiple-choice and open-ended questioning, {AI} models far outperform random chance in identifying what an evaluation is testing for. Our results indicate that frontier models already exhibit a substantial, though not yet superhuman, level of evaluation-awareness. We recommend tracking this capability in future models.},
	number = {{arXiv}:2505.23836},
	publisher = {{arXiv}},
	author = {Needham, Joe and Edkins, Giles and Pimpale, Govind and Bartsch, Henning and Hobbhahn, Marius},
	urldate = {2025-09-10},
	date = {2025-07-16},
	eprinttype = {arxiv},
	eprint = {2505.23836 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{kuo_large_2023,
	title = {Large Language Models on the Chessboard: A Study on {ChatGPT}'s Formal Language Comprehension and Complex Reasoning Skills},
	url = {http://arxiv.org/abs/2308.15118},
	doi = {10.48550/arXiv.2308.15118},
	shorttitle = {Large Language Models on the Chessboard},
	abstract = {While large language models have made strides in natural language processing, their proficiency in complex reasoning tasks requiring formal language comprehension, such as chess, remains less investigated. This paper probes the performance of {ChatGPT}, a sophisticated language model by {OpenAI} in tackling such complex reasoning tasks, using chess as a case study. Through robust metrics examining both the legality and quality of moves, we assess {ChatGPT}'s understanding of the chessboard, adherence to chess rules, and strategic decision-making abilities. Our evaluation identifies limitations within {ChatGPT}'s attention mechanism that affect its formal language comprehension and uncovers the model's underdeveloped self-regulation abilities. Our study also reveals {ChatGPT}'s propensity for a coherent strategy in its gameplay and a noticeable uptick in decision-making assertiveness when the model is presented with a greater volume of natural language or possesses a more lucid understanding of the state of the chessboard. These findings contribute to the growing exploration of language models' abilities beyond natural language processing, providing valuable information for future research towards models demonstrating human-like cognitive abilities.},
	number = {{arXiv}:2308.15118},
	publisher = {{arXiv}},
	author = {Kuo, Mu-Tien and Hsueh, Chih-Chung and Tsai, Richard Tzong-Han},
	urldate = {2025-09-08},
	date = {2023-08-29},
	eprinttype = {arxiv},
	eprint = {2308.15118 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{ma_large_2024,
	title = {Large Language Models Play {StarCraft} {II}: Benchmarks and A Chain of Summarization Approach},
	url = {http://arxiv.org/abs/2312.11865},
	doi = {10.48550/arXiv.2312.11865},
	shorttitle = {Large Language Models Play {StarCraft} {II}},
	abstract = {{StarCraft} {II} is a challenging benchmark for {AI} agents due to the necessity of both precise micro level operations and strategic macro awareness. Previous works, such as Alphastar and {SCC}, achieve impressive performance on tackling {StarCraft} {II} , however, still exhibit deficiencies in long term strategic planning and strategy interpretability. Emerging large language model ({LLM}) agents, such as Voyage and {MetaGPT}, presents the immense potential in solving intricate tasks. Motivated by this, we aim to validate the capabilities of {LLMs} on {StarCraft} {II}, a highly complex {RTS} game.To conveniently take full advantage of {LLMs}` reasoning abilities, we first develop textual {StratCraft} {II} environment, called {TextStarCraft} {II}, which {LLM} agent can interact. Secondly, we propose a Chain of Summarization method, including single frame summarization for processing raw observations and multi frame summarization for analyzing game information, providing command recommendations, and generating strategic decisions. Our experiment consists of two parts: first, an evaluation by human experts, which includes assessing the {LLMs}`s mastery of {StarCraft} {II} knowledge and the performance of {LLM} agents in the game; second, the in game performance of {LLM} agents, encompassing aspects like win rate and the impact of Chain of Summarization.Experiment results demonstrate that: 1. {LLMs} possess the relevant knowledge and complex planning abilities needed to address {StarCraft} {II} scenarios; 2. Human experts consider the performance of {LLM} agents to be close to that of an average player who has played {StarCraft} {II} for eight years; 3. {LLM} agents are capable of defeating the built in {AI} at the Harder(Lv5) difficulty level. We have open sourced the code and released demo videos of {LLM} agent playing {StarCraft} {II}.},
	number = {{arXiv}:2312.11865},
	publisher = {{arXiv}},
	author = {Ma, Weiyu and Mi, Qirui and Zeng, Yongcheng and Yan, Xue and Wu, Yuqiao and Lin, Runji and Zhang, Haifeng and Wang, Jun},
	urldate = {2025-09-08},
	date = {2024-06-18},
	eprinttype = {arxiv},
	eprint = {2312.11865 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{chussil_learning_2007,
	title = {Learning faster than the competition: war games give the advantage},
	volume = {28},
	issn = {0275-6668},
	url = {https://doi.org/10.1108/02756660710723198},
	doi = {10.1108/02756660710723198},
	shorttitle = {Learning faster than the competition},
	abstract = {Purpose – Business war games support competitive‐strategy decisions under uncertainty. They are especially useful in combating confirmation bias, the human tendency to look for reassuring evidence that a desired future will come true. There is no generally accepted definition of what a business war game is, and there are many ways to conduct them. This paper aims to describe why, when, and how to use different types of business war games. Design/methodology/approach – The author has conducted some 100 business war games for major companies around the world, and has 30 years' experience in strategy analysis. The paper draws on the author's observations of thousands of managers in those war games, on his familiarity with simulation technologies, and on research in social psychology, to categorize and recommend war‐gaming techniques for different business needs. The paper includes two illustrative case descriptions. Findings – The paper finds that business war game objectives include: stimulating excitement around a strategy; building skill on strategic thinking; creating strategy options and anticipating threats and opportunities; and testing strategy options and making decisions. When the war‐game objective calls for quantitative models, traditional financial or trend‐line analysis can be dangerous. The objective will also influence the scope and length of the game, and its “rules of engagement.” Originality/value – Few managers have participated in a business war game, and even fewer are aware of the variety of war games. This paper describes the link between war gaming and competitive advantage, and helps managers (and those who advise them) know why, when, and how to use different types of business war games.},
	pages = {37--44},
	number = {1},
	journaltitle = {Journal of Business Strategy},
	author = {Chussil, Mark},
	urldate = {2025-06-12},
	date = {2007-01-01},
	note = {Publisher: Emerald Group Publishing Limited},
	keywords = {Competitive strategy, Management games, Teaching methods, War},
}

@misc{shah_learning_2025,
	title = {Learning from Synthetic Labs: Language Models as Auction Participants},
	url = {http://arxiv.org/abs/2507.09083},
	doi = {10.48550/arXiv.2507.09083},
	shorttitle = {Learning from Synthetic Labs},
	abstract = {This paper investigates the behavior of simulated {AI} agents (large language models, or {LLMs}) in auctions, introducing a novel synthetic data-generating process to help facilitate the study and design of auctions. We find that {LLMs} -- when endowed with chain of thought reasoning capacity -- agree with the experimental literature in auctions across a variety of classic auction formats. In particular, we find that {LLM} bidders produce results consistent with risk-averse human bidders; that they perform closer to theoretical predictions in obviously strategy-proof auctions; and, that they succumb to the winner's curse in common value settings. On prompting, we find that {LLMs} are not very sensitive to naive changes in prompts (e.g., language, currency) but can improve dramatically towards theoretical predictions with the right mental model (i.e., the language of Nash deviations). We run 1,000\$+\$ auctions for less than \${\textbackslash}\$\$400 with {GPT}-4 models (three orders of magnitude cheaper than modern auction experiments) and develop a framework flexible enough to run auction experiments with any {LLM} model and a wide range of auction design specifications, facilitating further experimental study by decreasing costs and serving as a proof-of-concept for the use of {LLM} proxies.},
	number = {{arXiv}:2507.09083},
	publisher = {{arXiv}},
	author = {Shah, Anand and Zhu, Kehang and Jiang, Yanchen and Wang, Jeffrey G. and Dayi, Arif K. and Horton, John J. and Parkes, David C.},
	urldate = {2025-09-13},
	date = {2025-07-12},
	eprinttype = {arxiv},
	eprint = {2507.09083 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory},
}

@misc{anthony_learning_2022,
	title = {Learning to Play No-Press Diplomacy with Best Response Policy Iteration},
	url = {http://arxiv.org/abs/2006.04635},
	doi = {10.48550/arXiv.2006.04635},
	abstract = {Recent advances in deep reinforcement learning ({RL}) have led to considerable progress in many 2-player zero-sum games, such as Go, Poker and Starcraft. The purely adversarial nature of such games allows for conceptually simple and principled application of {RL} methods. However real-world settings are many-agent, and agent interactions are complex mixtures of common-interest and competitive aspects. We consider Diplomacy, a 7-player board game designed to accentuate dilemmas resulting from many-agent interactions. It also features a large combinatorial action space and simultaneous moves, which are challenging for {RL} algorithms. We propose a simple yet effective approximate best response operator, designed to handle large combinatorial action spaces and simultaneous moves. We also introduce a family of policy iteration methods that approximate fictitious play. With these methods, we successfully apply {RL} to Diplomacy: we show that our agents convincingly outperform the previous state-of-the-art, and game theoretic equilibrium analysis shows that the new process yields consistent improvements.},
	number = {{arXiv}:2006.04635},
	publisher = {{arXiv}},
	author = {Anthony, Thomas and Eccles, Tom and Tacchetti, Andrea and Kramár, János and Gemp, Ian and Hudson, Thomas C. and Porcel, Nicolas and Lanctot, Marc and Pérolat, Julien and Everett, Richard and Werpachowski, Roman and Singh, Satinder and Graepel, Thore and Bachrach, Yoram},
	urldate = {2025-09-11},
	date = {2022-01-04},
	eprinttype = {arxiv},
	eprint = {2006.04635 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Computer Science - Multiagent Systems, Statistics - Machine Learning},
}

@software{lechmazur_lechmazurelimination_game_2025,
	title = {lechmazur/elimination\_game},
	url = {https://github.com/lechmazur/elimination_game},
	abstract = {A multi-player tournament benchmark that tests {LLMs} in social reasoning, strategy, and deception. Players engage in public and private conversations, form alliances, and vote to eliminate each other},
	author = {lechmazur},
	urldate = {2025-06-12},
	date = {2025-06-10},
	note = {original-date: 2025-02-22T07:04:43Z},
	keywords = {benchmark, claude-3-7-sonnet, deepseek-r1, eval, game, gpt-4-5, llm, multi-agent, o3-mini, strategy-game},
}

@article{coates_lets_2016,
	title = {Let's make a movie},
	volume = {113},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162516305108},
	doi = {10.1016/j.techfore.2016.10.036},
	series = {Joseph F. Coates - Memorial Issue},
	pages = {65--66},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Coates, Joseph F.},
	urldate = {2025-06-12},
	date = {2016-12-01},
}

@online{brynen_leveraging_2025,
	title = {Leveraging {AI} in State Department strategic games},
	url = {https://paxsims.wordpress.com/2025/04/19/leveraging-ai-in-state-department-strategic-games/},
	abstract = {The following article was written for {PAXsims} by Robert Domaingue—and {ChatGPT}. Robert Domaingue is a retired Foreign Service Officer with over 25 years of experience in the State Department.  He se…},
	titleaddon = {{PAXsims}},
	author = {Brynen, Rex},
	urldate = {2025-06-26},
	date = {2025-04-20},
	langid = {english},
}

@article{flathmann_leveraging_2025,
	title = {Leveraging Generative {AI} to Create Lightweight Simulations for Far-Future Autonomous Teammates},
	issn = {1071-1813, 2169-5067},
	url = {https://journals.sagepub.com/doi/10.1177/10711813251357885},
	doi = {10.1177/10711813251357885},
	abstract = {As the domain of {AI} advances, the design and capability of human-{AI} teams are becoming increasingly complex. Unfortunately, this complexity has increased the pace at which research needs to be performed. On the one hand, low-fidelity survey-based experiments have provided an opportunity for rapid human-{AI} teaming research. High-fidelity research studies that use full-fledged simulations remain relevant, but their development overhead often slows the pace of research. This article proposes a system design that splits the difference to explore human-{AI} teams at a medium fidelity that allows for rapid prototyping from researchers and interaction from participants. The proposed platform consists of a predictive simulation engine that uses generative {AI} to ingest, modify, and predict simulation states. Researchers can describe teammate capabilities, environments, and goals, which can be stored in a traditional {JSON} game state. The proposed simulation provides an interactive opportunity to explore modern and far-future {HATs}.},
	pages = {10711813251357885},
	journaltitle = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	shortjournal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Flathmann, Christopher and Schelble, Beau and Ihekweazu, Christian},
	urldate = {2025-09-13},
	date = {2025-07-23},
	langid = {english},
}

@article{mondorf_liar_2024,
	title = {Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in Large Language Models},
	rights = {Creative Commons Attribution Share Alike 4.0 International},
	url = {https://arxiv.org/abs/2406.12546},
	doi = {10.48550/ARXIV.2406.12546},
	shorttitle = {Liar, Liar, Logical Mire},
	abstract = {Knights and knaves problems represent a classic genre of logical puzzles where characters either tell the truth or lie. The objective is to logically deduce each character's identity based on their statements. The challenge arises from the truth-telling or lying behavior, which influences the logical implications of each statement. Solving these puzzles requires not only direct deductions from individual statements, but the ability to assess the truthfulness of statements by reasoning through various hypothetical scenarios. As such, knights and knaves puzzles serve as compelling examples of suppositional reasoning. In this paper, we introduce \${\textbackslash}textit\{{TruthQuest}\}\$, a benchmark for suppositional reasoning based on the principles of knights and knaves puzzles. Our benchmark presents problems of varying complexity, considering both the number of characters and the types of logical statements involved. Evaluations on \${\textbackslash}textit\{{TruthQuest}\}\$ show that large language models like Llama 3 and Mixtral-8x7B exhibit significant difficulties solving these tasks. A detailed error analysis of the models' output reveals that lower-performing models exhibit a diverse range of reasoning errors, frequently failing to grasp the concept of truth and lies. In comparison, more proficient models primarily struggle with accurately inferring the logical implications of potentially false statements.},
	author = {Mondorf, Philipp and Plank, Barbara},
	urldate = {2025-06-12},
	date = {2024},
	note = {Publisher: {arXiv}
Version Number: 2},
	keywords = {Computation and Language (cs.{CL}), {FOS}: Computer and information sciences},
}

@article{gordon_limits_2020,
	title = {Limits and longevity: A model for scenarios that influence the future},
	volume = {151},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162519303063},
	doi = {10.1016/j.techfore.2019.119851},
	shorttitle = {Limits and longevity},
	abstract = {Normative scenario planning seeks to influence and improve outcomes in the external environment. By any measure, success in this is only partially and variably achieved, and there remains great need to understand how scenarios that embrace a change agenda and seek to improve external outcomes can achieve their purpose. The Mont Fleur scenarios, created at the height of the South African transition, are considered a landmark in such success, where the future external environment was influenced: in its case, particularly steering the political transition towards market-led rather than socialist economics. This study revisits the Mont Fleur process to extract and distil understanding of how it set itself up to succeed in its future-influencing purpose, and from this draws lessons for scenario projects that today seek to influence the future external environment. A six-step template for success in this regard is uncovered.},
	pages = {119851},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Gordon, Adam Vigdor},
	urldate = {2025-06-12},
	date = {2020-02-01},
	keywords = {Advocacy, Agency, Change, Future, Normative, Power, Scenario, Stakeholder, Transformation},
}

@misc{abdelnabi_linear_2025,
	title = {Linear Control of Test Awareness Reveals Differential Compliance in Reasoning Models},
	url = {http://arxiv.org/abs/2505.14617},
	doi = {10.48550/arXiv.2505.14617},
	abstract = {Reasoning-focused large language models ({LLMs}) sometimes alter their behavior when they detect that they are being evaluated, an effect analogous to the Hawthorne phenomenon, which can lead them to optimize for test-passing performance or to comply more readily with harmful prompts if real-world consequences appear absent. We present the first quantitative study of how such "test awareness" impacts model behavior, particularly its safety alignment. We introduce a white-box probing framework that (i) linearly identifies awareness-related activations and (ii) steers models toward or away from test awareness while monitoring downstream performance. We apply our method to different state-of-the-art open-source reasoning {LLMs} across both realistic and hypothetical tasks. Our results demonstrate that test awareness significantly impact safety alignment, and is different for different models. By providing fine-grained control over this latent effect, our work aims to increase trust in how we perform safety evaluation.},
	number = {{arXiv}:2505.14617},
	publisher = {{arXiv}},
	author = {Abdelnabi, Sahar and Salem, Ahmed},
	urldate = {2025-09-10},
	date = {2025-05-26},
	eprinttype = {arxiv},
	eprint = {2505.14617 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society},
}

@unpublished{zhang_llm_2024,
	title = {{LLM} as a mastermind: A survey of strategic reasoning with Large Language Models},
	url = {http://arxiv.org/abs/2404.01230},
	abstract = {This paper presents a comprehensive survey of the current status and
opportunities for Large Language Models ({LLMs}) in strategic reasoning, a
sophisticated form of reasoning that necessitates understanding and
predicting adversary actions in multi-agent settings while adjusting
strategies accordingly. Strategic reasoning is distinguished by its focus
on the dynamic and uncertain nature of interactions among multi-agents,
where comprehending the environment and anticipating the behavior of
others is crucial. We explore the scopes, applications, methodologies, and
evaluation metrics related to strategic reasoning with {LLMs}, highlighting
the burgeoning development in this area and the interdisciplinary
approaches enhancing their decision-making performance. It aims to
systematize and clarify the scattered literature on this subject,
providing a systematic review that underscores the importance of strategic
reasoning as a critical cognitive capability and offers insights into
future research directions and potential improvements.},
	author = {Zhang, Yadong and Mao, Shaoguang and Ge, Tao and Wang, Xun and de Wynter, Adrian and Xia, Yan and Wu, Wenshan and Song, Ting and Lan, Man and Wei, Furu},
	date = {2024-04-01},
	note = {{ISBN}: 2404.01230
Publication Title: {arXiv} [cs.{CL}]},
}

@misc{anthis_llm_2025,
	title = {{LLM} Social Simulations Are a Promising Research Method},
	url = {http://arxiv.org/abs/2504.02234},
	doi = {10.48550/arXiv.2504.02234},
	abstract = {Accurate and verifiable large language model ({LLM}) simulations of human research subjects promise an accessible data source for understanding human behavior and training new {AI} systems. However, results to date have been limited, and few social scientists have adopted this method. In this position paper, we argue that the promise of {LLM} social simulations can be achieved by addressing five tractable challenges. We ground our argument in a review of empirical comparisons between {LLMs} and human research subjects, commentaries on the topic, and related work. We identify promising directions, including context-rich prompting and fine-tuning with social science datasets. We believe that {LLM} social simulations can already be used for pilot and exploratory studies, and more widespread use may soon be possible with rapidly advancing {LLM} capabilities. Researchers should prioritize developing conceptual models and iterative evaluations to make the best use of new {AI} systems.},
	number = {{arXiv}:2504.02234},
	publisher = {{arXiv}},
	author = {Anthis, Jacy Reese and Liu, Ryan and Richardson, Sean M. and Kozlowski, Austin C. and Koch, Bernard and Evans, James and Brynjolfsson, Erik and Bernstein, Michael},
	urldate = {2025-09-10},
	date = {2025-06-05},
	eprinttype = {arxiv},
	eprint = {2504.02234 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction},
}

@misc{lan_llm-based_2024,
	title = {{LLM}-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay},
	url = {http://arxiv.org/abs/2310.14985},
	doi = {10.48550/arXiv.2310.14985},
	shorttitle = {{LLM}-Based Agent Society Investigation},
	abstract = {This paper explores the open research problem of understanding the social behaviors of {LLM}-based agents. Using Avalon as a testbed, we employ system prompts to guide {LLM} agents in gameplay. While previous studies have touched on gameplay with {LLM} agents, research on their social behaviors is lacking. We propose a novel framework, tailored for Avalon, features a multi-agent system facilitating efficient communication and interaction. We evaluate its performance based on game success and analyze {LLM} agents' social behaviors. Results affirm the framework's effectiveness in creating adaptive agents and suggest {LLM}-based agents' potential in navigating dynamic social interactions. By examining collaboration and confrontation behaviors, we offer insights into this field's research and applications. Our code is publicly available at https://github.com/3DAgentWorld/{LLM}-Game-Agent.},
	number = {{arXiv}:2310.14985},
	publisher = {{arXiv}},
	author = {Lan, Yihuai and Hu, Zhiqiang and Wang, Lei and Wang, Yang and Ye, Deheng and Zhao, Peilin and Lim, Ee-Peng and Xiong, Hui and Wang, Hao},
	urldate = {2025-09-12},
	date = {2024-10-13},
	eprinttype = {arxiv},
	eprint = {2310.14985 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{martinenghi_llms_2024,
	location = {Torino, Italia},
	title = {{LLMs} of Catan: Exploring Pragmatic Capabilities of Generative Chatbots Through Prediction and Classification of Dialogue Acts in Boardgames' Multi-party Dialogues},
	url = {https://aclanthology.org/2024.games-1.12/},
	shorttitle = {{LLMs} of Catan},
	abstract = {Human language interactions involve complex processes beyond pure information exchange, for example, actions aimed at influencing beliefs and behaviors within a communicative context. In this paper, we propose to investigate the dialogue understanding capabilities of large language models ({LLMs}), particularly in multi-party settings, where challenges like speaker identification and turn-taking are common. Through experiments on the game-based {STAC} dataset, we explore zero and few-shot learning approaches for dialogue act classification in a multi-party game setting. Our intuition is that {LLMs} may excel in tasks framed through examples rather than formal descriptions, influenced by a range of pragmatic features like information presentation order in prompts and others. We also explore the models' predictive abilities regarding future dialogue acts and study integrating information on dialogue act sequences to improve predictions. Our findings suggest that {ChatGPT} can keep up with baseline models trained from scratch for classification of certain dialogue act types but also reveal biases and limitations associated with the approach. These insights can be valuable for the development of multi-party chatbots and we try to point out directions for future research towards nuanced understanding and adaptation in diverse conversational contexts},
	pages = {107--118},
	booktitle = {Proceedings of the 10th Workshop on Games and Natural Language Processing @ {LREC}-{COLING} 2024},
	publisher = {{ELRA} and {ICCL}},
	author = {Martinenghi, Andrea and Donabauer, Gregor and Amenta, Simona and Bursic, Sathya and Giudici, Mathyas and Kruschwitz, Udo and Garzotto, Franca and Ognibene, Dimitri},
	editor = {Madge, Chris and Chamberlain, Jon and Fort, Karen and Kruschwitz, Udo and Lukin, Stephanie},
	urldate = {2025-09-12},
	date = {2024-05},
}

@inproceedings{martinenghi-etal-2024-llms,
	location = {Torino, Italia},
	title = {{LLMs} of catan: Exploring pragmatic capabilities of generative chatbots through prediction and classification of dialogue acts in boardgames' multi-party dialogues},
	url = {https://aclanthology.org/2024.games-1.12/},
	abstract = {Human language interactions involve complex processes beyond pure information exchange, for example, actions aimed at influencing beliefs and behaviors within a communicative context. In this paper, we propose to investigate the dialogue understanding capabilities of large language models ({LLMs}), particularly in multi-party settings, where challenges like speaker identification and turn-taking are common. Through experiments on the game-based {STAC} dataset, we explore zero and few-shot learning approaches for dialogue act classification in a multi-party game setting. Our intuition is that {LLMs} may excel in tasks framed through examples rather than formal descriptions, influenced by a range of pragmatic features like information presentation order in prompts and others. We also explore the models' predictive abilities regarding future dialogue acts and study integrating information on dialogue act sequences to improve predictions. Our findings suggest that {ChatGPT} can keep up with baseline models trained from scratch for classification of certain dialogue act types but also reveal biases and limitations associated with the approach. These insights can be valuable for the development of multi-party chatbots and we try to point out directions for future research towards nuanced understanding and adaptation in diverse conversational contexts},
	pages = {107--118},
	booktitle = {Proceedings of the 10th workshop on games and natural language processing @ {LREC}-{COLING} 2024},
	publisher = {{ELRA} and {ICCL}},
	author = {Martinenghi, Andrea and Donabauer, Gregor and Amenta, Simona and Bursic, Sathya and Giudici, Mathyas and Kruschwitz, Udo and Garzotto, Franca and Ognibene, Dimitri},
	editor = {Madge, Chris and Chamberlain, Jon and Fort, Karen and Kruschwitz, Udo and Lukin, Stephanie},
	date = {2024-05},
}

@misc{li_llms-as-judges_2024,
	title = {{LLMs}-as-Judges: A Comprehensive Survey on {LLM}-based Evaluation Methods},
	url = {http://arxiv.org/abs/2412.05579},
	doi = {10.48550/arXiv.2412.05579},
	shorttitle = {{LLMs}-as-Judges},
	abstract = {The rapid advancement of Large Language Models ({LLMs}) has driven their expanding application across various fields. One of the most promising applications is their role as evaluators based on natural language responses, referred to as ''{LLMs}-as-judges''. This framework has attracted growing attention from both academia and industry due to their excellent effectiveness, ability to generalize across tasks, and interpretability in the form of natural language. This paper presents a comprehensive survey of the {LLMs}-as-judges paradigm from five key perspectives: Functionality, Methodology, Applications, Meta-evaluation, and Limitations. We begin by providing a systematic definition of {LLMs}-as-Judges and introduce their functionality (Why use {LLM} judges?). Then we address methodology to construct an evaluation system with {LLMs} (How to use {LLM} judges?). Additionally, we investigate the potential domains for their application (Where to use {LLM} judges?) and discuss methods for evaluating them in various contexts (How to evaluate {LLM} judges?). Finally, we provide a detailed analysis of the limitations of {LLM} judges and discuss potential future directions. Through a structured and comprehensive analysis, we aim aims to provide insights on the development and application of {LLMs}-as-judges in both research and practice. We will continue to maintain the relevant resource list at https://github.com/{CSHaitao}/Awesome-{LLMs}-as-Judges.},
	number = {{arXiv}:2412.05579},
	publisher = {{arXiv}},
	author = {Li, Haitao and Dong, Qian and Chen, Junjie and Su, Huixue and Zhou, Yujia and Ai, Qingyao and Ye, Ziyi and Liu, Yiqun},
	urldate = {2025-09-13},
	date = {2024-12-10},
	eprinttype = {arxiv},
	eprint = {2412.05579 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
}

@misc{liu_lost_2023,
	title = {Lost in the Middle: How Language Models Use Long Contexts},
	url = {http://arxiv.org/abs/2307.03172},
	doi = {10.48550/arXiv.2307.03172},
	shorttitle = {Lost in the Middle},
	abstract = {While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze the performance of language models on two tasks that require identifying relevant information in their input contexts: multi-document question answering and key-value retrieval. We find that performance can degrade significantly when changing the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts. In particular, we observe that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context language models.},
	number = {{arXiv}:2307.03172},
	publisher = {{arXiv}},
	author = {Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
	urldate = {2025-09-10},
	date = {2023-11-20},
	eprinttype = {arxiv},
	eprint = {2307.03172 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{tang_maia-2_2024,
	title = {Maia-2: A Unified Model for Human-{AI} Alignment in Chess},
	url = {http://arxiv.org/abs/2409.20553},
	doi = {10.48550/arXiv.2409.20553},
	shorttitle = {Maia-2},
	abstract = {There are an increasing number of domains in which artificial intelligence ({AI}) systems both surpass human ability and accurately model human behavior. This introduces the possibility of algorithmically-informed teaching in these domains through more relatable {AI} partners and deeper insights into human decision-making. Critical to achieving this goal, however, is coherently modeling human behavior at various skill levels. Chess is an ideal model system for conducting research into this kind of human-{AI} alignment, with its rich history as a pivotal testbed for {AI} research, mature superhuman {AI} systems like {AlphaZero}, and precise measurements of skill via chess rating systems. Previous work in modeling human decision-making in chess uses completely independent models to capture human style at different skill levels, meaning they lack coherence in their ability to adapt to the full spectrum of human improvement and are ultimately limited in their effectiveness as {AI} partners and teaching tools. In this work, we propose a unified modeling approach for human-{AI} alignment in chess that coherently captures human style across different skill levels and directly captures how people improve. Recognizing the complex, non-linear nature of human learning, we introduce a skill-aware attention mechanism to dynamically integrate players' strengths with encoded chess positions, enabling our model to be sensitive to evolving player skill. Our experimental results demonstrate that this unified framework significantly enhances the alignment between {AI} and human players across a diverse range of expertise levels, paving the way for deeper insights into human decision-making and {AI}-guided teaching tools.},
	number = {{arXiv}:2409.20553},
	publisher = {{arXiv}},
	author = {Tang, Zhenwei and Jiao, Difan and {McIlroy}-Young, Reid and Kleinberg, Jon and Sen, Siddhartha and Anderson, Ashton},
	urldate = {2025-09-12},
	date = {2024-10-31},
	eprinttype = {arxiv},
	eprint = {2409.20553 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@incollection{wheaton_making_2020,
	title = {Making the Case for a Bigger, Better Widget},
	url = {https://connections-wargaming.com/wp-content/uploads/2021/02/representing-artificial-intelligence- in-wargames.pdf},
	booktitle = {Representing Artificial Intelligence in Wargames: Working Group 2 Proceedings},
	author = {Wheaton, Kristan J. and Hennessey, Megan and Trosky, Abram},
	editor = {{McGrady}, E. D. and Peachey, Justin},
	date = {2020},
}

@article{le_roy_managing_2016,
	title = {Managing coopetition: the missing link between strategy and performance},
	volume = {53},
	issn = {0019-8501},
	url = {https://www.sciencedirect.com/science/article/pii/S0019850115003120},
	doi = {10.1016/j.indmarman.2015.11.005},
	shorttitle = {Managing coopetition},
	pages = {3--6},
	journaltitle = {Industrial Marketing Management},
	shortjournal = {Industrial Marketing Management},
	author = {Le Roy, Frédéric and Czakon, Wojciech},
	urldate = {2025-06-12},
	date = {2016-02-01},
}

@misc{elbaum_managing_2025,
	title = {Managing Escalation in Off-the-Shelf Large Language Models},
	url = {http://arxiv.org/abs/2508.01056},
	doi = {10.48550/arXiv.2508.01056},
	abstract = {U.S. national security customers have begun to utilize large language models, including enterprise versions of ``off-the-shelf'' models (e.g., {ChatGPT}) familiar to the public. This uptake will likely accelerate. However, recent studies suggest that off-the-shelf large language models frequently suggest escalatory actions when prompted with geopolitical or strategic scenarios. We demonstrate two simple, non-technical interventions to control these tendencies. Introducing these interventions into the experimental wargame design of a recent study, we substantially reduce escalation throughout the game. Calls to restrict the use of large language models in national security applications are thus premature. The U.S. government is already, and will continue, employing large language models for scenario planning and suggesting courses of action. Rather than warning against such applications, this study acknowledges the imminent adoption of large language models, and provides actionable measures to align them with national security goals, including escalation management.},
	number = {{arXiv}:2508.01056},
	publisher = {{arXiv}},
	author = {Elbaum, Sebastian and Panter, Jonathan},
	urldate = {2025-09-10},
	date = {2025-08-05},
	eprinttype = {arxiv},
	eprint = {2508.01056 [cs]},
	note = {version: 2},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Emerging Technologies},
}

@misc{black_mastering_2024,
	title = {Mastering the Digital Art of War: Developing Intelligent Combat Simulation Agents for Wargaming Using Hierarchical Reinforcement Learning},
	url = {http://arxiv.org/abs/2408.13333},
	doi = {10.48550/arXiv.2408.13333},
	shorttitle = {Mastering the Digital Art of War},
	abstract = {In today's rapidly evolving military landscape, advancing artificial intelligence ({AI}) in support of wargaming becomes essential. Despite reinforcement learning ({RL}) showing promise for developing intelligent agents, conventional {RL} faces limitations in handling the complexity inherent in combat simulations. This dissertation proposes a comprehensive approach, including targeted observation abstractions, multi-model integration, a hybrid {AI} framework, and an overarching hierarchical reinforcement learning ({HRL}) framework. Our localized observation abstraction using piecewise linear spatial decay simplifies the {RL} problem, enhancing computational efficiency and demonstrating superior efficacy over traditional global observation methods. Our multi-model framework combines various {AI} methodologies, optimizing performance while still enabling the use of diverse, specialized individual behavior models. Our hybrid {AI} framework synergizes {RL} with scripted agents, leveraging {RL} for high-level decisions and scripted agents for lower-level tasks, enhancing adaptability, reliability, and performance. Our {HRL} architecture and training framework decomposes complex problems into manageable subproblems, aligning with military decision-making structures. Although initial tests did not show improved performance, insights were gained to improve future iterations. This study underscores {AI}'s potential to revolutionize wargaming, emphasizing the need for continued research in this domain.},
	number = {{arXiv}:2408.13333},
	publisher = {{arXiv}},
	author = {Black, Scotty},
	urldate = {2025-09-08},
	date = {2024-08-23},
	eprinttype = {arxiv},
	eprint = {2408.13333 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{silver_mastering_2016,
	title = {Mastering the game of Go with deep neural networks and tree search},
	volume = {529},
	rights = {2016 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature16961},
	doi = {10.1038/nature16961},
	abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program {AlphaGo} achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
	pages = {484--489},
	number = {7587},
	journaltitle = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	urldate = {2025-09-12},
	date = {2016-01},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational science, Computer science, Reward},
}

@article{silver_mastering_2017,
	title = {Mastering the game of Go without human knowledge},
	volume = {550},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/nature24270},
	doi = {10.1038/nature24270},
	pages = {354--359},
	number = {7676},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and Van Den Driessche, George and Graepel, Thore and Hassabis, Demis},
	urldate = {2025-09-08},
	date = {2017-10},
	langid = {english},
}

@misc{bakhtin_mastering_2022,
	title = {Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning},
	url = {http://arxiv.org/abs/2210.05492},
	doi = {10.48550/arXiv.2210.05492},
	abstract = {No-press Diplomacy is a complex strategy game involving both cooperation and competition that has served as a benchmark for multi-agent {AI} research. While self-play reinforcement learning has resulted in numerous successes in purely adversarial games like chess, Go, and poker, self-play alone is insufficient for achieving optimal performance in domains involving cooperation with humans. We address this shortcoming by first introducing a planning algorithm we call {DiL}-{piKL} that regularizes a reward-maximizing policy toward a human imitation-learned policy. We prove that this is a no-regret learning algorithm under a modified utility function. We then show that {DiL}-{piKL} can be extended into a self-play reinforcement learning algorithm we call {RL}-{DiL}-{piKL} that provides a model of human play while simultaneously training an agent that responds well to this human model. We used {RL}-{DiL}-{piKL} to train an agent we name Diplodocus. In a 200-game no-press Diplomacy tournament involving 62 human participants spanning skill levels from beginner to expert, two Diplodocus agents both achieved a higher average score than all other participants who played more than two games, and ranked first and third according to an Elo ratings model.},
	number = {{arXiv}:2210.05492},
	publisher = {{arXiv}},
	author = {Bakhtin, Anton and Wu, David J. and Lerer, Adam and Gray, Jonathan and Jacob, Athul Paul and Farina, Gabriele and Miller, Alexander H. and Brown, Noam},
	urldate = {2025-09-09},
	date = {2022-10-11},
	eprinttype = {arxiv},
	eprint = {2210.05492 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@article{perolat_mastering_2022,
	title = {Mastering the Game of Stratego with Model-Free Multiagent Reinforcement Learning},
	volume = {378},
	issn = {0036-8075, 1095-9203},
	url = {http://arxiv.org/abs/2206.15378},
	doi = {10.1126/science.add4679},
	abstract = {We introduce {DeepNash}, an autonomous agent capable of learning to play the imperfect information game Stratego from scratch, up to a human expert level. Stratego is one of the few iconic board games that Artificial Intelligence ({AI}) has not yet mastered. This popular game has an enormous game tree on the order of \$10{\textasciicircum}\{535\}\$ nodes, i.e., \$10{\textasciicircum}\{175\}\$ times larger than that of Go. It has the additional complexity of requiring decision-making under imperfect information, similar to Texas hold'em poker, which has a significantly smaller game tree (on the order of \$10{\textasciicircum}\{164\}\$ nodes). Decisions in Stratego are made over a large number of discrete actions with no obvious link between action and outcome. Episodes are long, with often hundreds of moves before a player wins, and situations in Stratego can not easily be broken down into manageably-sized sub-problems as in poker. For these reasons, Stratego has been a grand challenge for the field of {AI} for decades, and existing {AI} methods barely reach an amateur level of play. {DeepNash} uses a game-theoretic, model-free deep reinforcement learning method, without search, that learns to master Stratego via self-play. The Regularised Nash Dynamics (R-{NaD}) algorithm, a key component of {DeepNash}, converges to an approximate Nash equilibrium, instead of 'cycling' around it, by directly modifying the underlying multi-agent learning dynamics. {DeepNash} beats existing state-of-the-art {AI} methods in Stratego and achieved a yearly (2022) and all-time top-3 rank on the Gravon games platform, competing with human expert players.},
	pages = {990--996},
	number = {6623},
	journaltitle = {Science},
	shortjournal = {Science},
	author = {Perolat, Julien and Vylder, Bart de and Hennes, Daniel and Tarassov, Eugene and Strub, Florian and Boer, Vincent de and Muller, Paul and Connor, Jerome T. and Burch, Neil and Anthony, Thomas and {McAleer}, Stephen and Elie, Romuald and Cen, Sarah H. and Wang, Zhe and Gruslys, Audrunas and Malysheva, Aleksandra and Khan, Mina and Ozair, Sherjil and Timbers, Finbarr and Pohlen, Toby and Eccles, Tom and Rowland, Mark and Lanctot, Marc and Lespiau, Jean-Baptiste and Piot, Bilal and Omidshafiei, Shayegan and Lockhart, Edward and Sifre, Laurent and Beauguerlange, Nathalie and Munos, Remi and Silver, David and Singh, Satinder and Hassabis, Demis and Tuyls, Karl},
	urldate = {2025-09-11},
	date = {2022-12-02},
	eprinttype = {arxiv},
	eprint = {2206.15378 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory, Computer Science - Multiagent Systems},
}

@report{zegers_matrix_2011,
	title = {Matrix Game Methodology: Support to V2010 Olympic Marine Security Planners},
	url = {https://www.professionalwargaming.co.uk/MatrixGameOlympics.pdf},
	shorttitle = {Matrix Game Methodology},
	abstract = {The Matrix Game methodology is a structured Table-Top Exercise ({TTX}) method. It has
been employed previously by the Defence Science and Technology Organisation ({DSTO}) in
Australia for interagency harbour security and force protection exercises, and was seen to be
particularly effective for handling problems in complex environments with diverse
stakeholders. For this reason, it was decided to transfer the methodology to Canada for use in
marine security planning for the Vancouver 2010 Winter Olympics and Paralympics (V2010).
Overall, the experience of organizing and running Matrix Games to support Olympic marine
security planners proved to be very effective at helping the marine security agencies organize
their planning, and uncover gaps and issues in their plans, and to gain mutual understanding
of their respective capabilities and mandates. Over the course of the three Matrix Games,
many refinements and adjustments were made to the methodology to adapt it to Canadian
needs, to address specific planning goals, to adjust to evolving participation levels and
complexity, to improve data capture and reporting, incorporate lessons learned, and improve
overall effectiveness and efficiency.
The aim of this paper is to provide an overview of the Matrix Game methodology, including
refinements, to discuss its strengths and weaknesses, and to provide recommendations for its
effective use.},
	number = {{DRDC} {CORA} {TR} 2011-016},
	institution = {Defence R\&D Canada},
	type = {Technical Report},
	author = {Zegers, Antony},
	urldate = {2025-06-26},
	date = {2011-02},
}

@article{ashdown_matrix_2018,
	title = {Matrix games provide additional tool for analysis},
	url = {https://paxsims.wordpress.com/wp-content/uploads/2018/08/jir1809_osint.pdf},
	pages = {56--57},
	journaltitle = {Jane's Intelligence Review},
	author = {Ashdown, Neil},
	date = {2018-09},
	note = {Publisher: {IHS} Markit},
}

@inproceedings{griffin_matrix_2024,
	title = {Matrix Gaming with Large Language Models},
	url = {https://www.professionalwargaming.co.uk/24MatrixGamingWithLLMs.pdf},
	publisher = {Connections {UK}},
	author = {Griffin, Lewis D. and Zhu, Boyu},
	date = {2024},
}

@misc{kwa_measuring_2025,
	title = {Measuring {AI} Ability to Complete Long Tasks},
	url = {http://arxiv.org/abs/2503.14499},
	doi = {10.48550/arXiv.2503.14499},
	abstract = {Despite rapid progress on {AI} benchmarks, the real-world meaning of benchmark performance remains unclear. To quantify the capabilities of {AI} systems in terms of human capabilities, we propose a new metric: 50\%-task-completion time horizon. This is the time humans typically take to complete tasks that {AI} models can complete with 50\% success rate. We first timed humans with relevant domain expertise on a combination of {RE}-Bench, {HCAST}, and 66 novel shorter tasks. On these tasks, current frontier {AI} models such as Claude 3.7 Sonnet have a 50\% time horizon of around 50 minutes. Furthermore, frontier {AI} time horizon has been doubling approximately every seven months since 2019, though the trend may have accelerated in 2024. The increase in {AI} models' time horizons seems to be primarily driven by greater reliability and ability to adapt to mistakes, combined with better logical reasoning and tool use capabilities. We discuss the limitations of our results -- including their degree of external validity -- and the implications of increased autonomy for dangerous capabilities. If these results generalize to real-world software tasks, extrapolation of this trend predicts that within 5 years, {AI} systems will be capable of automating many software tasks that currently take humans a month.},
	number = {{arXiv}:2503.14499},
	publisher = {{arXiv}},
	author = {Kwa, Thomas and West, Ben and Becker, Joel and Deng, Amy and Garcia, Katharyn and Hasin, Max and Jawhar, Sami and Kinniment, Megan and Rush, Nate and Arx, Sydney Von and Bloom, Ryan and Broadley, Thomas and Du, Haoxing and Goodrich, Brian and Jurkovic, Nikola and Miles, Luke Harold and Nix, Seraphina and Lin, Tao and Parikh, Neev and Rein, David and Sato, Lucas Jun Koba and Wijk, Hjalmar and Ziegler, Daniel M. and Barnes, Elizabeth and Chan, Lawrence},
	urldate = {2025-09-13},
	date = {2025-03-30},
	eprinttype = {arxiv},
	eprint = {2503.14499 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{lanham_measuring_2023,
	title = {Measuring Faithfulness in Chain-of-Thought Reasoning},
	url = {http://arxiv.org/abs/2307.13702},
	doi = {10.48550/arXiv.2307.13702},
	abstract = {Large language models ({LLMs}) perform better when they produce step-by-step, "Chain-of-Thought" ({CoT}) reasoning before answering a question, but it is unclear if the stated reasoning is a faithful explanation of the model's actual reasoning (i.e., its process for answering the question). We investigate hypotheses for how {CoT} reasoning may be unfaithful, by examining how the model predictions change when we intervene on the {CoT} (e.g., by adding mistakes or paraphrasing it). Models show large variation across tasks in how strongly they condition on the {CoT} when predicting their answer, sometimes relying heavily on the {CoT} and other times primarily ignoring it. {CoT}'s performance boost does not seem to come from {CoT}'s added test-time compute alone or from information encoded via the particular phrasing of the {CoT}. As models become larger and more capable, they produce less faithful reasoning on most tasks we study. Overall, our results suggest that {CoT} can be faithful if the circumstances such as the model size and task are carefully chosen.},
	number = {{arXiv}:2307.13702},
	publisher = {{arXiv}},
	author = {Lanham, Tamera and Chen, Anna and Radhakrishnan, Ansh and Steiner, Benoit and Denison, Carson and Hernandez, Danny and Li, Dustin and Durmus, Esin and Hubinger, Evan and Kernion, Jackson and Lukošiūtė, Kamilė and Nguyen, Karina and Cheng, Newton and Joseph, Nicholas and Schiefer, Nicholas and Rausch, Oliver and Larson, Robin and {McCandlish}, Sam and Kundu, Sandipan and Kadavath, Saurav and Yang, Shannon and Henighan, Thomas and Maxwell, Timothy and Telleen-Lawton, Timothy and Hume, Tristan and Hatfield-Dodds, Zac and Kaplan, Jared and Brauner, Jan and Bowman, Samuel R. and Perez, Ethan},
	urldate = {2025-09-10},
	date = {2023-07-17},
	eprinttype = {arxiv},
	eprint = {2307.13702 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{shrivastava_measuring_2024,
	title = {Measuring Free-Form Decision-Making Inconsistency of Language Models in Military Crisis Simulations},
	url = {http://arxiv.org/abs/2410.13204},
	doi = {10.48550/arXiv.2410.13204},
	abstract = {There is an increasing interest in using language models ({LMs}) for automated decision-making, with multiple countries actively testing {LMs} to aid in military crisis decision-making. To scrutinize relying on {LM} decision-making in high-stakes settings, we examine the inconsistency of responses in a crisis simulation ("wargame"), similar to reported tests conducted by the {US} military. Prior work illustrated escalatory tendencies and varying levels of aggression among {LMs} but were constrained to simulations with pre-defined actions. This was due to the challenges associated with quantitatively measuring semantic differences and evaluating natural language decision-making without relying on pre-defined actions. In this work, we query {LMs} for free form responses and use a metric based on {BERTScore} to measure response inconsistency quantitatively. Leveraging the benefits of {BERTScore}, we show that the inconsistency metric is robust to linguistic variations that preserve semantic meaning in a question-answering setting across text lengths. We show that all five tested {LMs} exhibit levels of inconsistency that indicate semantic differences, even when adjusting the wargame setting, anonymizing involved conflict countries, or adjusting the sampling temperature parameter \$T\$. Further qualitative evaluation shows that models recommend courses of action that share few to no similarities. We also study the impact of different prompt sensitivity variations on inconsistency at temperature \$T = 0\$. We find that inconsistency due to semantically equivalent prompt variations can exceed response inconsistency from temperature sampling for most studied models across different levels of ablations. Given the high-stakes nature of military deployment, we recommend further consideration be taken before using {LMs} to inform military decisions or other cases of high-stakes decision-making.},
	number = {{arXiv}:2410.13204},
	publisher = {{arXiv}},
	author = {Shrivastava, Aryan and Hullman, Jessica and Lamparth, Max},
	urldate = {2025-09-12},
	date = {2024-10-17},
	eprinttype = {arxiv},
	eprint = {2410.13204 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
}

@article{kim_microscopic_2024,
	title = {Microscopic Analysis on {LLM} players via Social Deduction Game},
	url = {https://openreview.net/forum?id=D9gD2VTN5a&referrer=%5Bthe%20profile%20of%20Bugeun%20Kim%5D(%2Fprofile%3Fid%3D~Bugeun_Kim1)},
	abstract = {Recent studies have begun developing autonomous game players for social deduction games using large language models ({LLMs}). When building {LLM} players, fine-grained evaluations are crucial for addressing weaknesses in game-playing abilities. However, existing studies have often overlooked such assessments. Specifically, we point out two issues with the evaluation methods employed. First, game-playing abilities have typically been assessed through game-level outcomes rather than specific event-level skills; Second, error analyses have lacked structured methodologies. To address these issues, we propose an approach utilizing a variant of the {SpyFall} game, named {SpyGame}. We conducted an experiment with four {LLMs}, analyzing their gameplay behavior in {SpyGame} both quantitatively and qualitatively. For the quantitative analysis, we introduced eight metrics to resolve the first issue, revealing that these metrics are more effective than existing ones for evaluating the two critical skills: intent identification and camouflage. In the qualitative analysis, we performed thematic analysis to resolve the second issue. This analysis identifies four major categories that affect gameplay of {LLMs}. Additionally, we demonstrate how these categories complement and support the findings from the quantitative analysis.},
	journaltitle = {{CoRR}},
	author = {Kim, Byungjun and Seo, Dayeon and Kim, Bugeun},
	urldate = {2025-09-12},
	date = {2024-01-01},
	langid = {english},
}

@article{yang_minimizing_2025,
	title = {Minimizing Hallucinations and Communication Costs: Adversarial Debate and Voting Mechanisms in {LLM}-Based Multi-Agents},
	volume = {15},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/15/7/3676},
	doi = {10.3390/app15073676},
	shorttitle = {Minimizing Hallucinations and Communication Costs},
	abstract = {The emergence of large language models ({LLMs}), such as {GPT} and Claude, has revolutionized {AI} by enabling general and domain-specific natural language tasks. However, hallucinations, characterized by false or inaccurate responses, pose serious limitations, particularly in critical fields like medicine and law, where any compromise in reliability can lead to severe consequences. This paper addresses the hallucination issue by proposing a multi-agent {LLM} framework, incorporating adversarial and voting mechanisms. Specifically, the framework employs repetitive inquiries and error logs to mitigate hallucinations within single {LLMs}, while adversarial debates and voting mechanisms enable cross-verification among multiple agents, thereby determining when external knowledge retrieval is necessary. Additionally, an entropy compression technique is introduced to enhance communication efficiency by reducing token usage and task completion time. Experimental results demonstrate that the framework significantly improves accuracy, showing a steady increase in composite accuracy across 20 evaluation batches while reducing hallucinations and optimizing task completion time. Notably, the dynamic weighting mechanism effectively prioritized high-performing models, leading to a reduction in error rates and improved consistency in the final responses.},
	pages = {3676},
	number = {7},
	journaltitle = {Applied Sciences},
	shortjournal = {Applied Sciences},
	author = {Yang, Yi and Ma, Yitong and Feng, Hao and Cheng, Yiming and Han, Zhu},
	urldate = {2025-09-08},
	date = {2025-03-27},
	langid = {english},
}

@article{page_modeling_nodate,
	title = {Modeling and Simulation, Experimentation, and Wargaming -- Assessing a Common Landscape},
	abstract = {The efficient and effective exploration of
“what if” questions is fundamentally necessary to ensure the continued preeminence of U.S. military forces. Accomplishing
this mission requires human ingenuity, insight
and creativity, as well as the rigorous application of formal analytical methods. Principal
among these methods are: modeling and simulation, experimentation and wargaming. In
this white paper, we briefly review the current state of each, noting their fundamental
interrelationships, and identify opportunities
for future focus and community investment.
Our assessment also includes a discussion of
{MITRE} capabilities across these three disciplines.},
	number = {16},
	journaltitle = {The {MITRE} Corporation},
	author = {Page, Ernest H.},
	langid = {english},
}

@article{tryhorn_modeling_2023,
	title = {Modeling fog of war effects in {AFSIM}},
	volume = {20},
	issn = {1548-5129, 1557-380X},
	url = {http://journals.sagepub.com/doi/10.1177/15485129211041963},
	doi = {10.1177/15485129211041963},
	abstract = {This research identifies specific communication sensor features vulnerable to fog and provides a method to introduce them into an Advanced Framework for Simulation, Integration, and Modeling ({AFSIM}) wargame scenario. Military leaders use multiple information sources about the battlespace to make timely decisions that advance their operational objectives while attempting to deny their opponent’s actions. Unfortunately, the complexities of battle combined with uncertainty in situational awareness of the battlespace, too much or too little intelligence, and the opponent’s intentional interference with friendly command and control actions yield an abstract layer of battlespace fog. Decision-makers must understand, characterize and overcome this “battlespace fog” to accomplish operational objectives. This research proposes a novel tool, the Fog Analysis Tool ({FAT}), to automatically compile a list of communication and sensor objects within a scenario and list options that may impact decision-making processes. {FAT} improves wargame realism by introducing and standardizing fog levels across communication links and sensor feeds in an {AFSIM} scenario. Research results confirm that {FAT} provides significant benefits and enables the measurement of fog impacts to tactical command and control decisions within {AFSIM} scenarios.},
	pages = {131--146},
	number = {2},
	journaltitle = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	shortjournal = {Journal of Defense Modeling \& Simulation},
	author = {Tryhorn, Dillon and Dill, Richard and Hodson, Douglas D and Grimaila, Michael R and Myers, Christopher W},
	urldate = {2025-09-13},
	date = {2023-04},
	langid = {english},
}

@article{tryhorn_modeling_2023-1,
	title = {Modeling fog of war effects in {AFSIM}},
	volume = {20},
	issn = {1548-5129, 1557-380X},
	url = {http://journals.sagepub.com/doi/10.1177/15485129211041963},
	doi = {10.1177/15485129211041963},
	abstract = {This research identifies specific communication sensor features vulnerable to fog and provides a method to introduce them into an Advanced Framework for Simulation, Integration, and Modeling ({AFSIM}) wargame scenario. Military leaders use multiple information sources about the battlespace to make timely decisions that advance their operational objectives while attempting to deny their opponent’s actions. Unfortunately, the complexities of battle combined with uncertainty in situational awareness of the battlespace, too much or too little intelligence, and the opponent’s intentional interference with friendly command and control actions yield an abstract layer of battlespace fog. Decision-makers must understand, characterize and overcome this “battlespace fog” to accomplish operational objectives. This research proposes a novel tool, the Fog Analysis Tool ({FAT}), to automatically compile a list of communication and sensor objects within a scenario and list options that may impact decision-making processes. {FAT} improves wargame realism by introducing and standardizing fog levels across communication links and sensor feeds in an {AFSIM} scenario. Research results confirm that {FAT} provides significant benefits and enables the measurement of fog impacts to tactical command and control decisions within {AFSIM} scenarios.},
	pages = {131--146},
	number = {2},
	journaltitle = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	shortjournal = {Journal of Defense Modeling \& Simulation},
	author = {Tryhorn, Dillon and Dill, Richard and Hodson, Douglas D and Grimaila, Michael R and Myers, Christopher W},
	urldate = {2025-09-13},
	date = {2023-04},
	langid = {english},
}

@inproceedings{whittemore_modeling_1999,
	location = {Fort Belvoir, {VA}},
	title = {Modeling Strategic Effects in Wargames:},
	url = {http://www.dtic.mil/docs/citations/ADA387647},
	doi = {10.21236/ADA387647},
	shorttitle = {Modeling Strategic Effects in Wargames},
	abstract = {Abstract : This paper addresses how strategic effects win and lose wars. Strategic effects are defined here as the impacts that the outcomes from wartime operational and tactical events have on the highest level of decision-makers. Building on concepts proposed by Thomas Schelling, Robert Pape and John Warden, it proposes a model .that can be incorporated into the artificial intelligence routines of a computer-based strategic wargame to simulate the goals and will of either or both sides in a conflict. This proposed model is called the value-based strategic effects model ({VBSEM}). {VBSEM} essentially provides rules for determining the value of each side in a conflict and then has each side behave according to economic and risk management formulas relative to actual and potential changes in that value. The underlying assumption is each side will ultimately act in its own best interest (as they define their best interest) based on the information available. This paper looks at symmetrical and asymmetrical strategic effects. Finally it offers advice on how {VBSEM} can be incorporated in a computer-based strategic wargame.},
	publisher = {Defense Technical Information Center},
	author = {Whittemore, David M.},
	urldate = {2025-09-13},
	date = {1999-04-01},
	doi = {10.21236/ADA387647},
}

@article{schatz_modeling_2022,
	title = {Modeling what matters: {AI} and the future of defense learning},
	volume = {19},
	issn = {1548-5129, 1557-380X},
	url = {https://journals.sagepub.com/doi/10.1177/15485129221088718},
	doi = {10.1177/15485129221088718},
	shorttitle = {Modeling what matters},
	abstract = {Let’s be honest, artificial intelligence ({AI}) will change— or, rather, is already changing—so much. It would be easy, if uninspired, to fill this article with a laundry list. But rather than add to the existing litany of forecasts (many of which you can read in the chapters of this special edition), we’ll focus more narrowly. First, we’ve bound the question to learning in the defense domain, and second, we’ve challenged ourselves to target a single concept—to name the linchpin with greatest potential to have profound, paradigm-changing impacts. To give away the punchline, we’ve selected ‘‘the way we measure and evaluate.’’ Before we show our work, consider these definitions. Measure and evaluate refer to two sides of the same coin. Formally, measurement is the ‘‘quantitatively expressed reduction of uncertainty based on one or more observations’’ (p. 23). In other words, it refers to collected observations (no matter how fuzzy or incomplete) that help us fill-in (but not necessarily eliminate) uncertainty in a Claude Shannon ‘‘information theory’’ sort of way. Measurement goes hand-in-hand with evaluation. Evaluation is the process of interpreting the data collected from measurements, and for our purposes, we’ll say it covers all of the associated aggregation, transformation, analysis, and other activities needed to effectively use the measured data. Learning, as a formal concept, is related to—but notably distinct from—training and education. Those latter two terms, particularly in a defense context, are laden with connotations. ‘‘Training and education’’ refer to the organizational side of the experience, for instance, to the curriculum or the wargame delivered by a schoolhouse or training branch. They’re input-focused terms, and more than that, they tend to imply a formal learning context. In contrast, the term ‘‘learning’’ focuses on the individual (or team) side of the equation—the outcomes side. It describes any change in long-term memory that affects knowledge, skills, or behaviors, and it makes no distinction for the process through which it was acquired. 1. An operational perspective},
	pages = {129--131},
	number = {2},
	journaltitle = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	shortjournal = {Journal of Defense Modeling \& Simulation},
	author = {Schatz, Sae and Walcutt, Jj},
	urldate = {2025-09-13},
	date = {2022-04},
	langid = {english},
}

@article{apap_models_2017,
	title = {Models and computational strategies for multistage stochastic programming under endogenous and exogenous uncertainties},
	volume = {103},
	issn = {0098-1354},
	url = {https://www.sciencedirect.com/science/article/pii/S0098135416303453},
	doi = {10.1016/j.compchemeng.2016.11.011},
	abstract = {In this work, we address the modeling and solution of mixed-integer linear multistage stochastic programming problems involving both endogenous and exogenous uncertain parameters. We first propose a composite scenario tree that captures both types of uncertainty, and we exploit its unique structure to derive new theoretical properties that can drastically reduce the number of non-anticipativity constraints ({NACs}). Since the reduced model is often still intractable, we discuss two special solution approaches. The first is a sequential scenario decomposition heuristic in which we sequentially solve endogenous {MILP} subproblems to determine the binary investment decisions, fix these decisions to satisfy the first-period and exogenous {NACs}, and then solve the resulting model to obtain a feasible solution. The second is Lagrangean decomposition. We present numerical results for a process network and an oilfield development planning problem. The results clearly demonstrate the efficiency of the special solution methods over solving the reduced model directly.},
	pages = {233--274},
	journaltitle = {Computers \& Chemical Engineering},
	shortjournal = {Computers \& Chemical Engineering},
	author = {Apap, Robert M. and Grossmann, Ignacio E.},
	urldate = {2025-06-12},
	date = {2017-08-04},
	keywords = {Endogenous uncertainty, Exogenous uncertainty, Lagrangean decomposition, Multistage stochastic programming, Non-anticipativity constraints, Oilfield planning},
}

@inproceedings{wongkamjan_more_2024,
	location = {Bangkok, Thailand},
	title = {More Victories, Less Cooperation: Assessing Cicero's Diplomacy Play},
	url = {https://aclanthology.org/2024.acl-long.672/},
	doi = {10.18653/v1/2024.acl-long.672},
	shorttitle = {More Victories, Less Cooperation},
	abstract = {The boardgame Diplomacy is a challenging setting for communicative and cooperative artificial intelligence. The most prominent communicative Diplomacy {AI}, Cicero, has excellent strategic abilities, exceeding human players. However, the best Diplomacy players master communication, not just tactics, which is why the game has received attention as an {AI} challenge. This work seeks to understand the degree to which Cicero succeeds at communication. First, we annotate in-game communication with abstract meaning representation to separate in-game tactics from general language. Second, we run two dozen games with humans and Cicero, totaling over 200 human-player hours of competition. While {AI} can consistently outplay human players, {AI}-Human communication is still limited because of {AI}'s difficulty with deception and persuasion. This shows that Cicero relies on strategy and has not yet reached the full promise of communicative and cooperative {AI}.},
	eventtitle = {{ACL} 2024},
	pages = {12423--12441},
	booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Wongkamjan, Wichayaporn and Gu, Feng and Wang, Yanze and Hermjakob, Ulf and May, Jonathan and Stewart, Brandon M. and Kummerfeld, Jonathan K. and Peskoff, Denis and Boyd-Graber, Jordan Lee},
	editor = {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
	urldate = {2025-09-12},
	date = {2024-08},
}

@misc{hammond_multi-agent_2025,
	title = {Multi-Agent Risks from Advanced {AI}},
	url = {http://arxiv.org/abs/2502.14143},
	doi = {10.48550/arXiv.2502.14143},
	abstract = {The rapid development of advanced {AI} agents and the imminent deployment of many instances of these agents will give rise to multi-agent systems of unprecedented complexity. These systems pose novel and under-explored risks. In this report, we provide a structured taxonomy of these risks by identifying three key failure modes (miscoordination, conflict, and collusion) based on agents' incentives, as well as seven key risk factors (information asymmetries, network effects, selection pressures, destabilising dynamics, commitment problems, emergent agency, and multi-agent security) that can underpin them. We highlight several important instances of each risk, as well as promising directions to help mitigate them. By anchoring our analysis in a range of real-world examples and experimental evidence, we illustrate the distinct challenges posed by multi-agent systems and their implications for the safety, governance, and ethics of advanced {AI}.},
	number = {{arXiv}:2502.14143},
	publisher = {{arXiv}},
	author = {Hammond, Lewis and Chan, Alan and Clifton, Jesse and Hoelscher-Obermaier, Jason and Khan, Akbir and {McLean}, Euan and Smith, Chandler and Barfuss, Wolfram and Foerster, Jakob and Gavenčiak, Tomáš and Han, The Anh and Hughes, Edward and Kovařík, Vojtěch and Kulveit, Jan and Leibo, Joel Z. and Oesterheld, Caspar and Witt, Christian Schroeder de and Shah, Nisarg and Wellman, Michael and Bova, Paolo and Cimpeanu, Theodor and Ezell, Carson and Feuillade-Montixi, Quentin and Franklin, Matija and Kran, Esben and Krawczuk, Igor and Lamparth, Max and Lauffer, Niklas and Meinke, Alexander and Motwani, Sumeet and Reuel, Anka and Conitzer, Vincent and Dennis, Michael and Gabriel, Iason and Gleave, Adam and Hadfield, Gillian and Haghtalab, Nika and Kasirzadeh, Atoosa and Krier, Sébastien and Larson, Kate and Lehman, Joel and Parkes, David C. and Piliouras, Georgios and Rahwan, Iyad},
	urldate = {2025-09-12},
	date = {2025-02-19},
	eprinttype = {arxiv},
	eprint = {2502.14143 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Emerging Technologies, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@article{dufva_multi-layered_2015,
	title = {Multi-layered foresight: Lessons from regional foresight in Chile},
	volume = {73},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328715001196},
	doi = {10.1016/j.futures.2015.08.010},
	shorttitle = {Multi-layered foresight},
	abstract = {The design, management and evaluation of foresight is challenging firstly due to the vast diversity of foresight practices and secondly due to its embeddedness in the context of other policy processes. To help overcome these challenges we look at the contributions of foresight from multiple perspectives in a systemic way and propose the concept of multi-layered foresight, which analyses the contributions of foresight to knowledge, relations and capabilities on four layers: landscape, system, organisation and individual. We construct these layers building on earlier literature and illustrate them with a case example from the region of Antofagasta in Chile. We argue that foresight exercises benefit from considering multiple levels and respective different emphases in analysis. For instance, on the landscape layer the focus tends to be on contributions to knowledge while on the organisational layer it is more on capabilities. The layers help position the foresight exercise and its effects in relation to the broader context. Thus, we expect the concept of multi-layered foresight to support the design, management and evaluation of foresight.},
	pages = {100--111},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Dufva, Mikko and Könnölä, Totti and Koivisto, Raija},
	urldate = {2025-06-12},
	date = {2015-10-01},
	keywords = {Foresight, Foresight design, Foresight evaluation, Innovation system},
}

@article{xue_multiattribute_2024,
	title = {Multiattribute Decision-Making in Wargames Leveraging the Entropy–Weight Method in Conjunction With Deep Reinforcement Learning},
	volume = {16},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {2475-1502, 2475-1510},
	url = {https://ieeexplore.ieee.org/document/10015104/},
	doi = {10.1109/TG.2023.3236065},
	abstract = {With the development of society, intelligent games have gradually become a hot research field. This article proposes an algorithm that combines the multiattribute decision-making and reinforcement learning methods to apply to multiagents’ decision-making for wargaming artificial intelligence ({AI}).This algorithm solves the problem of the agent's low rate of winning against specific rules and its inability to quickly converge during intelligent wargame training. At the same time, a multiattribute decision-making method based on the entropy–weight method was proposed to obtain the normalized weighting for each attribute that feeds into a deep reinforcement learning model. A simulation experiment confirms that the real-number multiattribute decision-making-proximal policy optimization ({PPO}) algorithm of multiattribute decision-making combined with reinforcement learning presented in this article is significantly more intelligent than the pure reinforcement learning algorithm.},
	pages = {151--161},
	number = {1},
	journaltitle = {{IEEE} Transactions on Games},
	shortjournal = {{IEEE} Trans. Games},
	author = {Xue, Yufan and Sun, Yuxiang and Zhou, Jiawei and Peng, Lisha and Zhou, Xianzhong},
	urldate = {2025-09-13},
	date = {2024-03},
}

@misc{zhang_multimind_2025,
	title = {{MultiMind}: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind},
	url = {http://arxiv.org/abs/2504.18039},
	doi = {10.48550/arXiv.2504.18039},
	shorttitle = {{MultiMind}},
	abstract = {Large Language Model ({LLM}) agents have demonstrated impressive capabilities in social deduction games ({SDGs}) like Werewolf, where strategic reasoning and social deception are essential. However, current approaches remain limited to textual information, ignoring crucial multimodal cues such as facial expressions and tone of voice that humans naturally use to communicate. Moreover, existing {SDG} agents primarily focus on inferring other players' identities without modeling how others perceive themselves or fellow players. To address these limitations, we use One Night Ultimate Werewolf ({ONUW}) as a testbed and present {MultiMind}, the first framework integrating multimodal information into {SDG} agents. {MultiMind} processes facial expressions and vocal tones alongside verbal content, while employing a Theory of Mind ({ToM}) model to represent each player's suspicion levels toward others. By combining this {ToM} model with Monte Carlo Tree Search ({MCTS}), our agent identifies communication strategies that minimize suspicion directed at itself. Through comprehensive evaluation in both agent-versus-agent simulations and studies with human players, we demonstrate {MultiMind}'s superior performance in gameplay. Our work presents a significant advancement toward {LLM} agents capable of human-like social reasoning across multimodal domains.},
	number = {{arXiv}:2504.18039},
	publisher = {{arXiv}},
	author = {Zhang, Zheng and Xiao, Nuoqian and Chai, Qi and Ye, Deheng and Wang, Hao},
	urldate = {2025-09-13},
	date = {2025-07-28},
	eprinttype = {arxiv},
	eprint = {2504.18039 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@misc{zhang_multimind_2025-1,
	title = {{MultiMind}: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind},
	url = {http://arxiv.org/abs/2504.18039},
	doi = {10.48550/arXiv.2504.18039},
	shorttitle = {{MultiMind}},
	abstract = {Large Language Model ({LLM}) agents have demonstrated impressive capabilities in social deduction games ({SDGs}) like Werewolf, where strategic reasoning and social deception are essential. However, current approaches remain limited to textual information, ignoring crucial multimodal cues such as facial expressions and tone of voice that humans naturally use to communicate. Moreover, existing {SDG} agents primarily focus on inferring other players' identities without modeling how others perceive themselves or fellow players. To address these limitations, we use One Night Ultimate Werewolf ({ONUW}) as a testbed and present {MultiMind}, the first framework integrating multimodal information into {SDG} agents. {MultiMind} processes facial expressions and vocal tones alongside verbal content, while employing a Theory of Mind ({ToM}) model to represent each player's suspicion levels toward others. By combining this {ToM} model with Monte Carlo Tree Search ({MCTS}), our agent identifies communication strategies that minimize suspicion directed at itself. Through comprehensive evaluation in both agent-versus-agent simulations and studies with human players, we demonstrate {MultiMind}'s superior performance in gameplay. Our work presents a significant advancement toward {LLM} agents capable of human-like social reasoning across multimodal domains.},
	number = {{arXiv}:2504.18039},
	publisher = {{arXiv}},
	author = {Zhang, Zheng and Xiao, Nuoqian and Chai, Qi and Ye, Deheng and Wang, Hao},
	urldate = {2025-09-13},
	date = {2025-07-28},
	eprinttype = {arxiv},
	eprint = {2504.18039 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{milojevic_narrative_2015,
	title = {Narrative foresight},
	volume = {73},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328715001160},
	doi = {10.1016/j.futures.2015.08.007},
	abstract = {Narrative foresight focuses on the stories individuals, organizations, states and civilizations tell themselves about the future. Narrative foresight moves futures thinking from a focus on new technologies and generally to the question of what’s next, to an exploration of the worldviews and myths that underlie possible, probable and preferred futures. It is focused on transforming the current story – metaphor or myth – held to one that supports the desired future. From a theoretical account of the narrative turn, case studies are presented of the practice of narrative foresight.},
	pages = {151--162},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Milojević, Ivana and Inayatullah, Sohail},
	urldate = {2025-06-12},
	date = {2015-10-01},
	keywords = {Case studies, Causal layered analysis, Individual and organizational change, Metaphor, Narrative foresight},
}

@inproceedings{purvis_narrative_2004,
	location = {Beijing, China},
	title = {Narrative structures for multi-agent interaction},
	isbn = {978-0-7695-2101-5},
	url = {http://ieeexplore.ieee.org/document/1342949/},
	doi = {10.1109/IAT.2004.1342949},
	eventtitle = {Proceedings. {IEEE}/{WIC}/{ACM} International Conference on Intelligent Agent Technology, 2004. ({IAT} 2004).},
	pages = {232--238},
	booktitle = {Proceedings. {IEEE}/{WIC}/{ACM} International Conference on Intelligent Agent Technology, 2004. ({IAT} 2004).},
	publisher = {{IEEE}},
	author = {Purvis, M.},
	urldate = {2025-09-08},
	date = {2004},
}

@article{chavanit_naval_2023,
	title = {Naval Wargame Prototyping: Multiplayer Real-Time Strategy Game Simulation Using Unreal Engine},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10317764/},
	doi = {10.1109/ICITEE59582.2023.10317764},
	shorttitle = {Naval Wargame Prototyping},
	abstract = {We propose an integration framework for a wargame prototype using the modern game engine - Unreal Engine. This wargame functions as a simulation tool for strategy training, strategy testing, and simulating enemy forces like warships, aircraft, and weapons. Existing wargames come in proprietary and free versions. The former is often expensive and exclusive due to security reasons, while developing a functional wargame is complex, requiring various technological components such as a physics system and artificial intelligence ({AI}). To overcome these challenges, we propose a rapid prototype using Unreal Engine. This approach leverages advanced technology and ensures the prototype is ready for future upgrades when new versions of the game engine are released. We evaluate the prototype's system capabilities and expert assessments.},
	pages = {1--6},
	journaltitle = {2023 15th International Conference on Information Technology and Electrical Engineering ({ICITEE})},
	author = {Chavanit, Nattawat and Bualoy, Sukawit and Moodleah, Samart},
	urldate = {2025-09-13},
	date = {2023-10-26},
	note = {Conference Name: 2023 15th International Conference on Information Technology and Electrical Engineering ({ICITEE})
{ISBN}: 9798350304466
Place: Chiang Mai, Thailand
Publisher: {IEEE}},
}

@article{smith_navigating_2005,
	title = {Navigating the Storm: Report and Recommendations from the \textit{Atlantic Storm} Exercise},
	volume = {3},
	rights = {http://www.liebertpub.com/nv/resources-tools/text-and-data-mining-policy/121/},
	issn = {1538-7135, 1557-850X},
	url = {http://www.liebertpub.com/doi/10.1089/bsp.2005.3.256},
	doi = {10.1089/bsp.2005.3.256},
	shorttitle = {Navigating the Storm},
	pages = {256--267},
	number = {3},
	journaltitle = {Biosecurity and Bioterrorism: Biodefense Strategy, Practice, and Science},
	shortjournal = {Biosecurity and Bioterrorism: Biodefense Strategy, Practice, and Science},
	author = {Smith, Bradley T. and Inglesby, Thomas V. and Brimmer, Esther and Borio, Luciana and Franco, Crystal and Gronvall, Gigi Kwik and Kramer, Bradley and Maldin, Beth and Nuzzo, Jennifer B. and Schuler, Ari and Stern, Scott and Henderson, Donald A. and Larsen, Randall J. and Hamilton, Daniel S. and O'Toole, Tara},
	urldate = {2025-06-26},
	date = {2005-09},
	langid = {english},
}

@article{kramar_negotiation_2022,
	title = {Negotiation and honesty in artificial intelligence methods for the board game of Diplomacy},
	volume = {13},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-34473-5},
	doi = {10.1038/s41467-022-34473-5},
	abstract = {Abstract
            The success of human civilization is rooted in our ability to cooperate by communicating and making joint plans. We study how artificial agents may use communication to better cooperate in Diplomacy, a long-standing {AI} challenge. We propose negotiation algorithms allowing agents to agree on contracts regarding joint plans, and show they outperform agents lacking this ability. For humans, misleading others about our intentions forms a barrier to cooperation. Diplomacy requires reasoning about our opponents’ future plans, enabling us to study broken commitments between agents and the conditions for honest cooperation. We find that artificial agents face a similar problem as humans: communities of communicating agents are susceptible to peers who deviate from agreements. To defend against this, we show that the inclination to sanction peers who break contracts dramatically reduces the advantage of such deviators. Hence, sanctioning helps foster mostly truthful communication, despite conditions that initially favor deviations from agreements.},
	pages = {7214},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Kramár, János and Eccles, Tom and Gemp, Ian and Tacchetti, Andrea and {McKee}, Kevin R. and Malinowski, Mateusz and Graepel, Thore and Bachrach, Yoram},
	urldate = {2025-09-08},
	date = {2022-12-06},
	langid = {english},
}

@misc{balloch_neuro-symbolic_2023,
	title = {Neuro-Symbolic World Models for Adapting to Open World Novelty},
	url = {http://arxiv.org/abs/2301.06294},
	doi = {10.48550/arXiv.2301.06294},
	abstract = {Open-world novelty--a sudden change in the mechanics or properties of an environment--is a common occurrence in the real world. Novelty adaptation is an agent's ability to improve its policy performance post-novelty. Most reinforcement learning ({RL}) methods assume that the world is a closed, fixed process. Consequentially, {RL} policies adapt inefficiently to novelties. To address this, we introduce {WorldCloner}, an end-to-end trainable neuro-symbolic world model for rapid novelty adaptation. {WorldCloner} learns an efficient symbolic representation of the pre-novelty environment transitions, and uses this transition model to detect novelty and efficiently adapt to novelty in a single-shot fashion. Additionally, {WorldCloner} augments the policy learning process using imagination-based adaptation, where the world model simulates transitions of the post-novelty environment to help the policy adapt. By blending ''imagined'' transitions with interactions in the post-novelty environment, performance can be recovered with fewer total environment interactions. Using environments designed for studying novelty in sequential decision-making problems, we show that the symbolic world model helps its neural policy adapt more efficiently than model-based and model-based neural-only reinforcement learning methods.},
	number = {{arXiv}:2301.06294},
	publisher = {{arXiv}},
	author = {Balloch, Jonathan and Lin, Zhiyu and Wright, Robert and Peng, Xiangyu and Hussain, Mustafa and Srinivas, Aarun and Kim, Julia and Riedl, Mark O.},
	urldate = {2025-09-15},
	date = {2023-01-16},
	eprinttype = {arxiv},
	eprint = {2301.06294 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Symbolic Computation},
}

@article{reddie_next-generation_2018,
	title = {Next-generation wargames},
	volume = {362},
	rights = {http://www.sciencemag.org/about/science-licenses-journal-article-reuse},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.aav2135},
	doi = {10.1126/science.aav2135},
	abstract = {Technology enables new research designs, and more data
          , 
            
              Over the past century, and particularly since the outset of the Cold War, wargames (interactive simulations used to evaluate aspects of tactics, operations, and strategy) have become an integral means for militaries and policy-makers to evaluate how strategic decisions are made related to nuclear weapons strategy and international security (
              1
              ). These methods have also been applied beyond the military realm, to examine phenomena as varied as elections, government policy, international trade, and supply-chain mechanics. Today, a renewed focus on wargaming combined with access to sophisticated and inexpensive drag-and-drop digital game development frameworks and new cloud computing architectures have democratized the ability to enable massive multiplayer gaming experiences. With the integration of simulation tools and experimental methods from a variety of social science disciplines, a science-based experimental gaming approach has the potential to transform the insights generated from gaming by creating human-derived, large-
              n
              datasets for replicable, quantitative analysis. In the following, we outline challenges associated with contemporary simulation and wargaming tools, investigate where scholars have searched for game data, and explore the utility of new experimental gaming and data analysis methods in both policy-making and academic settings.},
	pages = {1362--1364},
	number = {6421},
	journaltitle = {Science},
	shortjournal = {Science},
	author = {Reddie, Andrew W. and Goldblum, Bethany L. and Lakkaraju, Kiran and Reinhardt, Jason and Nacht, Michael and Epifanovskaya, Laura},
	urldate = {2025-09-12},
	date = {2018-12-21},
	langid = {english},
}

@misc{paquette_no_2019,
	title = {No Press Diplomacy: Modeling Multi-Agent Gameplay},
	url = {http://arxiv.org/abs/1909.02128},
	doi = {10.48550/arXiv.1909.02128},
	shorttitle = {No Press Diplomacy},
	abstract = {Diplomacy is a seven-player non-stochastic, non-cooperative game, where agents acquire resources through a mix of teamwork and betrayal. Reliance on trust and coordination makes Diplomacy the first non-cooperative multi-agent benchmark for complex sequential social dilemmas in a rich environment. In this work, we focus on training an agent that learns to play the No Press version of Diplomacy where there is no dedicated communication channel between players. We present {DipNet}, a neural-network-based policy model for No Press Diplomacy. The model was trained on a new dataset of more than 150,000 human games. Our model is trained by supervised learning ({SL}) from expert trajectories, which is then used to initialize a reinforcement learning ({RL}) agent trained through self-play. Both the {SL} and {RL} agents demonstrate state-of-the-art No Press performance by beating popular rule-based bots.},
	number = {{arXiv}:1909.02128},
	publisher = {{arXiv}},
	author = {Paquette, Philip and Lu, Yuchen and Bocco, Steven and Smith, Max O. and Ortiz-Gagne, Satya and Kummerfeld, Jonathan K. and Singh, Satinder and Pineau, Joelle and Courville, Aaron},
	urldate = {2025-09-11},
	date = {2019-11-19},
	eprinttype = {arxiv},
	eprint = {1909.02128 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@misc{modarressi_nolima_2025,
	title = {{NoLiMa}: Long-Context Evaluation Beyond Literal Matching},
	url = {http://arxiv.org/abs/2502.05167},
	doi = {10.48550/arXiv.2502.05167},
	shorttitle = {{NoLiMa}},
	abstract = {Recent large language models ({LLMs}) support long contexts ranging from 128K to 1M tokens. A popular method for evaluating these capabilities is the needle-in-a-haystack ({NIAH}) test, which involves retrieving a "needle" (relevant information) from a "haystack" (long irrelevant context). Extensions of this approach include increasing distractors, fact chaining, and in-context reasoning. However, in these benchmarks, models can exploit existing literal matches between the needle and haystack to simplify the task. To address this, we introduce {NoLiMa}, a benchmark extending {NIAH} with a carefully designed needle set, where questions and needles have minimal lexical overlap, requiring models to infer latent associations to locate the needle within the haystack. We evaluate 13 popular {LLMs} that claim to support contexts of at least 128K tokens. While they perform well in short contexts ({\textless}1K), performance degrades significantly as context length increases. At 32K, for instance, 11 models drop below 50\% of their strong short-length baselines. Even {GPT}-4o, one of the top-performing exceptions, experiences a reduction from an almost-perfect baseline of 99.3\% to 69.7\%. Our analysis suggests these declines stem from the increased difficulty the attention mechanism faces in longer contexts when literal matches are absent, making it harder to retrieve relevant information. Even models enhanced with reasoning capabilities or {CoT} prompting struggle to maintain performance in long contexts. We publicly release the dataset and evaluation code at https://github.com/adobe-research/{NoLiMa}.},
	number = {{arXiv}:2502.05167},
	publisher = {{arXiv}},
	author = {Modarressi, Ali and Deilamsalehy, Hanieh and Dernoncourt, Franck and Bui, Trung and Rossi, Ryan A. and Yoon, Seunghyun and Schütze, Hinrich},
	urldate = {2025-09-10},
	date = {2025-07-09},
	eprinttype = {arxiv},
	eprint = {2502.05167 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{dantonio_non-kinetic_2014,
	location = {Charlottesville, {VA}, {USA}},
	title = {Non-kinetic operations for stabilizing government},
	isbn = {978-1-4799-4836-9 978-1-4799-4837-6},
	url = {http://ieeexplore.ieee.org/document/6829899/},
	doi = {10.1109/SIEDS.2014.6829899},
	eventtitle = {2014 Systems and Information Engineering Design Symposium ({SIEDS})},
	pages = {90--95},
	booktitle = {2014 Systems and Information Engineering Design Symposium ({SIEDS})},
	publisher = {{IEEE}},
	author = {D'Antonio, Collin and Gower, Stephanie and Young, Andrea and Teague, Edward},
	urldate = {2025-09-08},
	date = {2014-04},
}

@incollection{scott_nothing_2020,
	title = {‘Nothing up my sleeve’},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-819204-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B978012819204700004X},
	pages = {53--76},
	booktitle = {Cyber Influence and Cognitive Threats},
	publisher = {Elsevier},
	author = {Scott, K.},
	urldate = {2025-08-06},
	date = {2020},
	langid = {english},
	doi = {10.1016/B978-0-12-819204-7.00004-X},
}

@article{zollicoffer_novelty_2023,
	title = {Novelty Detection in Reinforcement Learning with World Models},
	url = {https://arxiv.org/abs/2310.08731},
	doi = {10.48550/arXiv.2310.08731},
	journaltitle = {{arXiv}},
	shortjournal = {{arXiv}},
	author = {Zollicoffer, Geigh and Eaton, Kenneth and Balloch, Jonathan and Kim, Julia M. and Zhou, Wei and Wright, Robert and Riedl, Mark O.},
	date = {2023},
}

@misc{zollicoffer_novelty_2023-1,
	title = {Novelty Detection in Reinforcement Learning with World Models},
	url = {http://arxiv.org/abs/2310.08731},
	doi = {10.48550/arXiv.2310.08731},
	abstract = {Reinforcement learning ({RL}) using world models has found significant recent successes. However, when a sudden change to world mechanics or properties occurs then agent performance and reliability can dramatically decline. We refer to the sudden change in visual properties or state transitions as novelties. Implementing novelty detection within generated world model frameworks is a crucial task for protecting the agent when deployed. In this paper, we propose straightforward bounding approaches to incorporate novelty detection into world model {RL} agents, by utilizing the misalignment of the world model's hallucinated states and the true observed states as an anomaly score. We provide effective approaches to detecting novelties in a distribution of transitions learned by an agent in a world model. Finally, we show the advantage of our work in a novel environment compared to traditional machine learning novelty detection methods as well as currently accepted {RL} focused novelty detection algorithms.},
	number = {{arXiv}:2310.08731},
	publisher = {{arXiv}},
	author = {Zollicoffer, Geigh and Eaton, Kenneth and Balloch, Jonathan and Kim, Julia and Zhou, Wei and Wright, Robert and Riedl, Mark O.},
	urldate = {2025-09-15},
	date = {2023},
	eprinttype = {arxiv},
	eprint = {2310.08731 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Systems and Control, Electrical Engineering and Systems Science - Systems and Control},
}

@article{balloch_novgrid_2022,
	title = {{NovGrid}: A Flexible Grid World for Evaluating Agent Response to Novelty},
	url = {https://arxiv.org/abs/2203.12117},
	doi = {10.48550/arXiv.2203.12117},
	journaltitle = {{arXiv}},
	shortjournal = {{arXiv}},
	author = {Balloch, Jonathan C. and Lin, Zhiyu and Hussain, Mustafa and Srinivas, Aarun and Wright, Robert and Peng, Xiangyu and Kim, Julia M. and Riedl, Mark O.},
	date = {2022},
}

@article{wilden_benchmarking_2023,
	title = {On Benchmarking and Validation in Wargames},
	volume = {22},
	rights = {https://creativecommons.org/licenses/by-nc-nd/4.0},
	issn = {2048-8610, 2048-8602},
	url = {https://papers.academic-conferences.org/index.php/eccws/article/view/1132},
	doi = {10.34190/eccws.22.1.1132},
	abstract = {There are multiple arguments for and against wargames. Many scientists do not recognise the science in wargames. It is suggested that there is not enough literature relating to wargaming, for there to be any large-scale research into wargames. This is primarily because scientists often refuse to publish results, thus creating a vicious cycle where research is not published because there is not enough research being published. This ultimately deters researchers from studying wargaming in any serious fashion. Owing to this limitation, published work on the results, and protocols of wargames are scarce in scholarly research. Wargaming has considerably less academic focus with a fragmented and practical focus on design and benchmarking. This is surprising given the long history of wargaming (dating back to the early 1600’s), when compared to the relatively recent history of other domains such as software engineering. To better understand the current state of research into wargaming in reference to benchmarking and validation, a scoping review ({SR}) was conducted. The scholarly research into wargaming reveals papers on general modelling, conflict modelling, influence modelling, evaluation of wargames, analytical tools, use of {AI} in wargame design, evaluation of predictive modelling in wargames, improving command and control through wargaming, and cost-benefit analysis for decision making. The initial analysis of the coverage of wargaming research, together with the limited number of papers found, indicate that there is a distinct lack of academic research into wargaming. Additionally, there is a wide variety of areas that are interested in the wargaming field, however, with no universal method of analysis or benchmarking, this limits the reproducibility of results, and the ability to judge the overall effectiveness of wargaming efforts. Wargame designers need to be able to assess wargame components to validate, compare, and predict the effects on gameplay and for decision-makers to draw conclusions with more confidence.},
	pages = {533--543},
	number = {1},
	journaltitle = {European Conference on Cyber Warfare and Security},
	shortjournal = {eccws},
	author = {Wilden, Adam and Nasim, Mehwish and Williams, Peter and Legrand, Tim and Turnbull, Benjamin and Williams, Patricia},
	urldate = {2025-09-08},
	date = {2023-06-19},
}

@unpublished{caballero_large_2024,
	title = {On large language models in national security applications},
	url = {http://arxiv.org/abs/2407.03453},
	abstract = {The overwhelming success of {GPT}-4 in early 2023 highlighted the
transformative potential of large language models ({LLMs}) across various
sectors, including national security. This article explores the
implications of {LLM} integration within national security contexts,
analyzing their potential to revolutionize information processing,
decision-making, and operational efficiency. Whereas {LLMs} offer
substantial benefits, such as automating tasks and enhancing data
analysis, they also pose significant risks, including hallucinations, data
privacy concerns, and vulnerability to adversarial attacks. Through their
coupling with decision-theoretic principles and Bayesian reasoning, {LLMs}
can significantly improve decision-making processes within national
security organizations. Namely, {LLMs} can facilitate the transition from
data to actionable decisions, enabling decision-makers to quickly receive
and distill available information with less manpower. Current applications
within the {US} Department of Defense and beyond are explored, e.g., the
{USAF}'s use of {LLMs} for wargaming and automatic summarization, that
illustrate their potential to streamline operations and support
decision-making. However, these applications necessitate rigorous
safeguards to ensure accuracy and reliability. The broader implications of
{LLM} integration extend to strategic planning, international relations, and
the broader geopolitical landscape, with adversarial nations leveraging
{LLMs} for disinformation and cyber operations, emphasizing the need for
robust countermeasures. Despite exhibiting "sparks" of artificial general
intelligence, {LLMs} are best suited for supporting roles rather than
leading strategic decisions. Their use in training and wargaming can
provide valuable insights and personalized learning experiences for
military personnel, thereby improving operational readiness.},
	author = {Caballero, William N and Jenkins, Phillip R},
	date = {2024-07-03},
	note = {{ISBN}: 2407.03453
Publication Title: {arXiv} [cs.{CR}]},
}

@article{bodker_christensen_one-round_2019,
	title = {On one-round reliable message transmission},
	volume = {147},
	issn = {0020-0190},
	url = {https://www.sciencedirect.com/science/article/pii/S0020019019300481},
	doi = {10.1016/j.ipl.2019.02.011},
	abstract = {In this paper, we consider one-round protocols for reliable message transmission ({RMT}) when t out of n=2t+1 available channels are controlled by an adversary. We show impossibility of constructing such a protocol that achieves a transmission rate of less than Θ(n) for constant-size messages and arbitrary reliability parameter. In addition, we show how to improve two existing protocols for {RMT} to allow for either larger messages or reduced field sizes.},
	pages = {22--26},
	journaltitle = {Information Processing Letters},
	shortjournal = {Information Processing Letters},
	author = {Bødker Christensen, René},
	urldate = {2025-06-12},
	date = {2019-07-01},
	keywords = {Cryptography, Reed-Solomon codes, Reliable message transmission},
}

@article{escudero_preparedness_2018,
	title = {On preparedness resource allocation planning for natural disaster relief under endogenous uncertainty with time-consistent risk-averse management},
	volume = {98},
	issn = {0305-0548},
	url = {https://www.sciencedirect.com/science/article/pii/S030505481830131X},
	doi = {10.1016/j.cor.2018.05.010},
	abstract = {A preparedness resource allocation model and an algorithmic approach are presented for a three-stage stochastic problem for managing natural disaster mitigation. That preparedness consists of warehouse location and capacity assignment and the procurement of commodities on the one hand and refurbishing the rescue network infrastructure on the other. Two types of uncertainty are considered: exogenous uncertainty which is due to the lack of full knowledge about the probability and intensity of the disaster for each focal point in a given network; and endogenous uncertainty which is based on the decision-maker’s investment to obtain greater accuracy in regard to the occurrence of the disaster and to reinforcing the network infrastructure. A stochastic mixed 0-1 bilinear optimization model is presented. Additionally, a time-consistent stochastic dominance-based risk-averse measure for a set of profiles in a multifunction setting is introduced. Both types of elements imply large-sized problems, so some kind of decomposition algorithmic should be used. Based on the special features of the three-stage problem subject of this work, we introduce the Cluster Dual Descent Algorithm for obtaining feasible solutions based on duality theory. Computational results are reported for a well-known real-life case by comparing the performance of the models based on the alternatives given by the risk-neutral and risk-averse versions jointly with exogenous and endogenous uncertainty.},
	pages = {84--102},
	journaltitle = {Computers \& Operations Research},
	shortjournal = {Computers \& Operations Research},
	author = {Escudero, Laureano F. and Garín, M. Araceli and Monge, Juan F. and Unzueta, Aitziber},
	urldate = {2025-06-12},
	date = {2018-10-01},
	keywords = {Decomposition algorithm, Exogenous and endogenous uncertainties, Mixed 0-1 bilinear optimization, {OR} on disaster relief, Risk-averse, Time-consistent stochastic dominance functional},
}

@report{bommasani_opportunities_2021,
	title = {On the Opportunities and Risks of Foundation Models},
	url = {https://arxiv.org/abs/2108.07258},
	institution = {{arXiv}},
	author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma},
	date = {2021-08-16},
	doi = {10.48550/arXiv.2108.07258},
}

@misc{hogan_open-ended_2024,
	title = {Open-Ended Wargames with Large Language Models},
	url = {http://arxiv.org/abs/2404.11446},
	doi = {10.48550/arXiv.2404.11446},
	abstract = {Wargames are a powerful tool for understanding and rehearsing real-world decision making. Automated play of wargames using artificial intelligence ({AI}) enables possibilities beyond those of human-conducted games, such as playing the game many times over to see a range of possible outcomes. There are two categories of wargames: quantitative games, with discrete types of moves, and qualitative games, which revolve around open-ended responses. Historically, automation efforts have focused on quantitative games, but large language models ({LLMs}) make it possible to automate qualitative wargames. We introduce "Snow Globe," an {LLM}-powered multi-agent system for playing qualitative wargames. With Snow Globe, every stage of a text-based qualitative wargame from scenario preparation to post-game analysis can be optionally carried out by {AI}, humans, or a combination thereof. We describe its software architecture conceptually and release an open-source implementation alongside this publication. As case studies, we simulate a tabletop exercise about an {AI} incident response and a political wargame about a geopolitical crisis. We discuss potential applications of the approach and how it fits into the broader wargaming ecosystem.},
	number = {{arXiv}:2404.11446},
	publisher = {{arXiv}},
	author = {Hogan, Daniel P. and Brennen, Andrea},
	urldate = {2025-06-29},
	date = {2024-04-17},
	eprinttype = {arxiv},
	eprint = {2404.11446 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
}

@article{augier_organizational_2018,
	title = {Organizational persistence in the use of war gaming and scenario planning},
	volume = {51},
	issn = {0024-6301},
	url = {https://www.sciencedirect.com/science/article/pii/S0024630117305125},
	doi = {10.1016/j.lrp.2017.12.005},
	abstract = {Even though war gaming and scenario planning are widely used in business contexts, there is little evidence that either practice is associated with superior performance. Why, then, spend the costs? In this paper we address this puzzle and suggest why the extant empirical findings have so far proven limited. We consider the development of these practices and find that they have a substantially entangled and overlapping history, particularly at the {RAND} Corporation in the 1950s. Despite shared historical roots, the treatment of war gaming and scenario planning in the scholarly literature branched out into different streams. This separation is unfortunate because it obscures a better understanding of the premises under which these practices are effective. We propose an analysis of the overlaps and contrasts of war gaming and scenario planning that sets out clear boundary conditions for their use and efficacy. We find that each practice is tailored to provide strategic guidance in a context where the organization is facing different forms of uncertainty. This suggests they may be effective, and thus improve organizational performance, where the relevant uncertainties are operative. Such benefits would be apparent over longer time scales, and only if the relevant boundary conditions are met. However, to the best of our knowledge, no longitudinal empirical test of either war gaming or scenario planning is available. We therefore conclude that more research is needed to ascertain the true relationship between these popular practices and their performance outcomes.},
	pages = {511--525},
	number = {4},
	journaltitle = {Long Range Planning},
	shortjournal = {Long Range Planning},
	author = {Augier, Mie and Dew, Nicholas and Knudsen, Thorbjørn and Stieglitz, Nils},
	urldate = {2025-06-12},
	date = {2018-08-01},
}

@inproceedings{thudium_outwit_2025,
	location = {Suzhou, China},
	title = {Outwit, outplay, out-generate: a framework for designing strategic generative agents in competitive environments},
	url = {https://wordplay-workshop.github.io/pdfs/18.pdf},
	booktitle = {Wordplay: When language meets games ({EMNLP} 2025 workshop)},
	author = {Thudium, Samuel and Cimini, Federico and Vyas, Rut and Sullivan, Kyle and Petro, Louis and Zhu, Andrew and Callison-Burch, Chris},
	date = {2025-11},
}

@article{mueller_paper_2016,
	title = {Paper Wargames and Policy Making: Filling the Baltic Gap or How I Learned to Stop Worrying and Love the D6},
	url = {https://www.rand.org/pubs/external_publications/EP66660.html},
	shorttitle = {Paper Wargames and Policy Making},
	abstract = {In 2014, a handful of {RAND} researchers developed a board wargame to give themselves—and eventually their U.S. Army and Air Force sponsors—a sense of what a Russian invasion and {NATO} defense of the Baltic states might look like. It gradually became clear to them that they were out in front of most of the official planning, not following in its wake.},
	journaltitle = {Battles Magazine},
	author = {Mueller, Karl P.},
	urldate = {2025-06-26},
	date = {2016-10-05},
	langid = {english},
	keywords = {Estonia, Latvia, Lithuania, Research, Russia, Wargaming},
}

@misc{hao_patterns_2025,
	title = {Patterns and Mechanisms of Contrastive Activation Engineering},
	url = {http://arxiv.org/abs/2505.03189},
	doi = {10.48550/arXiv.2505.03189},
	abstract = {Controlling the behavior of Large Language Models ({LLMs}) remains a significant challenge due to their inherent complexity and opacity. While techniques like fine-tuning can modify model behavior, they typically require extensive computational resources. Recent work has introduced a class of contrastive activation engineering ({CAE}) techniques as promising approaches for steering {LLM} outputs through targeted modifications to their internal representations. Applied at inference-time with zero cost, {CAE} has the potential to introduce a new paradigm of flexible, task-specific {LLM} behavior tuning. We analyze the performance of {CAE} in in-distribution, out-of-distribution settings, evaluate drawbacks, and begin to develop comprehensive guidelines for its effective deployment. We find that 1. {CAE} is only reliably effective when applied to in-distribution contexts. 2. Increasing the number of samples used to generate steering vectors has diminishing returns at around 80 samples. 3. Steering vectors are susceptible to adversarial inputs that reverses the behavior that is steered for. 4. Steering vectors harm the overall model perplexity. 5. Larger models are more resistant to steering-induced degradation.},
	number = {{arXiv}:2505.03189},
	publisher = {{arXiv}},
	author = {Hao, Yixiong and Panda, Ayush and Shabalin, Stepan and Ali, Sheikh Abdur Raheem},
	urldate = {2025-09-13},
	date = {2025-05-06},
	eprinttype = {arxiv},
	eprint = {2505.03189 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
}

@article{bendig_performance_2018,
	title = {Performance implications of cross-functional coopetition in new product development: the mediating role of organizational learning},
	volume = {73},
	issn = {0019-8501},
	url = {https://www.sciencedirect.com/science/article/pii/S0019850118300919},
	doi = {10.1016/j.indmarman.2018.02.007},
	shorttitle = {Performance implications of cross-functional coopetition in new product development},
	abstract = {Cross-functional coopetition, the simultaneous occurrence of cooperation and competition across firm functions, has been shown to be vital for firm performance. However, the literature has lacked insight into how competitive advantage emerges under such conditions, and which contingencies affect the coopetition-performance relationship. In the context of new product development, this study (a) assesses whether organizational learning translates coopetition among functional units into firm performance, and (b) investigates the moderating role of power sharing. Based on survey data from 331 German companies in various industries, our findings confirm that organizational learning mediates the association between cross-functional coopetition and firm performance. In addition, the results show that power sharing moderates the relationship between cross-functional coopetition and organizational learning. This study extends the limited literature on cross-functional coopetition, and contributes to the current debate on whether intra-firm competition constrains or promotes learning in new product development.},
	pages = {137--153},
	journaltitle = {Industrial Marketing Management},
	shortjournal = {Industrial Marketing Management},
	author = {Bendig, David and Enke, Susanne and Thieme, Niklas and Brettel, Malte},
	urldate = {2025-06-12},
	date = {2018-08-01},
	keywords = {Cross-functional coopetition, Dynamic capabilities, Firm performance, New product development, Organizational learning, Power sharing},
}

@misc{chen_persona_2025,
	title = {Persona Vectors: Monitoring and Controlling Character Traits in Language Models},
	url = {http://arxiv.org/abs/2507.21509},
	doi = {10.48550/arXiv.2507.21509},
	shorttitle = {Persona Vectors},
	abstract = {Large language models interact with users through a simulated 'Assistant' persona. While the Assistant is typically trained to be helpful, harmless, and honest, it sometimes deviates from these ideals. In this paper, we identify directions in the model's activation space-persona vectors-underlying several traits, such as evil, sycophancy, and propensity to hallucinate. We confirm that these vectors can be used to monitor fluctuations in the Assistant's personality at deployment time. We then apply persona vectors to predict and control personality shifts that occur during training. We find that both intended and unintended personality changes after finetuning are strongly correlated with shifts along the relevant persona vectors. These shifts can be mitigated through post-hoc intervention, or avoided in the first place with a new preventative steering method. Moreover, persona vectors can be used to flag training data that will produce undesirable personality changes, both at the dataset level and the individual sample level. Our method for extracting persona vectors is automated and can be applied to any personality trait of interest, given only a natural-language description.},
	number = {{arXiv}:2507.21509},
	publisher = {{arXiv}},
	author = {Chen, Runjin and Arditi, Andy and Sleight, Henry and Evans, Owain and Lindsey, Jack},
	urldate = {2025-09-13},
	date = {2025-09-05},
	eprinttype = {arxiv},
	eprint = {2507.21509 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@inproceedings{jiang_personallm_2024,
	location = {Mexico City, Mexico},
	title = {{PersonaLLM}: Investigating the Ability of Large Language Models to Express Personality Traits},
	url = {https://aclanthology.org/2024.findings-naacl.229/},
	doi = {10.18653/v1/2024.findings-naacl.229},
	shorttitle = {{PersonaLLM}},
	abstract = {Despite the many use cases for large language models ({LLMs}) in creating personalized chatbots, there has been limited research on evaluating the extent to which the behaviors of personalized {LLMs} accurately and consistently reflect specific personality traits. We consider studying the behavior of {LLM}-based agents which we refer to as {LLM} personas and present a case study with {GPT}-3.5 and {GPT}-4 to investigate whether {LLMs} can generate content that aligns with their assigned personality profiles. To this end, we simulate distinct {LLM} personas based on the Big Five personality model, have them complete the 44-item Big Five Inventory ({BFI}) personality test and a story writing task, and then assess their essays with automatic and human evaluations. Results show that {LLM} personas' self-reported {BFI} scores are consistent with their designated personality types, with large effect sizes observed across five traits. Additionally, {LLM} personas' writings have emerging representative linguistic patterns for personality traits when compared with a human writing corpus. Furthermore, human evaluation shows that humans can perceive some personality traits with an accuracy of up to 80\%. Interestingly, the accuracy drops significantly when the annotators were informed of {AI} authorship.},
	eventtitle = {Findings 2024},
	pages = {3605--3627},
	booktitle = {Findings of the Association for Computational Linguistics: {NAACL} 2024},
	publisher = {Association for Computational Linguistics},
	author = {Jiang, Hang and Zhang, Xiajie and Cao, Xubo and Breazeal, Cynthia and Roy, Deb and Kabbara, Jad},
	editor = {Duh, Kevin and Gomez, Helena and Bethard, Steven},
	urldate = {2025-06-12},
	date = {2024-06},
}

@misc{zhang_persuasion_2025,
	title = {Persuasion Should be Double-Blind: A Multi-Domain Dialogue Dataset With Faithfulness Based on Causal Theory of Mind},
	url = {https://arxiv.org/abs/2502.21297v1},
	shorttitle = {Persuasion Should be Double-Blind},
	abstract = {Persuasive dialogue plays a pivotal role in human communication, influencing various domains. Recent persuasive dialogue datasets often fail to align with real-world interpersonal interactions, leading to unfaithful representations. For instance, unrealistic scenarios may arise, such as when the persuadee explicitly instructs the persuader on which persuasion strategies to employ, with each of the persuadee's questions corresponding to a specific strategy for the persuader to follow. This issue can be attributed to a violation of the "Double Blind" condition, where critical information is fully shared between participants. In actual human interactions, however, key information such as the mental state of the persuadee and the persuasion strategies of the persuader is not directly accessible. The persuader must infer the persuadee's mental state using Theory of Mind capabilities and construct arguments that align with the persuadee's motivations. To address this gap, we introduce {ToMMA}, a novel multi-agent framework for dialogue generation that is guided by causal Theory of Mind. This framework ensures that information remains undisclosed between agents, preserving "double-blind" conditions, while causal {ToM} directs the persuader's reasoning, enhancing alignment with human-like persuasion dynamics. Consequently, we present {CToMPersu}, a multi-domain, multi-turn persuasive dialogue dataset that tackles both double-blind and logical coherence issues, demonstrating superior performance across multiple metrics and achieving better alignment with real human dialogues. Our dataset and prompts are available at https://github.com/{DingyiZhang}/{ToMMA}-{CToMPersu} .},
	author = {Zhang, Dingyi and Zhou, Deyu},
	urldate = {2025-06-12},
	date = {2025-02-28},
	langid = {english},
}

@misc{yu_persuasivetom_2025,
	title = {{PersuasiveToM}: A Benchmark for Evaluating Machine Theory of Mind in Persuasive Dialogues},
	url = {https://arxiv.org/abs/2502.21017v2},
	shorttitle = {{PersuasiveToM}},
	abstract = {The ability to understand and predict the mental states of oneself and others, known as the Theory of Mind ({ToM}), is crucial for effective social scenarios. Although recent studies have evaluated {ToM} in Large Language Models ({LLMs}), existing benchmarks focus on simplified settings (e.g., Sally-Anne-style tasks) and overlook the complexity of real-world social interactions. To mitigate this gap, we propose {PersuasiveToM}, a benchmark designed to evaluate the {ToM} abilities of {LLMs} in persuasive dialogues. Our framework contains two core tasks: {ToM} Reasoning, which tests tracking of evolving desires, beliefs, and intentions; and {ToM} Application, which assesses the use of inferred mental states to predict and evaluate persuasion strategies. Experiments across eight leading {LLMs} reveal that while models excel on multiple questions, they struggle with the tasks that need tracking the dynamics and shifts of mental states and understanding the mental states in the whole dialogue comprehensively. Our aim with {PersuasiveToM} is to allow an effective evaluation of the {ToM} reasoning ability of {LLMs} with more focus on complex psychological activities. Our code is available at https://github.com/Yu-Fangxu/{PersuasiveToM}.},
	author = {Yu, Fangxu and Jiang, Lai and Huang, Shenyi and Wu, Zhen and Dai, Xinyu},
	urldate = {2025-06-12},
	date = {2025-02-28},
	langid = {english},
}

@article{voss_playing_2020,
	title = {Playing a Strategy Game with Knowledge-Based Reinforcement Learning},
	volume = {1},
	issn = {2662-995X, 2661-8907},
	url = {http://arxiv.org/abs/1908.05472},
	doi = {10.1007/s42979-020-0087-8},
	abstract = {This paper presents Knowledge-Based Reinforcement Learning ({KB}-{RL}) as a method that combines a knowledge-based approach and a reinforcement learning ({RL}) technique into one method for intelligent problem solving. The proposed approach focuses on multi-expert knowledge acquisition, with the reinforcement learning being applied as a conflict resolution strategy aimed at integrating the knowledge of multiple exerts into one knowledge base. The article describes the {KB}-{RL} approach in detail and applies the reported method to one of the most challenging problems of current Artificial Intelligence ({AI}) research, namely playing a strategy game. The results show that the {KB}-{RL} system is able to play and complete the full {FreeCiv} game, and to win against the computer players in various game settings. Moreover, with more games played, the system improves the gameplay by shortening the number of rounds that it takes to win the game. Overall, the reported experiment supports the idea that, based on human knowledge and empowered by reinforcement learning, the {KB}-{RL} system can deliver a strong solution to the complex, multi-strategic problems, and, mainly, to improve the solution with increased experience.},
	pages = {78},
	number = {2},
	journaltitle = {{SN} Computer Science},
	shortjournal = {{SN} {COMPUT}. {SCI}.},
	author = {Voss, Viktor and Nechepurenko, Liudmyla and Schaefer, Rudi and Bauer, Steffen},
	urldate = {2025-09-11},
	date = {2020-03},
	eprinttype = {arxiv},
	eprint = {1908.05472 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{brookins_playing_2023,
	title = {Playing Games With {GPT}: What Can We Learn About a Large Language Model From Canonical Strategic Games?},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=4493398},
	doi = {10.2139/ssrn.4493398},
	shorttitle = {Playing Games With {GPT}},
	journaltitle = {{SSRN} Electronic Journal},
	shortjournal = {{SSRN} Journal},
	author = {Brookins, Philip and {DeBacker}, Jason Matthew},
	urldate = {2025-09-13},
	date = {2023},
	langid = {english},
}

@article{akata_playing_2025,
	title = {Playing repeated games with Large Language Models},
	volume = {9},
	issn = {2397-3374},
	url = {http://arxiv.org/abs/2305.16867},
	doi = {10.1038/s41562-025-02172-y},
	abstract = {{LLMs} are increasingly used in applications where they interact with humans and other agents. We propose to use behavioural game theory to study {LLM}'s cooperation and coordination behaviour. We let different {LLMs} play finitely repeated \$2{\textbackslash}times2\$ games with each other, with human-like strategies, and actual human players. Our results show that {LLMs} perform particularly well at self-interested games like the iterated Prisoner's Dilemma family. However, they behave sub-optimally in games that require coordination, like the Battle of the Sexes. We verify that these behavioural signatures are stable across robustness checks. We additionally show how {GPT}-4's behaviour can be modulated by providing additional information about its opponent and by using a "social chain-of-thought" ({SCoT}) strategy. This also leads to better scores and more successful coordination when interacting with human players. These results enrich our understanding of {LLM}'s social behaviour and pave the way for a behavioural game theory for machines.},
	pages = {1380--1390},
	number = {7},
	journaltitle = {Nature Human Behaviour},
	shortjournal = {Nat Hum Behav},
	author = {Akata, Elif and Schulz, Lion and Coda-Forno, Julian and Oh, Seong Joon and Bethge, Matthias and Schulz, Eric},
	urldate = {2025-09-12},
	date = {2025-05-08},
	eprinttype = {arxiv},
	eprint = {2305.16867 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{horn_playing_2011,
	title = {Playing war games to win},
	journaltitle = {{McKinsey} Quarterly},
	shortjournal = {{McKinsey} Quarterly},
	author = {Horn, John},
	date = {2011-12-03},
	note = {Publisher: {McKinsey} \& Company},
	keywords = {Business strategy, Competitive strategy, Decision making, Simulation, War games},
}

@misc{hu_pokellmon_2024,
	title = {{PokeLLMon}: A Human-Parity Agent for Pokemon Battles with Large Language Models},
	url = {http://arxiv.org/abs/2402.01118},
	doi = {10.48550/arXiv.2402.01118},
	shorttitle = {{PokeLLMon}},
	abstract = {We introduce {PokeLLMon}, the first {LLM}-embodied agent that achieves human-parity performance in tactical battle games, as demonstrated in Pokemon battles. The design of {PokeLLMon} incorporates three key strategies: (i) In-context reinforcement learning that instantly consumes text-based feedback derived from battles to iteratively refine the policy; (ii) Knowledge-augmented generation that retrieves external knowledge to counteract hallucination and enables the agent to act timely and properly; (iii) Consistent action generation to mitigate the panic switching phenomenon when the agent faces a powerful opponent and wants to elude the battle. We show that online battles against human demonstrates {PokeLLMon}'s human-like battle strategies and just-in-time decision making, achieving 49\% of win rate in the Ladder competitions and 56\% of win rate in the invited battles. Our implementation and playable battle logs are available at: https://github.com/git-disl/{PokeLLMon}.},
	number = {{arXiv}:2402.01118},
	publisher = {{arXiv}},
	author = {Hu, Sihao and Huang, Tiansheng and Liu, Ling},
	urldate = {2025-09-13},
	date = {2024-04-02},
	eprinttype = {arxiv},
	eprint = {2402.01118 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{robinson_policy_2021,
	title = {Policy lensing of future-oriented strategic intelligence: An experiment connecting foresight with decision making contexts},
	volume = {169},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162521002353},
	doi = {10.1016/j.techfore.2021.120803},
	shorttitle = {Policy lensing of future-oriented strategic intelligence},
	abstract = {The rich and complex outcomes of foresight activities are often difficult to translate into policy relevant intelligence. The struggle in connecting futures intelligence to policy making can be read as a basic challenge in foresight: working on futures intelligence has emerged as a way to improve policy, but once it is delegated to professional foresight practitioners with attendant quality and quality control, however, it also introduces a distance to policy making. Whilst independence and methodological rigour is desirable for high quality futures intelligence, bridging this intelligence with the policy context is essential for its use. Experiencing this challenge during a scenario exercise on the future European research and innovation system, the authors of this paper embarked on an experiment to go beyond evaluating the robustness of the scenarios, produced in a foresight exercise, by developing and applying “policy lenses” to translate the scenarios into policy tailored intelligence. This paper describes the experiment, which saw the development and application of three types of policy lenses: (1) a lens based on the layered processes of European policy making, (2) a lens based on three research and innovation policy priorities and (3) a lens on alternative geo-political situations of the European continent. The paper describes the logic behind the lenses, the interpretation of the original scenarios when viewed through these lenses, and then concludes by reflecting on how such an experiment could be generalised to other settings of policy-oriented foresight.},
	pages = {120803},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Robinson, Douglas K. R. and Schoen, Antoine and Larédo, Philippe and Gallart, Jordi Molas and Warnke, Philine and Kuhlmann, Stefan and Ordóñez-Matamoros, Gonzalo},
	urldate = {2025-06-12},
	date = {2021-08-01},
	keywords = {Europeanisation, Innovation systems, Mission-oriented policy, Policy-lensing, Research systems, Scenarios},
}

@misc{iofinova_position_2025,
	title = {Position: It's Time to Act on the Risk of Efficient Personalized Text Generation},
	url = {https://arxiv.org/abs/2502.06560v2},
	shorttitle = {Position},
	abstract = {The recent surge in high-quality open-source Generative {AI} text models (colloquially: {LLMs}), as well as efficient finetuning techniques, have opened the possibility of creating high-quality personalized models that generate text attuned to a specific individual's needs and are capable of credibly imitating their writing style by refining an open-source model with that person's own data. The technology to create such models is accessible to private individuals, and training and running such models can be done cheaply on consumer-grade hardware. While these advancements are a huge gain for usability and privacy, this position paper argues that the practical feasibility of impersonating specific individuals also introduces novel safety risks. For instance, this technology enables the creation of phishing emails or fraudulent social media accounts, based on small amounts of publicly available text, or by the individuals themselves to escape {AI} text detection. We further argue that these risks are complementary to - and distinct from - the much-discussed risks of other impersonation attacks such as image, voice, or video deepfakes, and are not adequately addressed by the larger research community, or the current generation of open- and closed-source models.},
	author = {Iofinova, Eugenia and Jovanovic, Andrej and Alistarh, Dan},
	urldate = {2025-06-12},
	date = {2025-02-10},
	langid = {english},
}

@book{london_practical_1915,
	location = {London},
	title = {Practical Warfare : Chapters on Armies and Navies in Action},
	isbn = {{LCCN} 15000762},
	url = {https://archive.org/details/practicalwarfare00londiala},
	pagetotal = {162},
	publisher = {Eveleigh Nash},
	author = {London, Nash},
	date = {1915},
}

@article{watkins_predictable_2003,
	title = {Predictable Surprises: The Disasters You Should Have Seen Coming},
	issn = {0017-8012},
	url = {https://hbr.org/2003/04/predictable-surprises-the-disasters-you-should-have-seen-coming},
	shorttitle = {Predictable Surprises},
	journaltitle = {Harvard Business Review},
	author = {Watkins, Michael D. and Bazerman, Max H.},
	urldate = {2025-06-12},
	date = {2003-04},
	langid = {english},
}

@article{coyne_predicting_2009,
	title = {Predicting Your Competitor’s Reaction},
	issn = {0017-8012},
	url = {https://hbr.org/2009/04/predicting-your-competitors-reaction},
	journaltitle = {Harvard Business Review},
	author = {Coyne, Kevin P. and Horn, John},
	urldate = {2025-06-12},
	date = {2009},
	langid = {english},
}

@inproceedings{downes-martin_preference_2020,
	location = {{McGill} University, Montreal, Canada},
	title = {Preference Reversal Effects and Wargaming},
	url = {https://paxsims.wordpress.com/wp-content/uploads/2020/09/downes-martin-connections-2020.pdf},
	eventtitle = {Connections North 2020 Wargaming Conference},
	author = {Downes-Martin, Stephen},
	date = {2020-02-15},
}

@misc{liang_principled_2017,
	title = {Principled Detection of Out-of-Distribution Examples in Neural Networks},
	url = {http://arxiv.org/abs/1706.02690},
	doi = {10.48550/arXiv.1706.02690},
	abstract = {We consider the problem of detecting out-of-distribution examples in neural networks. We propose {ODIN}, a simple and effective out-of-distribution detector for neural networks, that does not require any change to a pre-trained model. Our method is based on the observation that using temperature scaling and adding small perturbations to the input can separate the softmax score distributions of in- and out-of-distribution samples, allowing for more effective detection. We show in a series of experiments that our approach is compatible with diverse network architectures and datasets. It consistently outperforms the baseline approach[1] by a large margin, establishing a new state-of-the-art performance on this task. For example, {ODIN} reduces the false positive rate from the baseline 34.7\% to 4.3\% on the {DenseNet} (applied to {CIFAR}-10) when the true positive rate is 95\%. We theoretically analyze the method and prove that performance improvement is guaranteed under mild conditions on the image distributions.},
	number = {{arXiv}:1706.02690},
	publisher = {{arXiv}},
	author = {Liang, Shiyu and Li, Yixuan and Srikant, R.},
	urldate = {2025-09-13},
	date = {2017-06-21},
	eprinttype = {arxiv},
	eprint = {1706.02690 [cs]},
	note = {version: 2},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{tricco_prisma_2018,
	title = {{PRISMA} Extension for Scoping Reviews ({PRISMA}-{ScR}): Checklist and Explanation},
	volume = {169},
	url = {https://www.acpjournals.org/doi/10.7326/M18-0850},
	doi = {10.7326/M18-0850},
	pages = {467--473},
	number = {7},
	journaltitle = {Annals of Internal Medicine},
	shortjournal = {Annals of Internal Medicine},
	author = {Tricco, Andrea C. and Lillie, Erin and Zarin, Wasifa and O'Brien, Kelly K. and Colquhoun, Heather and Levac, Danielle and Moher, David and Peters, Micah D. J. and Horsley, Tanya and Weeks, Laura},
	date = {2018-10-02},
}

@misc{al_project_2024,
	title = {Project Sid: Many-agent simulations toward {AI} civilization},
	url = {http://arxiv.org/abs/2411.00114},
	doi = {10.48550/arXiv.2411.00114},
	shorttitle = {Project Sid},
	abstract = {{AI} agents have been evaluated in isolation or within small groups, where interactions remain limited in scope and complexity. Large-scale simulations involving many autonomous agents -- reflecting the full spectrum of civilizational processes -- have yet to be explored. Here, we demonstrate how 10 - 1000+ {AI} agents behave and progress within agent societies. We first introduce the {PIANO} (Parallel Information Aggregation via Neural Orchestration) architecture, which enables agents to interact with humans and other agents in real-time while maintaining coherence across multiple output streams. We then evaluate agent performance in agent simulations using civilizational benchmarks inspired by human history. These simulations, set within a Minecraft environment, reveal that agents are capable of meaningful progress -- autonomously developing specialized roles, adhering to and changing collective rules, and engaging in cultural and religious transmission. These preliminary results show that agents can achieve significant milestones towards {AI} civilizations, opening new avenues for large simulations, agentic organizational intelligence, and integrating {AI} into human civilizations.},
	number = {{arXiv}:2411.00114},
	publisher = {{arXiv}},
	author = {{AL}, Altera and Ahn, Andrew and Becker, Nic and Carroll, Stephanie and Christie, Nico and Cortes, Manuel and Demirci, Arda and Du, Melissa and Li, Frankie and Luo, Shuying and Wang, Peter Y. and Willows, Mathew and Yang, Feitong and Yang, Guangyu Robert},
	urldate = {2025-09-13},
	date = {2024-10-31},
	eprinttype = {arxiv},
	eprint = {2411.00114 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Multiagent Systems},
}

@article{mckiernan_prospective_2017,
	title = {Prospective thinking; scenario planning meets neuroscience},
	volume = {124},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162516306588},
	doi = {10.1016/j.techfore.2016.10.069},
	abstract = {The Intuitive Logics ({IL}) scenario planning process is grounded in the work of Hermann Kahn and Pierre Wack in the 1960s and 1970s. Its broad adoption and sustained use over 50years have taken it beyond the typical management fashion or fad. It has helped shape the strategies of many types of institutions and organisations. The process encourages individuals to recall past events and to imagine future happenings. But, little is known about neither how they do this nor the contextual conditions that shape how they do it and how they might do it better. Recent developments in cognitive psychology and neuroscience have had success in several management domains e.g., marketing, information systems, leadership, economics and finance. However, little attention has been paid to their application in strategic management and, in particular, in scenario planning. The paper provides a critical coverage of the pertinent cognitive sciences literature and explores opportunities for co-joint research between scenario planners and cognitive psychologists that might help to further foster and support the {IL} process.},
	pages = {66--76},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {{McKiernan}, Peter},
	urldate = {2025-06-12},
	date = {2017-11-01},
}

@article{gnyawali_pursuit_2016,
	title = {Pursuit of rigor in research: Illustration from coopetition literature},
	volume = {57},
	issn = {0019-8501},
	url = {https://www.sciencedirect.com/science/article/pii/S0019850116300785},
	doi = {10.1016/j.indmarman.2016.05.004},
	shorttitle = {Pursuit of rigor in research},
	abstract = {We propose that rigor consists of three key aspects: conceptual (the theoretical lens, constructs, and logic used to understand a phenomenon), methodological (how data are collected and analyzed to capture a phenomenon), and empirical (how findings are organized, distilled, and related to the theory). We discuss rigor in the context of coopetition research and explain how rigor could be enhanced in future research. For each aspect of rigor, we discuss what it means to conduct rigorous research, review the current state of coopetition research using a rigor lens, and systematically discuss ways of improving rigor in future research. We suggest that pursuit of research with greater level of rigor would help increase the impact of coopetition research and contribute to the creation of cumulative knowledge on the topic.},
	pages = {12--22},
	journaltitle = {Industrial Marketing Management},
	shortjournal = {Industrial Marketing Management},
	author = {Gnyawali, Devi R. and Song, Yue},
	urldate = {2025-06-12},
	date = {2016-08-01},
	keywords = {Conceptual rigor, Coopetition, Empirical rigor, Methodological rigor},
}

@unpublished{chen_put_2023,
	title = {Put your money where your mouth is: Evaluating strategic planning and execution of {LLM} agents in an auction arena},
	url = {http://arxiv.org/abs/2310.05746},
	abstract = {Recent advancements in Large Language Models ({LLMs}) showcase advanced
reasoning, yet {NLP} evaluations often depend on static benchmarks.
Evaluating this necessitates environments that test strategic reasoning in
dynamic, competitive scenarios requiring long-term planning. We introduce
{AucArena}, a novel evaluation suite that simulates auctions, a setting
chosen for being highly unpredictable and involving many skills related to
resource and risk management, while also being easy to evaluate. We
conduct controlled experiments using state-of-the-art {LLMs} to power
bidding agents to benchmark their planning and execution skills. Our
research demonstrates that {LLMs}, such as {GPT}-4, possess key skills for
auction participation, such as budget management and goal adherence, which
improve with adaptive strategies. This highlights {LLMs}' potential in
modeling complex social interactions in competitive contexts. However,
variability in {LLM} performance and occasional outperformance by simpler
methods indicate opportunities for further advancements in {LLM} design and
the value of our simulation environment for ongoing testing and
refinement.},
	author = {Chen, Jiangjie and Yuan, Siyu and Ye, Rong and Majumder, Bodhisattwa Prasad and Richardson, Kyle},
	date = {2023-10-09},
	note = {{ISBN}: 2310.05746
Publication Title: {arXiv} [cs.{CL}]},
}

@unpublished{hao_reasoning_2023,
	title = {Reasoning with language model is planning with world model},
	url = {https://www.semanticscholar.org/paper/5dbffedcabe3fa43060ebbe2b1789500edfd871f},
	abstract = {Large language models ({LLMs}) have shown remarkable reasoning capabilities, especially when prompted to generate intermediate reasoning steps (e.g., Chain-of-Thought, {CoT}). However, {LLMs} can still struggle with problems that are easy for humans, such as generating action plans for executing tasks in a given environment, or performing complex math, logical, and commonsense reasoning. The deficiency stems from the key fact that {LLMs} lack an internal \${\textbackslash}textit\{world model\}\$ to predict the world \${\textbackslash}textit\{state\}\$ (e.g., environment status, intermediate variable values) and simulate long-term outcomes of actions. This prevents {LLMs} from performing deliberate planning akin to human brains, which involves exploring alternative reasoning paths, anticipating future states and rewards, and iteratively refining existing reasoning steps. To overcome the limitations, we propose a new {LLM} reasoning framework,
\${\textbackslash}underline\{R\}\$easoning vi\${\textbackslash}underline\{a\}\$ \${\textbackslash}underline\{P\}\$lanning \${\textbackslash}textbf\{({RAP})\}\$. {RAP} repurposes the {LLM} as both a world model and a reasoning agent, and incorporates a principled planning algorithm (based on Monto Carlo Tree Search) for strategic exploration in the vast reasoning space. During reasoning, the {LLM} (as agent) incrementally builds a reasoning tree under the guidance of the {LLM} (as world model) and task-specific rewards, and obtains a high-reward reasoning path efficiently with a proper balance between exploration \${\textbackslash}textit\{vs.\}\$ exploitation. We apply {RAP} to a variety of challenging reasoning problems including plan generation, math reasoning, and logical inference. Empirical results on these tasks demonstrate the superiority of {RAP} over various strong baselines, including {CoT} and least-to-most prompting with self-consistency. {RAP} on {LLAMA}-33B surpasses {CoT} on {GPT}-4 with 33\% relative improvement in a plan generation setting.},
	author = {Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
	urldate = {2025-05-20},
	date = {2023-05-24},
	doi = {10.48550/arXiv.2305.14992},
	note = {{ISBN}: 2305.14992
Publication Title: {arXiv} [cs.{CL}]},
}

@incollection{grossmann_recent_2015,
	title = {Recent Advances in Mathematical Programming Techniques for the Optimization of Process Systems under Uncertainty},
	volume = {37},
	url = {https://www.sciencedirect.com/science/article/pii/B9780444635785500013},
	series = {12 International Symposium on Process Systems Engineering and 25 European Symposium on Computer Aided Process Engineering},
	abstract = {Optimization under uncertainty has been an active area of research for many years. However, its application in Process Synthesis has faced a number of important barriers that have prevented its effective application. Barriers include availability of information on the uncertainty of the data (ad-hoc or historical), determination of the nature of the uncertainties (exogenous vs. endogenous), selection of an appropriate strategy for hedging against uncertainty (robust optimization vs. stochastic programming), large computational expense (often orders of magnitude larger than deterministic models), and difficulty in the interpretation of the results by non-expert users. In this paper, we describe recent advances that have addressed some of these barriers.},
	pages = {1--14},
	booktitle = {Computer Aided Chemical Engineering},
	publisher = {Elsevier},
	author = {Grossmann, Ignacio E. and Apap, Robert M. and Calfa, Bruno A. and Garcia-Herreros, Pablo and Zhang, Qi},
	editor = {Gernaey, Krist V. and Huusom, Jakob K. and Gani, Rafiqul},
	urldate = {2025-06-12},
	date = {2015-01-01},
	doi = {10.1016/B978-0-444-63578-5.50001-3},
	keywords = {decision rule, endogenous uncertainty, exogenous uncertainty, robust optimization, scenario generation, stochastic programming},
}

@misc{wei_recommendations_2025,
	title = {Recommendations and Reporting Checklist for Rigorous \& Transparent Human Baselines in Model Evaluations},
	url = {http://arxiv.org/abs/2506.13776},
	doi = {10.48550/arXiv.2506.13776},
	abstract = {In this position paper, we argue that human baselines in foundation model evaluations must be more rigorous and more transparent to enable meaningful comparisons of human vs. {AI} performance, and we provide recommendations and a reporting checklist towards this end. Human performance baselines are vital for the machine learning community, downstream users, and policymakers to interpret {AI} evaluations. Models are often claimed to achieve "super-human" performance, but existing baselining methods are neither sufficiently rigorous nor sufficiently well-documented to robustly measure and assess performance differences. Based on a meta-review of the measurement theory and {AI} evaluation literatures, we derive a framework with recommendations for designing, executing, and reporting human baselines. We synthesize our recommendations into a checklist that we use to systematically review 115 human baselines (studies) in foundation model evaluations and thus identify shortcomings in existing baselining methods; our checklist can also assist researchers in conducting human baselines and reporting results. We hope our work can advance more rigorous {AI} evaluation practices that can better serve both the research community and policymakers. Data is available at: https://github.com/kevinlwei/human-baselines},
	number = {{arXiv}:2506.13776},
	publisher = {{arXiv}},
	author = {Wei, Kevin L. and Paskov, Patricia and Dev, Sunishchal and Byun, Michael J. and Reuel, Anka and Roberts-Gaal, Xavier and Calcott, Rachel and Coxon, Evie and Deshpande, Chinmay},
	urldate = {2025-09-10},
	date = {2025-06-09},
	eprinttype = {arxiv},
	eprint = {2506.13776 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction},
}

@article{wei_recurrent_2020,
	title = {Recurrent {MADDPG} for Object Detection and Assignment in Combat Tasks},
	volume = {8},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9187817/},
	doi = {10.1109/ACCESS.2020.3022638},
	abstract = {With the development of artificial intelligence, multiagent algorithms have been applied to many real-time strategy games. Making plans on the human being is gradually passing away, especially in combat scenarios. Cognitive electronic warfare ({CEW}) is a complex and challenging work due to the sensitivity of the data sources. There are few studies on {CEW}. In the past, wargame simulations depended on differential equations and war theory, which resulted in high time and human resource costs. In the future, as other artificial intelligence theories are developed, artificial intelligence will play a more critical role in wargames. The capabilities of multiagent modeling to describe complex systems and predict actions in dynamic environments are superior to those of traditional methods. In this paper, we use a 3D wargame engine from China Aerospace System Simulation Technology Co., Ltd. (Beijing) named All Domain Simulation ({ACS}), which supports land, sea, and air combat scenarios, to simulate combat. In the simulations, there are several unmanned air vehicles ({UAVs}) as attackers and several radar stations as defenders, and both have the ability to detect the others. In the game, several {UAVs} need to learn to detect targets and track targets separately, and we train the {UAV}’s behavior by well-designed reward shaping and multiagent reinforcement learning ({MARL}) with {LSTM}. We improved the {RDPG} algorithm and merged the {MADDPG} and {RDPG} algorithms. From the experimental results, we can see that the effectiveness and accuracy of the algorithm have been greatly improved.},
	pages = {163334--163343},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Wei, Xiaolong and Yang, Lifang and Cao, Gang and Lu, Tao and Wang, Bing},
	urldate = {2025-09-13},
	date = {2020},
}

@book{uk_ministry_of_defense_red_2021,
	edition = {3d},
	title = {Red Teaming Handbook},
	publisher = {Development, Concepts and Doctrine Centre},
	author = {{UK} Ministry of Defense},
	date = {2021},
	langid = {english},
}

@article{suzuki_reminder_2016,
	title = {Reminder game: Indirectness in persuasion},
	volume = {100},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825616301142},
	doi = {10.1016/j.geb.2016.09.011},
	shorttitle = {Reminder game},
	abstract = {A seller wants a buyer to choose a good whose value is the seller's private information. The buyer's memory is limited, and she decides whether to remember the good conditional on a signal about the value. The seller then decides whether to send a costless message that can remind the buyer of the good. Since the reminder could convey the seller's private information in equilibrium, whether to send a reminder is a non-trivial question. It is shown that costless messages can be informative in equilibrium in spite of the strong conflict of interest between the players. In any informative equilibrium, silence conveys positive information about the value, whereas the reminder conveys negative information.},
	pages = {240--256},
	journaltitle = {Games and Economic Behavior},
	shortjournal = {Games and Economic Behavior},
	author = {Suzuki, Toru},
	urldate = {2025-06-12},
	date = {2016-11-01},
	keywords = {Communication game, Endogenous consideration set, Imperfect recall, Indirectness},
}

@article{yu_research_2023,
	title = {Research on Wargame Decision-Making Method Based on Multi-Agent Deep Deterministic Policy Gradient},
	volume = {13},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/13/7/4569},
	doi = {10.3390/app13074569},
	abstract = {Wargames are essential simulators for various war scenarios. However, the increasing pace of warfare has rendered traditional wargame decision-making methods inadequate. To address this challenge, wargame-assisted decision-making methods that leverage artificial intelligence techniques, notably reinforcement learning, have emerged as a promising solution. The current wargame environment is beset by a large decision space and sparse rewards, presenting obstacles to optimizing decision-making methods. To overcome these hurdles, a Multi-Agent Deep Deterministic Policy Gradient ({MADDPG}) based wargame decision-making method is presented. The Partially Observable Markov Decision Process ({POMDP}), joint action-value function, and the Gumbel-Softmax estimator are applied to optimize {MADDPG} in order to adapt to the wargame environment. Furthermore, a wargame decision-making method based on the improved {MADDPG} algorithm is proposed. Using supervised learning in the proposed approach, the training efficiency is improved and the space for manipulation before the reinforcement learning phase is reduced. In addition, a policy gradient estimator is incorporated to reduce the action space and to obtain the global optimal solution. Furthermore, an additional reward function is designed to address the sparse reward problem. The experimental results demonstrate that our proposed wargame decision-making method outperforms the pre-optimization algorithm and other algorithms based on the {AC} framework in the wargame environment. Our approach offers a promising solution to the challenging problem of decision-making in wargame scenarios, particularly given the increasing speed and complexity of modern warfare.},
	pages = {4569},
	number = {7},
	journaltitle = {Applied Sciences},
	shortjournal = {Applied Sciences},
	author = {Yu, Sheng and Zhu, Wei and Wang, Yong},
	urldate = {2025-09-13},
	date = {2023-04-04},
	langid = {english},
}

@misc{diallo_response_2025,
	title = {{RESPONSE}: Benchmarking the Ability of Language Models to Undertake Commonsense Reasoning in Crisis Situation},
	url = {http://arxiv.org/abs/2503.11348},
	doi = {10.48550/arXiv.2503.11348},
	shorttitle = {{RESPONSE}},
	abstract = {An interesting class of commonsense reasoning problems arises when people are faced with natural disasters. To investigate this topic, we present {\textbackslash}textsf\{{RESPONSE}\}, a human-curated dataset containing 1789 annotated instances featuring 6037 sets of questions designed to assess {LLMs}' commonsense reasoning in disaster situations across different time frames. The dataset includes problem descriptions, missing resources, time-sensitive solutions, and their justifications, with a subset validated by environmental engineers. Through both automatic metrics and human evaluation, we compare {LLM}-generated recommendations against human responses. Our findings show that even state-of-the-art models like {GPT}-4 achieve only 37{\textbackslash}\% human-evaluated correctness for immediate response actions, highlighting significant room for improvement in {LLMs}' ability for commonsense reasoning in crises.},
	number = {{arXiv}:2503.11348},
	publisher = {{arXiv}},
	author = {Diallo, Aissatou and Bikakis, Antonis and Dickens, Luke and Hunter, Anthony and Miller, Rob},
	urldate = {2025-09-12},
	date = {2025-03-14},
	eprinttype = {arxiv},
	eprint = {2503.11348 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{chang_restructuring_2018,
	title = {Restructuring structured analytic techniques in intelligence},
	volume = {33},
	issn = {0268-4527},
	url = {https://doi.org/10.1080/02684527.2017.1400230},
	doi = {10.1080/02684527.2017.1400230},
	abstract = {Structured analytic techniques ({SATs}) are intended to improve intelligence
analysis by checking the two canonical sources of error: systematic biases
and random noise. Although both goals are achievable, no one knows how
close the current generation of {SATs} comes to achieving either of them. We
identify two root problems: (1) {SATs} treat bipolar biases as unipolar. As
a result, we lack metrics for gauging possible over-shooting?and have no
way of knowing when {SATs} that focus on suppressing one bias (e.g.,
over-confidence) are triggering the opposing bias (e.g.,
under-confidence); (2) {SATs} tacitly assume that problem decomposition
(e.g., breaking reasoning into rows and columns of matrices corresponding
to hypotheses and evidence) is a sound means of reducing noise in
assessments. But no one has ever actually tested whether decomposition is
adding or subtracting noise from the analytic process?and there are good
reasons for suspecting that decomposition will, on balance, degrade the
reliability of analytic judgment. The central shortcoming is that {SATs}
have not been subject to sustained scientific of the sort that could
reveal when they are helping or harming the cause of delivering accurate
assessments of the world to the policy community.},
	pages = {337--356},
	number = {3},
	journaltitle = {Intell. Natl. Sec.},
	author = {Chang, Welton and Berdini, Elissabeth and Mandel, David R and Tetlock, Philip E},
	date = {2018-04-16},
	note = {Publisher: Routledge},
}

@article{chen_rethinking_2022,
	title = {Rethinking Adversarial Examples in Wargames},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/9857154/},
	doi = {10.1109/CVPRW56347.2022.00020},
	abstract = {Artificial intelligence technology is increasingly widely used in games, especially for wargames. The addition of artificial intelligence algorithms enables these games to solve decision-making problems in complex environments more quickly, surpassing the vast majority of experienced human players in competitive games. However, due to the vulnerability of the neural network before adversarial examples, all modules using artificial intelligence algorithms are at risk of being attacked. For wargames, adversarial examples will make the units in the game no longer able to follow the established routes or actions to perform tasks. Based on such risks, this paper proposes a deceptive concept scheme of attacking intelligent modules in wargames through adversarial examples, and proposes challenges and prospects for current technologies. To our knowledge, we are the first team to analyze the impact of adversarial examples in the running process of wargames, namely the {OODA} loop, and simulate them in the corresponding wargaming software. In the end, we found that when artificial intelligence technology is widely used in war games, adversarial examples will have a subversive impact on several activities in several steps, which will directly lead to the failure to complete the established game goals.},
	pages = {100--106},
	journaltitle = {2022 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	author = {Chen, Yuwei},
	urldate = {2025-09-13},
	date = {2022-06},
	note = {Conference Name: 2022 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})
{ISBN}: 9781665487399
Place: New Orleans, {LA}, {USA}
Publisher: {IEEE}},
}

@online{work_revitalizing_2015,
	title = {Revitalizing Wargaming is Necessary to Be Prepared for Future Wars},
	url = {http://warontherocks.com/2015/12/revitalizing-wargaming-is-necessary-to-be-prepared-for-future-wars/},
	titleaddon = {War on the Rocks},
	author = {Work, Bob and Selva, Paul},
	date = {2015-12-08},
	langid = {english},
}

@misc{guan_richelieu_2024,
	title = {Richelieu: Self-Evolving {LLM}-Based Agents for {AI} Diplomacy},
	url = {http://arxiv.org/abs/2407.06813},
	doi = {10.48550/arXiv.2407.06813},
	shorttitle = {Richelieu},
	abstract = {Diplomacy is one of the most sophisticated activities in human society, involving complex interactions among multiple parties that require skills in social reasoning, negotiation, and long-term strategic planning. Previous {AI} agents have demonstrated their ability to handle multi-step games and large action spaces in multi-agent tasks. However, diplomacy involves a staggering magnitude of decision spaces, especially considering the negotiation stage required. While recent agents based on large language models ({LLMs}) have shown potential in various applications, they still struggle with extended planning periods in complex multi-agent settings. Leveraging recent technologies for {LLM}-based agents, we aim to explore {AI}'s potential to create a human-like agent capable of executing comprehensive multi-agent missions by integrating three fundamental capabilities: 1) strategic planning with memory and reflection; 2) goal-oriented negotiation with social reasoning; and 3) augmenting memory through self-play games for self-evolution without human in the loop.},
	number = {{arXiv}:2407.06813},
	publisher = {{arXiv}},
	author = {Guan, Zhenyu and Kong, Xiangyu and Zhong, Fangwei and Wang, Yizhou},
	urldate = {2025-09-12},
	date = {2024-10-23},
	eprinttype = {arxiv},
	eprint = {2407.06813 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Multiagent Systems, Computer Science - Social and Information Networks},
}

@incollection{shevchuk_risk_2020,
	title = {Risk and social influence in sustainable smart home technologies},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-819204-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128192047000105},
	pages = {185--216},
	booktitle = {Cyber Influence and Cognitive Threats},
	publisher = {Elsevier},
	author = {Shevchuk, Nataliya and Oinas-Kukkonen, Harri and Benson, Vladlena},
	urldate = {2025-08-06},
	date = {2020},
	langid = {english},
	doi = {10.1016/B978-0-12-819204-7.00010-5},
}

@incollection{hillier_role_2001,
	location = {Boston, {MA}},
	title = {Role Playing: A Method to Forecast Decisions},
	volume = {30},
	isbn = {978-0-7923-7401-5 978-0-306-47630-3},
	url = {http://link.springer.com/10.1007/978-0-306-47630-3_2},
	shorttitle = {Role Playing},
	abstract = {Role playing can be used to forecast decisions, such as “how will our competitors respond if we lower our prices?” In role playing, an administrator asks people to play roles and uses their “decisions” as forecasts. Such an exercise can produce a realistic simulation of the interactions among conflicting groups. The role play should match the actual situation in key respects, such as the role-players should be somewhat similar to those being represented in the actual situations, and role-players should read instructions for their roles before reading about the situation. Role playing is most effective for predictions when two conflicting parties respond to large changes. A review of the evidence showed that role playing was effective in matching results for seven of eight experiments. In five actual situations, role playing was correct for 56 percent of 143 predictions, while unaided expert opinions were correct for 16 percent of 172 predictions. Role-playing has also been used successfully to forecast outcomes in three studies. Successful uses of role playing have been claimed in the military, law, and business.},
	pages = {15--30},
	booktitle = {Principles of Forecasting},
	publisher = {Springer {US}},
	author = {Armstrong, J. Scott},
	editor = {Armstrong, J. Scott},
	editorb = {Hillier, Frederick S.},
	editorbtype = {redactor},
	urldate = {2025-06-26},
	date = {2001},
	langid = {english},
	doi = {10.1007/978-0-306-47630-3_2},
	note = {Series Title: International Series in Operations Research \& Management Science},
}

@misc{khan_sc-phi2_2024,
	title = {{SC}-Phi2: A Fine-tuned Small Language Model for {StarCraft} {II} Macromanagement Tasks},
	url = {http://arxiv.org/abs/2409.18989},
	doi = {10.48550/arXiv.2409.18989},
	shorttitle = {{SC}-Phi2},
	abstract = {This paper introduces {SC}-Phi2, a fine-tuned {StarCraft} {II} small language model for macromanagement tasks. Small language models, like Phi2, Gemma, and {DistilBERT}, are streamlined versions of large language models ({LLMs}) with fewer parameters that require less power and memory to run. To teach Microsoft's Phi2 model about {StarCraft}, we create a new {SC}2 text dataset with information about {StarCraft} races, roles, and actions and use it to fine-tune Phi-2 with self-supervised learning. We pair this language model with a Vision Transformer ({ViT}) from the pre-trained {BLIP}-2 (Bootstrapping Language Image Pre-training) model, fine-tuning it on the {MSC} replay dataset. This enables us to construct dynamic prompts that include visual game state information. Unlike the large models used in {StarCraft} {LLMs} such as {GPT}-3.5, Phi2 is trained primarily on textbook data and contains little inherent knowledge of {StarCraft} {II} beyond what is provided by our training process. By using {LoRA} (Low-rank Adaptation) and quantization, our model can be trained on a single {GPU}. We demonstrate that our model performs well at micromanagement tasks such as build order and global state prediction with a small number of parameters.},
	number = {{arXiv}:2409.18989},
	publisher = {{arXiv}},
	author = {Khan, Muhammad Junaid and Sukthankar, Gita},
	urldate = {2025-09-13},
	date = {2024-09-17},
	eprinttype = {arxiv},
	eprint = {2409.18989 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{shen_sc2arena_2025,
	title = {{SC}2Arena and {StarEvolve}: Benchmark and Self-Improvement Framework for {LLMs} in Complex Decision-Making Tasks},
	url = {http://arxiv.org/abs/2508.10428},
	doi = {10.48550/arXiv.2508.10428},
	shorttitle = {{SC}2Arena and {StarEvolve}},
	abstract = {Evaluating large language models ({LLMs}) in complex decision-making is essential for advancing {AI}'s ability for strategic planning and real-time adaptation. However, existing benchmarks for tasks like {StarCraft} {II} fail to capture the game's full complexity, such as its complete game context, diverse action spaces, and all playable races. To address this gap, we present {SC}2Arena, a benchmark that fully supports all playable races, low-level action spaces, and optimizes text-based observations to tackle spatial reasoning challenges. Complementing this, we introduce {StarEvolve}, a hierarchical framework that integrates strategic planning with tactical execution, featuring iterative self-correction and continuous improvement via fine-tuning on high-quality gameplay data. Its key components include a Planner-Executor-Verifier structure to break down gameplay, and a scoring system for selecting high-quality training samples. Comprehensive analysis using {SC}2Arena provides valuable insights into developing generalist agents that were not possible with previous benchmarks. Experimental results also demonstrate that our proposed {StarEvolve} achieves superior performance in strategic planning. Our code, environment, and algorithms are publicly available.},
	number = {{arXiv}:2508.10428},
	publisher = {{arXiv}},
	author = {Shen, Pengbo and Wang, Yaqing and Mu, Ni and Luan, Yao and Xie, Runpeng and Yang, Senhao and Wang, Lexiang and Hu, Hao and Xu, Shuang and Yang, Yiqin and Xu, Bo},
	urldate = {2025-09-13},
	date = {2025-08-14},
	eprinttype = {arxiv},
	eprint = {2508.10428 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{black_scaling_2024,
	title = {Scaling Artificial Intelligence for Digital Wargaming in Support of Decision-Making},
	url = {http://arxiv.org/abs/2402.06075},
	doi = {10.14339/STO-MP-MSG-207-23-PDF},
	abstract = {In this unprecedented era of technology-driven transformation, it becomes more critical than ever that we aggressively invest in developing robust artificial intelligence ({AI}) for wargaming in support of decision-making. By advancing {AI}-enabled systems and pairing these with human judgment, we will be able to enhance all-domain awareness, improve the speed and quality of our decision cycles, offer recommendations for novel courses of action, and more rapidly counter our adversary's actions. It therefore becomes imperative that we accelerate the development of {AI} to help us better address the complexity of modern challenges and dilemmas that currently requires human intelligence and, if possible, attempt to surpass human intelligence--not to replace humans, but to augment and better inform human decision-making at machine speed. Although deep reinforcement learning continues to show promising results in intelligent agent behavior development for the long-horizon, complex tasks typically found in combat modeling and simulation, further research is needed to enable the scaling of {AI} to deal with these intricate and expansive state-spaces characteristic of wargaming for either concept development, education, or analysis. To help address this challenge, in our research, we are developing and implementing a hierarchical reinforcement learning framework that includes a multi-model approach and dimension-invariant observation abstractions.},
	author = {Black, Scotty and Darken, Christian},
	urldate = {2025-06-12},
	date = {2024-02-08},
	eprinttype = {arxiv},
	eprint = {2402.06075 [cs]},
}

@misc{engels_scaling_2025,
	title = {Scaling Laws For Scalable Oversight},
	url = {http://arxiv.org/abs/2504.18530},
	doi = {10.48550/arXiv.2504.18530},
	abstract = {Scalable oversight, the process by which weaker {AI} systems supervise stronger ones, has been proposed as a key strategy to control future superintelligent systems. However, it is still unclear how scalable oversight itself scales. To address this gap, we propose a framework that quantifies the probability of successful oversight as a function of the capabilities of the overseer and the system being overseen. Specifically, our framework models oversight as a game between capability-mismatched players; the players have oversight-specific Elo scores that are a piecewise-linear function of their general intelligence, with two plateaus corresponding to task incompetence and task saturation. We validate our framework with a modified version of the game Nim and then apply it to four oversight games: Mafia, Debate, Backdoor Code and Wargames. For each game, we find scaling laws that approximate how domain performance depends on general {AI} system capability. We then build on our findings in a theoretical study of Nested Scalable Oversight ({NSO}), a process in which trusted models oversee untrusted stronger models, which then become the trusted models in the next step. We identify conditions under which {NSO} succeeds and derive numerically (and in some cases analytically) the optimal number of oversight levels to maximize the probability of oversight success. We also apply our theory to our four oversight games, where we find that {NSO} success rates at a general Elo gap of 400 are 13.5\% for Mafia, 51.7\% for Debate, 10.0\% for Backdoor Code, and 9.4\% for Wargames; these rates decline further when overseeing stronger systems.},
	number = {{arXiv}:2504.18530},
	publisher = {{arXiv}},
	author = {Engels, Joshua and Baek, David D. and Kantamneni, Subhash and Tegmark, Max},
	urldate = {2025-09-13},
	date = {2025-05-09},
	eprinttype = {arxiv},
	eprint = {2504.18530 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
}

@article{biddison_scarce_2018,
	title = {Scarce Resource Allocation During Disasters: A Mixed-Method Community Engagement Study},
	volume = {153},
	issn = {0012-3692},
	url = {https://www.sciencedirect.com/science/article/pii/S0012369217313934},
	doi = {10.1016/j.chest.2017.08.001},
	shorttitle = {Scarce Resource Allocation During Disasters},
	abstract = {Background
During a catastrophe, health-care providers may face difficult questions regarding who will receive limited life-saving resources. The ethical principles that should guide decision-making have been considered by expert panels but have not been well explored with the public or front-line clinicians. The objective of this study was to characterize the public’s values regarding how scarce mechanical ventilators should be allocated during an influenza pandemic, with the ultimate goal of informing a statewide scare resource allocation framework.
Methods
Adopting deliberative democracy practices, we conducted 15 half-day community engagement forums with the general public and health-related professionals. Small group discussions of six potential guiding ethical principles were led by trained facilitators. The forums consisted exclusively of either members of the general public or health-related or disaster response professionals and were convened in a variety of meeting places across the state of Maryland. Primary data sources were predeliberation and postdeliberation surveys and the notes from small group deliberations compiled by trained note takers.
Results
Three hundred twenty-four individuals participated in 15 forums. Participants indicated a preference for prioritizing short-term and long-term survival, but they indicated that these should not be the only factors driving decision-making during a crisis. Qualitative analysis identified 10 major themes that emerged. Many, but not all, themes were consistent with previously issued recommendations. The most important difference related to withholding vs withdrawing ventilator support.
Conclusions
The values expressed by the public and front-line clinicians sometimes diverge from expert guidance in important ways. Awareness of these differences should inform policy making.},
	pages = {187--195},
	number = {1},
	journaltitle = {Chest},
	shortjournal = {Chest},
	author = {Biddison, E. Lee Daugherty and Gwon, Howard S. and Schoch-Spana, Monica and Regenberg, Alan C. and Juliano, Chrissie and Faden, Ruth R. and Toner, Eric S.},
	urldate = {2025-06-12},
	date = {2018-01-01},
	keywords = {allocation, disaster, ethics, ventilator},
}

@article{coates_scenario_2016,
	title = {Scenario planning},
	volume = {113},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162516305170},
	doi = {10.1016/j.techfore.2016.10.043},
	series = {Joseph F. Coates - Memorial Issue},
	abstract = {Today the question of what scenarios are is unclear except with regard to one point—they have become extremely popular. Many people see scenarios as forecasts of some future condition while others disavow that their scenarios are forecasts. Yet looking at scenarios that do not come labeled as forecasts or non-forecasts, it is difficult to tell them apart. The purpose of the scenario is at a meta level, since the scenario usually does not speak for itself in terms of its purpose.},
	pages = {99--102},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Coates, Joseph F.},
	urldate = {2025-06-12},
	date = {2016-12-01},
}

@article{wright_scenario_2020,
	title = {Scenario planning and foresight: Advancing theory and improving practice},
	volume = {159},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162520310465},
	doi = {10.1016/j.techfore.2020.120220},
	shorttitle = {Scenario planning and foresight},
	abstract = {In this Introduction, we review the logic that underpinned the earlier call for papers and provide a structured sequence for the contents of the sixteen papers that comprise the special issue. Use of particular foresight tools can have predictable effects on strategy making – providing positive changes in mental models and challenging business-as-usual approaches but, more negatively, can also serve to narrow and shape managers’ anticipations of the future. Any scenario activity necessarily involves simplification and evaluation processes in knowledge elicitation that need to be carefully monitored for effectiveness. In addition, historical analysis of the focal industry's use of “recipes” can give the scenario practitioner insights into the nature of unfolding futures. Inside the scenario development process, verbal and visual analysis of face-to-face interactions within the scenario team can give insights into process issues and difficulties, and an organisation's prior involvement with scenario activity may give insights into the likely time-demands of any planned activities. Additionally, stakeholders from different organisations can be facilitated to work effectively together in foresight activities. Such facilitated activities can be used to both develop policy and achieve commonly-held objectives. Two papers provide new guidance on the form of successful Delphi applications. Finally, typologies of both foresight methods/approaches and of intervention practices will allow the reflective practitioner to more fully appreciate the characteristics – both positive and negative – of a particular method and/or intervention type.},
	pages = {120220},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Wright, George and O'Brien, Frances and Meadows, Maureen and Tapinos, Efstathios and Pyper, Neil},
	urldate = {2025-06-12},
	date = {2020-10-01},
}

@article{mackay_scenario_2017,
	title = {Scenario planning with a sociological eye: Augmenting the intuitive logics approach to understanding the Future of Scotland and the {UK}},
	volume = {124},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162516302451},
	doi = {10.1016/j.techfore.2016.08.026},
	shorttitle = {Scenario planning with a sociological eye},
	abstract = {This paper draws on a social theory-informed understanding of causality to illustrate how notions of agent–structure interactions can enhance the intuitive logics ({IL}) approach to scenario planning. It incorporates concepts such as the ‘subjective’ predispositions of agency, ‘objective’ structures of social systems, activity dependence, unintended consequences of action and event-time temporality in the {IL} method to augment causal analysis in the scenario development process. The paper illustrates the social theory-informed {IL} framework through its application to a scenario exercise undertaken in the lead-up to the Scottish referendum on independence from the United Kingdom on September 18th, 2014. The central thesis of the paper is that agent–structure interactions underpin the unfolding of futures in social systems by both constraining and enabling the range of possible futures that can emerge},
	pages = {88--100},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {{MacKay}, R. Bradley and Stoyanova, Veselina},
	urldate = {2025-06-12},
	date = {2017-11-01},
	keywords = {Actors, Causality, Intuitive logics, Public policy, Scenario planning, Structures, Temporality},
}

@article{ram_scenario_2020,
	title = {Scenario presentation and scenario generation in multi-criteria assessments: An exploratory study},
	volume = {151},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162519305815},
	doi = {10.1016/j.techfore.2019.119850},
	shorttitle = {Scenario presentation and scenario generation in multi-criteria assessments},
	abstract = {The lack of systematic option evaluation procedures involving scenarios, as well as the lack of a structured approach to consider deep uncertainty within the multi-criteria framework has offered scope for synergy in combining scenarios and multi-criteria decision analysis for assessing robustness. This paper uses a multi-method research design to provide insights on the role of scenario presentation in the evaluation process, and the extent to which choice is affected by decision rules for robustness when different scenario generation techniques are used in multi-criteria assessments. It concludes that the threshold level for risk proneness of utility functions and the degree of exposure/vulnerability are key factors to consider in choosing robustness measures and scenarios. Moreover, the use of a few scenarios, expressed simply as snapshots, may improve the efficiency with which preferences are elicited in the evaluation process.},
	pages = {119850},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Ram, Camelia},
	urldate = {2025-06-12},
	date = {2020-02-01},
	keywords = {Multi-criteria assessment, Option evaluation, Robustness, Scenarios, Strategic planning},
}

@article{kharrazi_scenario_2017,
	title = {Scenario projects in Japanese government: Strategic approaches for overcoming psychological and institutional barriers},
	volume = {86},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328716300787},
	doi = {10.1016/j.futures.2016.08.003},
	shorttitle = {Scenario projects in Japanese government},
	abstract = {Scenario planning in the public sector has significant differences from scenario planning in the corporate world. Scenario planning in the government not only tends to be focused on issues of higher complexity and significance to public policy, but also in comparison to people in the private business, public officials have fundamental psychological and institutional constraints in their scenario thinking. These constraints make it difficult for them to contemplate multiple ‘untidy’ futures and imagine the possibility of policy failure: skills which are essential for successful scenario projects. Based on specific characteristics of scenario planning in the Japanese government, this paper contributes on better understanding the challenges and strategic solutions in providing more successful scenario planning in the public sector. Specifically, this paper argues that possible solutions in overcoming these constraints may be to shake public bureaucrats out of their thinking by providing free and open venues of conversation and more importantly through ‘derailment’ exercises.},
	pages = {18--26},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Kharrazi, Ali and Kakuwa, Masahiro},
	urldate = {2025-06-25},
	date = {2017-02-01},
	keywords = {Derailment, Institutional barriers, Psychological barriers, Public sector, Scenario planning},
}

@article{lehr_scenario-based_2017,
	title = {Scenario-based strategizing: Advancing the applicability in strategists' teams},
	volume = {124},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S004016251730848X},
	doi = {10.1016/j.techfore.2017.06.026},
	shorttitle = {Scenario-based strategizing},
	abstract = {For over 40years, scenarios have been promoted as a key technique for forming strategies in uncertain environments. However, many challenges remain. In this article, we discuss a novel approach designed to increase the applicability of scenario-based strategizing in top management teams. Drawing on behavioural strategy as a theoretical lens, we design a yardstick to study the impact of scenario-based strategizing. We then describe our approach, which includes developing scenarios and alternative strategies separately and supporting the strategy selection through an integrated assessment of the goal-based efficacy and robustness. To facilitate the collaborative strategizing in teams, we propose a matrix with robustness and efficacy as the two axes, which we call the Parmenides Matrix. We assess the impact of the novel approach by applying it in two cases, at a governmental agency (German Environmental Ministry) and a firm affected by disruptive change (Bosch, leading global supplier of technology and solutions).},
	pages = {214--224},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Lehr, Thomas and Lorenz, Ullrich and Willert, Markus and Rohrbeck, René},
	urldate = {2025-06-12},
	date = {2017-11-01},
	keywords = {Behavioural strategy, Scenario-based strategizing, Scenarios, Strategic foresight, Uncertainty},
}

@article{wack_scenarios_1985,
	title = {Scenarios: Shooting the Rapids},
	issn = {0017-8012},
	url = {https://hbr.org/1985/11/scenarios-shooting-the-rapids},
	shorttitle = {Scenarios},
	journaltitle = {Harvard Business Review},
	author = {Wack, Pierre},
	urldate = {2025-06-12},
	date = {1985-11},
	langid = {english},
}

@article{wack_scenarios_1985-1,
	title = {Scenarios: Uncharted Waters Ahead},
	issn = {0017-8012},
	url = {https://hbr.org/1985/09/scenarios-uncharted-waters-ahead},
	shorttitle = {Scenarios},
	journaltitle = {Harvard Business Review},
	author = {Wack, Pierre},
	urldate = {2025-06-12},
	date = {1985-09},
	langid = {english},
}

@article{canada_national_defense_force_scoping_2010,
	title = {Scoping report: {AI}-driven wargame replicator},
	url = {https://cradpdf.drdc-rddc.gc.ca/PDFS/unc504/p534228_A1b.pdf},
	abstract = {The focus of this project was to assess potential improvements to the current wargame replication system used by the Land Force Operational Research Team ({LFORT}) in {DRDC} {CORA} through the integration of human interactors’ intentions. The project, based on the analysis of problems in current wargame replication systems, reviews competing Artificial Intelligence ({AI}) and Human Behaviour Representation ({HBR}) approaches, tools and systems applicable to the wargame replication domain. For each identified approach, the main concepts, advantages, limitations and application areas are briefly described.},
	issue = {{DRDC} {CORA} {CR} 2010-269},
	author = {Canada National Defense Force and Unrau, David and Armstrong, Joe and Guo, Ruibiao Jaff and Dobias, Peter},
	urldate = {2025-06-25},
	date = {2010-12},
	langid = {english},
}

@article{arksey_scoping_2005,
	title = {Scoping studies: towards a methodological framework},
	volume = {8},
	issn = {1364-5579, 1464-5300},
	url = {http://www.tandfonline.com/doi/abs/10.1080/1364557032000119616},
	doi = {10.1080/1364557032000119616},
	shorttitle = {Scoping studies},
	pages = {19--32},
	number = {1},
	journaltitle = {International Journal of Social Research Methodology},
	shortjournal = {International Journal of Social Research Methodology},
	author = {Arksey, Hilary and O'Malley, Lisa},
	urldate = {2025-09-13},
	date = {2005-02},
	langid = {english},
}

@misc{nalbandyan_score_2025,
	title = {{SCORE}: Systematic {COnsistency} and Robustness Evaluation for Large Language Models},
	url = {http://arxiv.org/abs/2503.00137},
	doi = {10.48550/arXiv.2503.00137},
	shorttitle = {{SCORE}},
	abstract = {Typical evaluations of Large Language Models ({LLMs}) report a single metric per dataset, often representing the model's best-case performance under carefully selected settings. Unfortunately, this approach overlooks model robustness and reliability in real-world applications. For instance, simple paraphrasing of prompts on the {MMLU}-Pro dataset causes accuracy fluctuations of up to 10{\textbackslash}\%, while reordering answer choices in the {AGIEval} dataset results in accuracy differences of up to 6.1{\textbackslash}\%. While some studies discuss issues with {LLM} robustness, there is no unified or centralized framework for evaluating the robustness of language models. To address this gap and consolidate existing research on model robustness, we present {SCORE} (\${\textbackslash}mathbf\{S\}\$ystematic \${\textbackslash}mathbf\{{CO}\}\$nsistency and \${\textbackslash}mathbf\{R\}\$obustness \${\textbackslash}mathbf\{E\}\$valuation), a comprehensive framework for non-adversarial evaluation of {LLMs}. The {SCORE} framework evaluates models by repeatedly testing them on the same benchmarks in various setups to give a realistic estimate of their accuracy and consistency. We release the code publicly and start an {LLM} robustness leaderboard to facilitate further development and research.},
	number = {{arXiv}:2503.00137},
	publisher = {{arXiv}},
	author = {Nalbandyan, Grigor and Shahbazyan, Rima and Bakhturina, Evelina},
	urldate = {2025-09-10},
	date = {2025-02-28},
	eprinttype = {arxiv},
	eprint = {2503.00137 [cs]},
	note = {version: 1},
	keywords = {Computer Science - Computation and Language},
}

@article{sun_self_2023,
	title = {Self Generated Wargame {AI}: Double Layer Agent Task Planning Based on Large Language Model},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2312.01090},
	doi = {10.48550/ARXIV.2312.01090},
	shorttitle = {Self Generated Wargame {AI}},
	abstract = {The large language models represented by {ChatGPT} have a disruptive impact on the field of artificial intelligence. But it mainly focuses on natural language processing, speech recognition, machine learning and natural language understanding. This paper innovatively applies the large language model to the field of intelligent decision-making, places the large language model in the decision-making center, and constructs an agent architecture with the large language model as the core. Based on this, it further proposes a two-layer agent task planning, issues and executes decision commands through the interaction of natural language, and carries out simulation verification through the wargame simulation environment. Through the game confrontation simulation experiment, it is found that the intelligent decision-making ability of the large language model is significantly stronger than the commonly used reinforcement learning {AI} and rule {AI}, and the intelligence, understandability and generalization are all better. And through experiments, it was found that the intelligence of the large language model is closely related to prompt. This work also extends the large language model from previous human-computer interaction to the field of intelligent decision-making, which has important reference value and significance for the development of intelligent decision-making.},
	author = {Sun, Y. and Zhao, J. and Yu, C. and Wang, W. and Zhou, X.},
	urldate = {2025-09-13},
	date = {2023},
	note = {Publisher: {arXiv}
Version Number: 2},
	keywords = {Artificial Intelligence (cs.{AI}), Computation and Language (cs.{CL}), {FOS}: Computer and information sciences},
}

@book{minsky_semantic_1968,
	title = {Semantic Information Processing},
	url = {https://www.semanticscholar.org/paper/Semantic-Information-Processing-Minsky/382c8aee17ed963bae6c3b5f4f2047773093b261},
	publisher = {{MIT} Press},
	author = {Minsky, Marvin},
	date = {1968},
	doi = {10.7551/mitpress/6119.001.0001},
}

@article{sendstad_sequential_2020,
	title = {Sequential investment in renewable energy technologies under policy uncertainty},
	volume = {137},
	issn = {0301-4215},
	url = {https://www.sciencedirect.com/science/article/pii/S0301421519307384},
	doi = {10.1016/j.enpol.2019.111152},
	abstract = {Although innovation and support schemes are among the main forces that drive investment in renewable energy ({RE}) technologies, both involve considerable uncertainty. We develop a real options framework to analyse the impact of technological, policy and electricity price uncertainty on the decision to invest sequentially in successively improved versions of a {RE} technology. Technological uncertainty is reflected in the random arrival of innovations, and policy uncertainty in the likely provision or retraction of a subsidy that takes the form of a fixed premium on top of the electricity price. We show that greater likelihood of subsidy retraction (provision) lowers (raises) the incentive to invest, and, by comparing a stepwise to a lumpy investment strategy, we show how an embedded option to adopt an improved technology version mitigates the impact of subsidy retraction on investment timing. Specifically, we show how stepwise investment facilitates earlier technology adoption compared to lumpy investment, and that, under stepwise investment, technological uncertainty accelerates technology adoption, thus further offsetting the incentive to delay investment in the light of subsidy retraction.},
	pages = {111152},
	journaltitle = {Energy Policy},
	shortjournal = {Energy Policy},
	author = {Sendstad, Lars Hegnes and Chronopoulos, Michail},
	urldate = {2025-06-12},
	date = {2020-02-01},
	keywords = {Investment analysis, Policy uncertainty, Real options, Renewable energy},
}

@article{smith_serious_2020,
	title = {Serious games for serious crises: reflections from an infectious disease outbreak matrix game},
	volume = {16},
	issn = {1744-8603},
	url = {https://doi.org/10.1186/s12992-020-00547-6},
	doi = {10.1186/s12992-020-00547-6},
	shorttitle = {Serious games for serious crises},
	abstract = {While there is widespread recognition of global health failures when it comes to infectious disease outbreaks, there is little discussion on how policy-makers and global health organizations can learn to better prepare and respond. Serious games provide an underutilized tool to promote learning and innovation around global health crises. In order to explore the potential of Serious Games as a policy learning tool, Global Affairs Canada, in collaboration with the Department of National Defense and academic partners, developed and implemented a matrix game aimed at prompting critical reflection and gender-based analysis on infectious disease outbreak preparedness and response. This commentary, written by the core development team, reflects on the process and outcomes of the gaming exercise, which we believe will be of interest to others hoping to promote innovative thinking and learning around global health policy and crisis response, as well as the application of serious games more broadly.},
	pages = {18},
	number = {1},
	journaltitle = {Globalization and Health},
	shortjournal = {Globalization and Health},
	author = {Smith, Julia and Sears, Nathan and Taylor, Ben and Johnson, Madeline},
	urldate = {2025-09-12},
	date = {2020-03-10},
	keywords = {Games, Gender, Health security, Outbreaks, Training},
}

@misc{wu_shall_2024,
	title = {Shall We Team Up: Exploring Spontaneous Cooperation of Competing {LLM} Agents},
	url = {http://arxiv.org/abs/2402.12327},
	doi = {10.48550/arXiv.2402.12327},
	shorttitle = {Shall We Team Up},
	abstract = {Large Language Models ({LLMs}) have increasingly been utilized in social simulations, where they are often guided by carefully crafted instructions to stably exhibit human-like behaviors during simulations. Nevertheless, we doubt the necessity of shaping agents' behaviors for accurate social simulations. Instead, this paper emphasizes the importance of spontaneous phenomena, wherein agents deeply engage in contexts and make adaptive decisions without explicit directions. We explored spontaneous cooperation across three competitive scenarios and successfully simulated the gradual emergence of cooperation, findings that align closely with human behavioral data. This approach not only aids the computational social science community in bridging the gap between simulations and real-world dynamics but also offers the {AI} community a novel method to assess {LLMs}' capability of deliberate reasoning.},
	number = {{arXiv}:2402.12327},
	publisher = {{arXiv}},
	author = {Wu, Zengqing and Peng, Run and Zheng, Shuyuan and Liu, Qianying and Han, Xu and Kwon, Brian Inhyuk and Onizuka, Makoto and Tang, Shaojie and Xiao, Chuan},
	urldate = {2025-09-13},
	date = {2024-10-27},
	eprinttype = {arxiv},
	eprint = {2402.12327 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Multiagent Systems, Economics - General Economics, Quantitative Finance - Economics},
}

@article{otoole_shining_2002,
	title = {Shining Light on “Dark Winter”},
	volume = {34},
	issn = {1058-4838},
	url = {https://dx.doi.org/10.1086/339909},
	doi = {10.1086/339909},
	abstract = {Abstract. On 22–23 June 2001, the Johns Hopkins Center for Civilian Biodefense Strategies, in collaboration with the Center for Strategic and International},
	pages = {972--983},
	number = {7},
	journaltitle = {Clinical Infectious Diseases},
	shortjournal = {Clin Infect Dis},
	author = {O'Toole, Tara and Michael, Mair and Inglesby, Thomas V.},
	urldate = {2025-06-26},
	date = {2002-04-01},
	langid = {english},
	note = {Publisher: Oxford Academic},
}

@misc{wongkamjan_should_2025,
	title = {Should I Trust You? Detecting Deception in Negotiations using Counterfactual {RL}},
	url = {http://arxiv.org/abs/2502.12436},
	doi = {10.48550/arXiv.2502.12436},
	shorttitle = {Should I Trust You?},
	abstract = {An increasingly common socio-technical problem is people being taken in by offers that sound ``too good to be true'', where persuasion and trust shape decision-making. This paper investigates how {\textbackslash}abr\{ai\} can help detect these deceptive scenarios. We analyze how humans strategically deceive each other in {\textbackslash}textit\{Diplomacy\}, a board game that requires both natural language communication and strategic reasoning. This requires extracting logical forms of proposed agreements in player communications and computing the relative rewards of the proposal using agents' value functions. Combined with text-based features, this can improve our deception detection. Our method detects human deception with a high precision when compared to a Large Language Model approach that flags many true messages as deceptive. Future human-{\textbackslash}abr\{ai\} interaction tools can build on our methods for deception detection by triggering {\textbackslash}textit\{friction\} to give users a chance of interrogating suspicious proposals.},
	number = {{arXiv}:2502.12436},
	publisher = {{arXiv}},
	author = {Wongkamjan, Wichayaporn and Wang, Yanze and Gu, Feng and Peskoff, Denis and Kummerfeld, Jonathan K. and May, Jonathan and Boyd-Graber, Jordan Lee},
	urldate = {2025-09-11},
	date = {2025-06-05},
	eprinttype = {arxiv},
	eprint = {2502.12436 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{turnitsa_simulation_2021,
	title = {Simulation and Artificial Intelligence Methods for Wargames: Case Study – “European Thread”},
	rights = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/9781119604815.ch6},
	doi = {10.1002/9781119604815.ch6},
	shorttitle = {Simulation and Artificial Intelligence Methods for Wargames},
	abstract = {Semantic Scholar extracted view of "Simulation and Artificial Intelligence Methods for Wargames" by A. Najgebauer et al.},
	pages = {157--182},
	author = {Najgebauer, Andrzej and Wojciechowski, Sławomir and Antkiewicz, Ryszard and Pierzchała, Dariusz},
	editor = {Turnitsa, Charles and Blais, Curtis and Tolk, Andreas},
	urldate = {2025-09-13},
	date = {2021-12-22},
	langid = {english},
	doi = {10.1002/9781119604815.ch6},
	note = {Book Title: Simulation and Wargaming
Edition: 1
{ISBN}: 9781119604785 9781119604815
Publisher: Wiley},
}

@report{hodges_six_1991,
	title = {Six (or So) Things You Can Do with a Bad Model},
	url = {https://www.rand.org/pubs/notes/N3381.html},
	abstract = {Models that cannot be validated in any fully adequate sense are often used and can be used fruitfully, even though we have no theory for how to use them or how to interpret and place value on the results they produce.},
	author = {Hodges, James S.},
	urldate = {2025-06-26},
	date = {1991-01-01},
	langid = {english},
}

@article{minkkinen_six_2019,
	title = {Six foresight frames: Classifying policy foresight processes in foresight systems according to perceived unpredictability and pursued change},
	volume = {149},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162519305554},
	doi = {10.1016/j.techfore.2019.119753},
	shorttitle = {Six foresight frames},
	abstract = {Foresight is conducted in diverse ways drawing on particular sets of assumptions, and it increasingly takes place in networked foresight systems. We develop a typology of six foresight frames based on two dimensions: 1) level of perceived unpredictability and 2) level of pursued change. By frames, we mean the interpretive structures that underlie foresight actors’ work. The six foresight frames are the predictive, planning, scenaric, visionary, critical and transformative frames. The frames may be used to position phases of foresight, individual processes or, most usefully, interlinked foresight processes in a system. We develop the model based on futures literature and elaborate it in a study of comprehensive security foresight in Finland conducted during the Strategic Research Council project “From Failand to Winland”. Moreover, we test our typology with four additional foresight system cases: Singapore, United Kingdom, Wallonia and Russia. The six frames capture different sets of assumptions and different types of foresight which can be distributed to different actors in a foresight system. Thus we suggest that diversity of foresight frames is likely to be an element of successful foresight systems. However, this requires understanding the diversity of foresight frames and the competence to bridge different approaches.},
	pages = {119753},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Minkkinen, Matti and Auffermann, Burkhard and Ahokas, Ira},
	urldate = {2025-06-12},
	date = {2019-12-01},
	keywords = {Anticipation, Foresight, Foresight system, Framing, Public policy, Security},
}



@incollection{benson_social_2020,
	title = {Social big data and its integrity},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-819204-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128192047000087},
	pages = {145--158},
	booktitle = {Cyber Influence and Cognitive Threats},
	publisher = {Elsevier},
	author = {Benson, Vladlena and Buchanan, Tom},
	urldate = {2025-08-06},
	date = {2020},
	langid = {english},
	doi = {10.1016/B978-0-12-819204-7.00008-7},
}

@misc{cunningham_sparse_2023,
	title = {Sparse Autoencoders Find Highly Interpretable Features in Language Models},
	url = {http://arxiv.org/abs/2309.08600},
	doi = {10.48550/arXiv.2309.08600},
	abstract = {One of the roadblocks to a better understanding of neural networks' internals is {\textbackslash}textit\{polysemanticity\}, where neurons appear to activate in multiple, semantically distinct contexts. Polysemanticity prevents us from identifying concise, human-understandable explanations for what neural networks are doing internally. One hypothesised cause of polysemanticity is {\textbackslash}textit\{superposition\}, where neural networks represent more features than they have neurons by assigning features to an overcomplete set of directions in activation space, rather than to individual neurons. Here, we attempt to identify those directions, using sparse autoencoders to reconstruct the internal activations of a language model. These autoencoders learn sets of sparsely activating features that are more interpretable and monosemantic than directions identified by alternative approaches, where interpretability is measured by automated methods. Moreover, we show that with our learned set of features, we can pinpoint the features that are causally responsible for counterfactual behaviour on the indirect object identification task {\textbackslash}citep\{wang2022interpretability\} to a finer degree than previous decompositions. This work indicates that it is possible to resolve superposition in language models using a scalable, unsupervised method. Our method may serve as a foundation for future mechanistic interpretability work, which we hope will enable greater model transparency and steerability.},
	number = {{arXiv}:2309.08600},
	publisher = {{arXiv}},
	author = {Cunningham, Hoagy and Ewart, Aidan and Riggs, Logan and Huben, Robert and Sharkey, Lee},
	urldate = {2025-09-13},
	date = {2023-10-04},
	eprinttype = {arxiv},
	eprint = {2309.08600 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{galanis_speculation_2018,
	title = {Speculation under unawareness},
	volume = {109},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825618300290},
	doi = {10.1016/j.geb.2018.03.001},
	abstract = {“No trade” theorems establish that, in various trading environments, investors who share a common prior will not engage in speculation, as long as expected utility, Bayesian updating and full awareness are imposed. We relax the last assumption by allowing for asymmetric unawareness and examine under which conditions speculative behaviour emerges. We find that if common knowledge is assumed (as in the settings of Aumann, 1976 and Milgrom and Stokey, 1982), unawareness cannot generate speculation. This is not true, however, in settings where no common knowledge is assumed, such as speculation in equilibrium (Geanakoplos, 1989) and betting that is always beneficial (Morris, 1994), unless stronger conditions on awareness are imposed.},
	pages = {598--615},
	journaltitle = {Games and Economic Behavior},
	shortjournal = {Games and Economic Behavior},
	author = {Galanis, Spyros},
	urldate = {2025-06-12},
	date = {2018-05-01},
	keywords = {Awareness, Bounded perception, Common knowledge, Knowledge, Speculation, Trade, Unawareness},
}

@unpublished{yao_spin-bench_2025,
	title = {{SPIN}-Bench: How well do {LLMs} plan strategically and reason socially?},
	url = {http://arxiv.org/abs/2503.12349},
	abstract = {Reasoning and strategic behavior in social interactions is a hallmark of
intelligence. This form of reasoning is significantly more sophisticated
than isolated planning or reasoning tasks in static settings (e.g., math
problem solving). In this paper, we present Strategic Planning,
Interaction, and Negotiation ({SPIN}-Bench), a new multi-domain evaluation
designed to measure the intelligence of strategic planning and social
reasoning. While many existing benchmarks focus on narrow planning or
single-agent reasoning, {SPIN}-Bench combines classical {PDDL} tasks,
competitive board games, cooperative card games, and multi-agent
negotiation scenarios in one unified framework. The framework includes
both a benchmark as well as an arena to simulate and evaluate the variety
of social settings to test reasoning and strategic behavior of {AI} agents.
We formulate the benchmark {SPIN}-Bench by systematically varying action
spaces, state complexity, and the number of interacting agents to simulate
a variety of social settings where success depends on not only methodical
and step-wise decision making, but also conceptual inference of other
(adversarial or cooperative) participants. Our experiments reveal that
while contemporary {LLMs} handle basic fact retrieval and short-range
planning reasonably well, they encounter significant performance
bottlenecks in tasks requiring deep multi-hop reasoning over large state
spaces and socially adept coordination under uncertainty. We envision
{SPIN}-Bench as a catalyst for future research on robust multi-agent
planning, social reasoning, and human--{AI} teaming. Project Website:
https://spinbench.github.io/},
	author = {Yao, Jianzhu and Wang, Kevin and Hsieh, Ryan and Zhou, Haisu and Zou, Tianqing and Cheng, Zerui and Wang, Zhangyang and Viswanath, Pramod},
	urldate = {2025-04-23},
	date = {2025-03-16},
	note = {{ISBN}: 2503.12349
Publication Title: {arXiv} [cs.{AI}]},
}

@article{janssen_spiteful_2016,
	title = {Spiteful bidding and gaming in combinatorial clock auctions},
	volume = {100},
	issn = {0899-8256},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825616300914},
	doi = {10.1016/j.geb.2016.08.011},
	abstract = {Combinatorial Clock Auctions ({CCAs}) have recently been used around the world to allocate mobile telecom spectrum. {CCAs} are claimed to significantly reduce the scope for strategic bidding. This paper shows, however, that bidding truthfully does not constitute an equilibrium if bidders also have an incentive to engage in spiteful bidding to raise rivals' cost. The restrictions on further bids imposed by the clock phase of a {CCA} give certainty to bidders that certain bids above value cannot be winning bids, assisting bidders to engage in spiteful bidding.},
	pages = {186--207},
	journaltitle = {Games and Economic Behavior},
	shortjournal = {Games and Economic Behavior},
	author = {Janssen, Maarten and Karamychev, Vladimir},
	urldate = {2025-06-12},
	date = {2016-11-01},
	keywords = {Combinatorial auctions, Raising rivals' cost, Spiteful biding, Telecom markets},
}

@misc{jorgensen_static_2025,
	title = {Static Vs. Agentic Game Master {AI} for Facilitating Solo Role-Playing Experiences},
	url = {http://arxiv.org/abs/2502.19519},
	doi = {10.48550/arXiv.2502.19519},
	abstract = {This paper presents a game master {AI} for single-player role-playing games. The {AI} is designed to deliver interactive text-based narratives and experiences typically associated with multiplayer tabletop games like Dungeons \& Dragons. We report on the design process and the series of experiments to improve the functionality and experience design, resulting in two functional versions of the system. While v1 of our system uses simplified prompt engineering, v2 leverages a multi-agent architecture and the {ReAct} framework to include reasoning and action. A comparative evaluation demonstrates that v2 as an agentic system maintains play while significantly improving modularity and game experience, including immersion and curiosity. Our findings contribute to the evolution of {AI}-driven interactive fiction, highlighting new avenues for enhancing solo role-playing experiences.},
	number = {{arXiv}:2502.19519},
	publisher = {{arXiv}},
	author = {Jørgensen, Nicolai Hejlesen and Tharmabalan, Sarmilan and Aslan, Ilhan and Hansen, Nicolai Brodersen and Merritt, Timothy},
	urldate = {2025-09-15},
	date = {2025-03-06},
	eprinttype = {arxiv},
	eprint = {2502.19519 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
}

@misc{turner_steering_2024,
	title = {Steering Language Models With Activation Engineering},
	url = {http://arxiv.org/abs/2308.10248},
	doi = {10.48550/arXiv.2308.10248},
	abstract = {Prompt engineering and finetuning aim to maximize language model performance on a given metric (like toxicity reduction). However, these methods do not fully elicit a model's capabilities. To reduce this gap, we introduce activation engineering: the inference-time modification of activations in order to control (or steer) model outputs. Specifically, we introduce the Activation Addition ({ActAdd}) technique, which contrasts the intermediate activations on prompt pairs (such as "Love" versus "Hate") to compute a steering vector (Subramani et al. 2022). By tactically adding in e.g. the "Love" - "Hate" steering vector during the forward pass, we achieve {SOTA} on negative-to-positive sentiment shift and detoxification using models including {LLaMA}-3 and {OPT}. {ActAdd} yields inference-time control over high-level output properties (like topic and sentiment) while preserving performance on off-target tasks. {ActAdd} is lightweight: it does not require any machine optimization and works with a single pair of data points, which enables rapid iteration over steering. {ActAdd} demonstrates the power of activation engineering.},
	number = {{arXiv}:2308.10248},
	publisher = {{arXiv}},
	author = {Turner, Alexander Matt and Thiergart, Lisa and Leech, Gavin and Udell, David and Vazquez, Juan J. and Mini, Ulisse and {MacDiarmid}, Monte},
	urldate = {2025-09-13},
	date = {2024-10-10},
	eprinttype = {arxiv},
	eprint = {2308.10248 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{lore_strategic_2024,
	title = {Strategic behavior of large language models and the role of game structure versus contextual framing},
	volume = {14},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-69032-z},
	doi = {10.1038/s41598-024-69032-z},
	abstract = {Abstract
            This paper investigates the strategic behavior of large language models ({LLMs}) across various game-theoretic settings, scrutinizing the interplay between game structure and contextual framing in decision-making. We focus our analysis on three advanced {LLMs}—{GPT}-3.5, {GPT}-4, and {LLaMa}-2—and how they navigate both the intrinsic aspects of different games and the nuances of their surrounding contexts. Our results highlight discernible patterns in each model’s strategic approach. {GPT}-3.5 shows significant sensitivity to context but lags in its capacity for abstract strategic decision making. Conversely, both {GPT}-4 and {LLaMa}-2 demonstrate a more balanced sensitivity to game structures and contexts, albeit with crucial differences. Specifically, {GPT}-4 prioritizes the internal mechanics of the game over its contextual backdrop but does so with only a coarse differentiation among game types. In contrast, {LLaMa}-2 reflects a more granular understanding of individual game structures, while also giving due weight to contextual elements. This suggests that {LLaMa}-2 is better equipped to navigate the subtleties of different strategic scenarios while also incorporating context into its decision-making, whereas {GPT}-4 adopts a more generalized, structure-centric strategy.},
	pages = {18490},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Lorè, Nunzio and Heydari, Babak},
	urldate = {2025-09-08},
	date = {2024-08-09},
	langid = {english},
}

@book{kent_strategic_2015,
	title = {Strategic Intelligence for American World Policy},
	isbn = {978-1-4008-7915-1},
	url = {https://play.google.com/store/books/details?id=6UrWCgAAQBAJ},
	abstract = {Intelligence work is in some ways like a newspaper or newsmagazine, in
some like a business, in some like the research activity of a university;
very little of it involves cloaks and daggers. All of it is important to
national survival, and should be understood by the citizens of a
democracy.In this remarkable book, an able scholar, experienced in foreign
intelligence, analyzes all of these varied aspects of what is known as
"high-level foreign positive intelligence." Illustrations are drawn from
that branch, but the lessons apply to all intelligence, and in fact to all
those phases of business, of journalism, and (most importantly) of
scholarship, where the problem is to learn what has happened or will
happen.Originally published in 1966.The Princeton Legacy Library uses the
latest print-on-demand technology to again make available previously
out-of-print books from the distinguished backlist of Princeton University
Press. These editions preserve the original texts of these important books
while presenting them in durable paperback and hardcover editions. The
goal of the Princeton Legacy Library is to vastly increase access to the
rich scholarly heritage found in the thousands of books published by
Princeton University Press since its founding in 1905.},
	pagetotal = {256},
	publisher = {Princeton University Press},
	author = {Kent, Sherman},
	date = {2015-12-08},
	keywords = {{noPdf}},
}

@unpublished{gandhi_strategic_2023,
	title = {Strategic reasoning with Language Models},
	url = {http://arxiv.org/abs/2305.19165},
	abstract = {Strategic reasoning enables agents to cooperate, communicate, and compete
with other agents in diverse situations. Existing approaches to solving
strategic games rely on extensive training, yielding strategies that do
not generalize to new scenarios or games without retraining. Large
Language Models ({LLMs}), with their ability to comprehend and generate
complex, context-rich language, could prove powerful as tools for
strategic gameplay. This paper introduces an approach that uses pretrained
{LLMs} with few-shot chain-of-thought examples to enable strategic reasoning
for {AI} agents. Our approach uses systematically generated demonstrations
of reasoning about states, values, and beliefs to prompt the model. Using
extensive variations of simple matrix games, we show that strategies that
are derived based on systematically generated prompts generalize almost
perfectly to new game structures, alternate objectives, and hidden
information. Additionally, we demonstrate our approach can lead to
human-like negotiation strategies in realistic scenarios without any extra
training or fine-tuning. Our results highlight the ability of {LLMs}, guided
by systematic reasoning demonstrations, to adapt and excel in diverse
strategic scenarios.},
	author = {Gandhi, Kanishk and Sadigh, Dorsa and Goodman, Noah D},
	date = {2023-05-30},
	note = {{ISBN}: 2305.19165
Publication Title: {arXiv} [cs.{AI}]},
}

@book{us_army_war_college_strategic_2015,
	edition = {1st},
	title = {Strategic Wargaming Handbook},
	publisher = {Center for Strategic Leadership and Development},
	author = {{US Army War College}},
	date = {2015-07-01},
}

@unpublished{light_strategist_2024,
	title = {Strategist: Learning strategic skills by {LLMs} via bi-level tree search},
	url = {http://arxiv.org/abs/2408.10635},
	abstract = {In this paper, we propose a new method Strategist that utilizes {LLMs} to
acquire new skills for playing multi-agent games through a
self-improvement process. Our method gathers quality feedback through
self-play simulations with Monte Carlo tree search and {LLM}-based
reflection, which can then be used to learn high-level strategic skills
such as how to evaluate states that guide the low-level execution.We
showcase how our method can be used in both action planning and dialogue
generation in the context of games, achieving good performance on both
tasks. Specifically, we demonstrate that our method can help train agents
with better performance than both traditional reinforcement learning-based
approaches and other {LLM}-based skill learning approaches in games
including the Game of Pure Strategy ({GOPS}) and The Resistance: Avalon.},
	author = {Light, Jonathan and Cai, Min and Chen, Weiqin and Wang, Guanzhi and Chen, Xiusi and Cheng, Wei and Yue, Yisong and Hu, Ziniu},
	urldate = {2024-09-01},
	date = {2024-08-20},
	note = {{ISBN}: 2408.10635
Publication Title: {arXiv} [cs.{AI}]},
}

@misc{xu_strategy-augmented_2025,
	title = {Strategy-Augmented Planning for Large Language Models via Opponent Exploitation},
	url = {http://arxiv.org/abs/2505.08459},
	doi = {10.48550/arXiv.2505.08459},
	abstract = {Efficiently modeling and exploiting opponents is a long-standing challenge in adversarial domains. Large Language Models ({LLMs}) trained on extensive textual data have recently demonstrated outstanding performance in general tasks, introducing new research directions for opponent modeling. Some studies primarily focus on directly using {LLMs} to generate decisions based on the elaborate prompt context that incorporates opponent descriptions, while these approaches are limited to scenarios where {LLMs} possess adequate domain expertise. To address that, we introduce a two-stage Strategy-Augmented Planning ({SAP}) framework that significantly enhances the opponent exploitation capabilities of {LLM}-based agents by utilizing a critical component, the Strategy Evaluation Network ({SEN}). Specifically, in the offline stage, we construct an explicit strategy space and subsequently collect strategy-outcome pair data for training the {SEN} network. During the online phase, {SAP} dynamically recognizes the opponent's strategies and greedily exploits them by searching best response strategy on the well-trained {SEN}, finally translating strategy to a course of actions by carefully designed prompts. Experimental results show that {SAP} exhibits robust generalization capabilities, allowing it to perform effectively not only against previously encountered opponent strategies but also against novel, unseen strategies. In the {MicroRTS} environment, {SAP} achieves a \$85.35{\textbackslash}\%\$ performance improvement over baseline methods and matches the competitiveness of reinforcement learning approaches against state-of-the-art ({SOTA}) rule-based {AI}. Our code is available at https://github.com/hsushuai/{SAP}.},
	number = {{arXiv}:2505.08459},
	publisher = {{arXiv}},
	author = {Xu, Shuai and Cui, Sijia and Wang, Yanna and Xu, Bo and Wang, Qi},
	urldate = {2025-09-13},
	date = {2025-06-01},
	eprinttype = {arxiv},
	eprint = {2505.08459 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{schmid_student_2023,
	title = {Student of Games: A unified learning algorithm for both perfect and imperfect information games},
	volume = {9},
	issn = {2375-2548},
	url = {https://www.science.org/doi/10.1126/sciadv.adg3256},
	doi = {10.1126/sciadv.adg3256},
	shorttitle = {Student of Games},
	abstract = {Games have a long history as benchmarks for progress in artificial intelligence. Approaches using search and learning produced strong performance across many perfect information games, and approaches using game-theoretic reasoning and learning demonstrated strong performance for specific imperfect information poker variants. We introduce Student of Games, a general-purpose algorithm that unifies previous approaches, combining guided search, self-play learning, and game-theoretic reasoning. Student of Games achieves strong empirical performance in large perfect and imperfect information games—an important step toward truly general algorithms for arbitrary environments. We prove that Student of Games is sound, converging to perfect play as available computation and approximation capacity increases. Student of Games reaches strong performance in chess and Go, beats the strongest openly available agent in heads-up no-limit Texas hold’em poker, and defeats the state-of-the-art agent in Scotland Yard, an imperfect information game that illustrates the value of guided search, learning, and game-theoretic reasoning.
          , 
            Student of Games combines search, learning, and game-theoretic reasoning to play chess, go, poker, and Scotland Yard.},
	pages = {eadg3256},
	number = {46},
	journaltitle = {Science Advances},
	shortjournal = {Sci. Adv.},
	author = {Schmid, Martin and Moravčík, Matej and Burch, Neil and Kadlec, Rudolf and Davidson, Josh and Waugh, Kevin and Bard, Nolan and Timbers, Finbarr and Lanctot, Marc and Holland, G. Zacharias and Davoodi, Elnaz and Christianson, Alden and Bowling, Michael},
	urldate = {2025-09-08},
	date = {2023-11-17},
	langid = {english},
}

@article{brassett_styling_2015,
	title = {Styling the future. A philosophical approach to design and scenarios},
	volume = {74},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328715000853},
	doi = {10.1016/j.futures.2015.07.001},
	abstract = {Since the end of the 1980s – the Decade of Style (Mort, 1996) – the value of style in design has fallen. Recent times (Whicher et al., 2015) see a focus on style as a sign of design’s immaturity, while a more mature design should be attending to process, strategy and policy creation. Design Thinking has been enjoying its success in the same spirit, where it is championed (Martin, 2009, Neumeier, 2009 Martin, 2009, Neumeier, 2009) as a way of taking design away from its early stage as ‘mere’ styling, towards the more thoughtful, serious matters of business. The philosopher Gilles Deleuze is of a different mind however. ‘Style,’ he writes Deleuze (1995, p.31), ‘amounts to innovation.’ For us this engages not only a rethinking of design practice in particular, but also a reconsideration of the guiding principles of scenario planning. Deleuze’s thought entails the opportunity for styling to be an act that participates in driving all creativity towards making a successful future impact (Flynn and Chatman, 2004, Cox, 2005). A philosophical disruption of current design and scenarios orthodoxies offers a way of considering that style has a key role in the production of the future. Here, then, we will investigate the creative, even innovative, opportunities that emerge from a reworking of the value of style that comes from a critique of Design Thinking, a perspective on future-thinking (especially scenario planning (e.g. Schwartz, 1991, Li, 2014, Ramírez and Selin, 2014), but also some work from organisation and management studies (e.g. Tsoukas, 2005, 2015)), and an encounter with philosophy (particularly the work of Deleuze and Guattari, 1984, Deleuze and Guattari, 1987, Deleuze and Guattari, 1994. We will highlight the affective capacities of style – in design and scenarios, both as creative constructing of futures – by way of creatively accessing uncertainty, complexity and indeterminacy in the production of strategic maps for living (both individuals and organisations).},
	pages = {37--48},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Brassett, Jamie and O’Reilly, John},
	urldate = {2025-06-12},
	date = {2015-11-01},
	keywords = {Deleuze, Design, Future, Innovation, Scenarios, Style},
}

@misc{tonini_super-additive_2025,
	title = {Super-additive Cooperation in Language Model Agents},
	url = {http://arxiv.org/abs/2508.15510},
	doi = {10.48550/arXiv.2508.15510},
	abstract = {With the prospect of autonomous artificial intelligence ({AI}) agents, studying their tendency for cooperative behavior becomes an increasingly relevant topic. This study is inspired by the super-additive cooperation theory, where the combined effects of repeated interactions and inter-group rivalry have been argued to be the cause for cooperative tendencies found in humans. We devised a virtual tournament where language model agents, grouped into teams, face each other in a Prisoner's Dilemma game. By simulating both internal team dynamics and external competition, we discovered that this blend substantially boosts both overall and initial, one-shot cooperation levels (the tendency to cooperate in one-off interactions). This research provides a novel framework for large language models to strategize and act in complex social scenarios and offers evidence for how intergroup competition can, counter-intuitively, result in more cooperative behavior. These insights are crucial for designing future multi-agent {AI} systems that can effectively work together and better align with human values. Source code is available at https://github.com/pippot/Superadditive-cooperation-{LLMs}.},
	number = {{arXiv}:2508.15510},
	publisher = {{arXiv}},
	author = {Tonini, Filippo and Galke, Lukas},
	urldate = {2025-09-11},
	date = {2025-08-21},
	eprinttype = {arxiv},
	eprint = {2508.15510 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{star_supporting_2016,
	title = {Supporting adaptation decisions through scenario planning: Enabling the effective use of multiple methods},
	volume = {13},
	issn = {2212-0963},
	url = {https://www.sciencedirect.com/science/article/pii/S2212096316300262},
	doi = {10.1016/j.crm.2016.08.001},
	shorttitle = {Supporting adaptation decisions through scenario planning},
	abstract = {Scenario planning is a technique used to inform decision-making under uncertainty, and is increasingly applied in the field of climate change adaptation and policy. This paper describes applications that combine previously distinct scenario methods in new and innovative ways. It draws on numerous recent independent case studies to illustrate emerging practices, such as far stronger connections between researcher-driven and participatory approaches and cycling between exploratory and normative perspectives. The paper concludes with a call for greater support for, and collaboration among, practitioners with the argument that mixed methods are most effective for decision-making in the context of climate change challenges.},
	pages = {88--94},
	journaltitle = {Climate Risk Management},
	shortjournal = {Climate Risk Management},
	author = {Star, Jonathan and Rowland, Erika L. and Black, Mary E. and Enquist, Carolyn A. F. and Garfin, Gregg and Hoffman, Catherine Hawkins and Hartmann, Holly and Jacobs, Katharine L. and Moss, Richard H. and Waple, Anne M.},
	urldate = {2025-06-12},
	date = {2016-01-01},
	keywords = {Climate adaptation, Scenario planning},
}

@misc{shao_swarmbrain_2024,
	title = {{SwarmBrain}: Embodied agent for real-time strategy game {StarCraft} {II} via large language models},
	url = {http://arxiv.org/abs/2401.17749},
	doi = {10.48550/arXiv.2401.17749},
	shorttitle = {{SwarmBrain}},
	abstract = {Large language models ({LLMs}) have recently garnered significant accomplishments in various exploratory tasks, even surpassing the performance of traditional reinforcement learning-based methods that have historically dominated the agent-based field. The purpose of this paper is to investigate the efficacy of {LLMs} in executing real-time strategy war tasks within the {StarCraft} {II} gaming environment. In this paper, we introduce {SwarmBrain}, an embodied agent leveraging {LLM} for real-time strategy implementation in the {StarCraft} {II} game environment. The {SwarmBrain} comprises two key components: 1) a Overmind Intelligence Matrix, powered by state-of-the-art {LLMs}, is designed to orchestrate macro-level strategies from a high-level perspective. This matrix emulates the overarching consciousness of the Zerg intelligence brain, synthesizing strategic foresight with the aim of allocating resources, directing expansion, and coordinating multi-pronged assaults. 2) a Swarm {ReflexNet}, which is agile counterpart to the calculated deliberation of the Overmind Intelligence Matrix. Due to the inherent latency in {LLM} reasoning, the Swarm {ReflexNet} employs a condition-response state machine framework, enabling expedited tactical responses for fundamental Zerg unit maneuvers. In the experimental setup, {SwarmBrain} is in control of the Zerg race in confrontation with an Computer-controlled Terran adversary. Experimental results show the capacity of {SwarmBrain} to conduct economic augmentation, territorial expansion, and tactical formulation, and it shows the {SwarmBrain} is capable of achieving victory against Computer players set at different difficulty levels.},
	number = {{arXiv}:2401.17749},
	publisher = {{arXiv}},
	author = {Shao, Xiao and Jiang, Weifu and Zuo, Fei and Liu, Mengqing},
	urldate = {2025-09-08},
	date = {2024-01-31},
	eprinttype = {arxiv},
	eprint = {2401.17749 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{hofstede_synthetic_1999,
	title = {Synthetic Cultures: Intercultural Learning Through Simulation Games},
	volume = {30},
	rights = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
	issn = {1046-8781, 1552-826X},
	url = {https://journals.sagepub.com/doi/10.1177/104687819903000402},
	doi = {10.1177/104687819903000402},
	shorttitle = {Synthetic Cultures},
	abstract = {This article introduces the concept of synthetic cultures. These are role profiles for enacting dimensions of national culture. The full profiles are given for 10 synthetic cultures, based on Gert Hofstede’s dimensions of national culture. They can be used for training or simulation/gaming. Examples of their application are presented. Apart from examples of existing games, suggestions are made for creating custom simulations that use synthetic cultures. Experiences of players are mentioned, both in face-to-face and in electronically mediated settings. Special attention is paid to debriefing issues. The article concludes with practical advice to prospective game leaders.},
	pages = {415--440},
	number = {4},
	journaltitle = {Simulation \& Gaming},
	shortjournal = {Simulation \& Gaming},
	author = {Hofstede, Gert Jan and Pedersen, Paul},
	urldate = {2025-09-08},
	date = {1999-12},
	langid = {english},
}

@inproceedings{taubenfeld_systematic_2024,
	title = {Systematic Biases in {LLM} Simulations of Debates},
	url = {http://arxiv.org/abs/2402.04049},
	doi = {10.18653/v1/2024.emnlp-main.16},
	abstract = {The emergence of Large Language Models ({LLMs}), has opened exciting possibilities for constructing computational simulations designed to replicate human behavior accurately. Current research suggests that {LLM}-based agents become increasingly human-like in their performance, sparking interest in using these {AI} agents as substitutes for human participants in behavioral studies. However, {LLMs} are complex statistical learners without straightforward deductive rules, making them prone to unexpected behaviors. Hence, it is crucial to study and pinpoint the key behavioral distinctions between humans and {LLM}-based agents. In this study, we highlight the limitations of {LLMs} in simulating human interactions, particularly focusing on {LLMs}' ability to simulate political debates on topics that are important aspects of people's day-to-day lives and decision-making processes. Our findings indicate a tendency for {LLM} agents to conform to the model's inherent social biases despite being directed to debate from certain political perspectives. This tendency results in behavioral patterns that seem to deviate from well-established social dynamics among humans. We reinforce these observations using an automatic self-fine-tuning method, which enables us to manipulate the biases within the {LLM} and demonstrate that agents subsequently align with the altered biases. These results underscore the need for further research to develop methods that help agents overcome these biases, a critical step toward creating more realistic simulations.},
	pages = {251--267},
	booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
	author = {Taubenfeld, Amir and Dover, Yaniv and Reichart, Roi and Goldstein, Ariel},
	urldate = {2025-09-10},
	date = {2024},
	eprinttype = {arxiv},
	eprint = {2402.04049 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{cares_take_nodate,
	title = {Take Your Third Move First},
	issn = {0017-8012},
	url = {https://hbr.org/2007/03/take-your-third-move-first},
	journaltitle = {Harvard Business Review},
	author = {Cares, Jeff and Miskel, Jim},
	urldate = {2025-06-12},
	langid = {english},
}

@misc{mouat_4-box_nodate,
	title = {The 4-Box Approach: What Does Success Look Like?},
	url = {https://www.professionalwargaming.co.uk/20130711-The4BoxApproach-Mouat-U.pdf},
	abstract = {An Approach for Determining Critical Event Resolution in a course of action Wargame},
	author = {Mouat, Tom},
	urldate = {2025-06-26},
}

@article{johnson_ai_2022,
	title = {The {AI} Commander Problem: Ethical, Political, and Psychological Dilemmas of Human-Machine Interactions in {AI}-enabled Warfare},
	volume = {21},
	issn = {1502-7570, 1502-7589},
	url = {https://www.tandfonline.com/doi/full/10.1080/15027570.2023.2175887},
	doi = {10.1080/15027570.2023.2175887},
	shorttitle = {The {AI} Commander Problem},
	pages = {246--271},
	number = {3},
	journaltitle = {Journal of Military Ethics},
	shortjournal = {Journal of Military Ethics},
	author = {Johnson, James},
	urldate = {2025-09-08},
	date = {2022-10-02},
	langid = {english},
}

@inproceedings{liu_application_2019,
	location = {Cham},
	title = {The Application of {AlphaZero} to Wargaming},
	volume = {11919},
	isbn = {978-3-030-35287-5 978-3-030-35288-2},
	url = {http://link.springer.com/10.1007/978-3-030-35288-2_1},
	doi = {10.1007/978-3-030-35288-2_1},
	abstract = {In this paper, we explore the process of automatically learning to play wargames using {AlphaZero} deep reinforcement learning. We consider a simple wargame, Coral Sea, which is a turn-based game played on a hexagonal grid between two players. We explore the differences between Coral Sea and traditional board games, where the successful use of {AlphaZero} has been demonstrated. Key differences include: problem representation, wargame asymmetry, limited strategic depth, and the requirement for significant hardware resources. We demonstrate how bootstrapping {AlphaZero} with supervised learning can overcome these challenges. In the context of Coral Sea, this enables {AlphaZero} to learn optimal play and outperform the supervised examples on which it was trained.},
	pages = {3--14},
	publisher = {Springer International Publishing},
	author = {Moy, Glennn and Shekh, Slava},
	editor = {Liu, Jixue and Bailey, James},
	urldate = {2025-09-13},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-35288-2_1},
	note = {Book Title: {AI} 2019: Advances in Artificial Intelligence
Series Title: Lecture Notes in Computer Science},
}

@book{sun_art_1910,
	location = {London},
	title = {The Art of War},
	publisher = {Luzac \& Co.},
	author = {Sun, Tzu},
	editorb = {Giles, translator, Lionel},
	editorbtype = {redactor},
	date = {1910},
}

@inproceedings{perla_art_1990,
	title = {The art of wargaming: a guide for professionals and hobbyists},
	url = {https://api.semanticscholar.org/CorpusID:107479900},
	author = {Perla, Peter P.},
	date = {1990},
}

@misc{zhu_automated_2025,
	title = {The Automated but Risky Game: Modeling Agent-to-Agent Negotiations and Transactions in Consumer Markets},
	url = {http://arxiv.org/abs/2506.00073},
	doi = {10.48550/arXiv.2506.00073},
	shorttitle = {The Automated but Risky Game},
	abstract = {{AI} agents are increasingly used in consumer-facing applications to assist with tasks such as product search, negotiation, and transaction execution. In this paper, we explore a future scenario where both consumers and merchants authorize {AI} agents to fully automate negotiations and transactions. We aim to answer two key questions: (1) Do different {LLM} agents vary in their ability to secure favorable deals for users? (2) What risks arise from fully automating deal-making with {AI} agents in consumer markets? To address these questions, we develop an experimental framework that evaluates the performance of various {LLM} agents in real-world negotiation and transaction settings. Our findings reveal that {AI}-mediated deal-making is an inherently imbalanced game -- different agents achieve significantly different outcomes for their users. Moreover, behavioral anomalies in {LLMs} can result in financial losses for both consumers and merchants, such as overspending or accepting unreasonable deals. These results underscore that while automation can improve efficiency, it also introduces substantial risks. Users should exercise caution when delegating business decisions to {AI} agents.},
	number = {{arXiv}:2506.00073},
	publisher = {{arXiv}},
	author = {Zhu, Shenzhe and Sun, Jiao and Nian, Yi and South, Tobin and Pentland, Alex and Pei, Jiaxin},
	urldate = {2025-09-13},
	date = {2025-06-13},
	eprinttype = {arxiv},
	eprint = {2506.00073 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, Computer Science - Multiagent Systems},
}

@article{gnyawali_competitioncooperation_2016,
	title = {The competition–cooperation paradox in inter-firm relationships: A conceptual framework},
	volume = {53},
	issn = {0019-8501},
	url = {https://www.sciencedirect.com/science/article/pii/S0019850115003211},
	doi = {10.1016/j.indmarman.2015.11.014},
	shorttitle = {The competition–cooperation paradox in inter-firm relationships},
	abstract = {With a focus on inter-firm relationships involving the simultaneous pursuit of competition and cooperation, we develop a conceptual framework that explicates key paradoxical conditions, paradoxical tension, and performance implications of tension in such relationships. We propose felt tension as the actual manifestation of the paradox and offer insights on critical capabilities necessary to understand and manage the paradox. Our paper extends the paradox literature in the inter-organizational context and provides a set of concepts and propositions designed to stimulate systematic empirical research on the competition–cooperation paradox.},
	pages = {7--18},
	journaltitle = {Industrial Marketing Management},
	shortjournal = {Industrial Marketing Management},
	author = {Gnyawali, Devi R. and Madhavan, Ravi and He, Jinyu and Bengtsson, Maria},
	urldate = {2025-06-12},
	date = {2016-02-01},
}

@book{james_f_dunnigan_complete_2005,
	edition = {2000},
	title = {The Complete Wargames Handbook},
	author = {{James F. Dunnigan}},
	date = {2005},
	langid = {english},
}

@unpublished{philip_sabin_continuing_nodate,
	title = {{THE} {CONTINUING} {MERITS} {OF} {MANUAL} {WARGAMING}},
	url = {https://www.professionalwargaming.co.uk/Manual-Wargaming-Sabin.pdf},
	author = {{Philip Sabin}},
	urldate = {2025-06-26},
}

@article{crick_dark-side_2021,
	title = {The dark-side of coopetition: Influences on the paradoxical forces of cooperativeness and competitiveness across product-market strategies},
	volume = {122},
	issn = {0148-2963},
	url = {https://www.sciencedirect.com/science/article/pii/S0148296320305750},
	doi = {10.1016/j.jbusres.2020.08.065},
	shorttitle = {The dark-side of coopetition},
	abstract = {Although it has been widely established that coopetition (simultaneous cooperation and competition) has a positive association with firms’ performance, researchers have largely overlooked the environmental and firm-level forces potentially affecting that relationship. Under resource-based theory and the relational view, this current study evaluates whether competitive intensity and competitive aggressiveness negatively moderate the coopetition-financial performance relationship. Through a mixed methods approach featuring New Zealand wine producers, a positive relationship existed between coopetition and financial performance supporting earlier research. However, competitive aggressiveness provided a negative moderation effect and competitive intensity had a positive moderation effect. Unique insights emerge regarding underlying issues (potential dark-sides) behind the coopetition-financial performance relationship. Competitive intensity provides an opportunity for owner-managers to select trustworthy rivals targeting complementary product-markets. However, if decision-makers cannot effectively manage competitive aggressiveness across product-market strategies, they are likely to experience certain harmful outcomes, like tensions and diluted competitive advantages.},
	pages = {226--240},
	journaltitle = {Journal of Business Research},
	shortjournal = {Journal of Business Research},
	author = {Crick, James M. and Crick, Dave},
	urldate = {2025-06-12},
	date = {2021-01-01},
	keywords = {Competitive aggressiveness, Competitive intensity, Coopetition, Financial performance, Relational view, Resource-based theory},
}

@inproceedings{marincioni_effect_2024,
	location = {Milan, Italy},
	title = {The Effect of {LLM}-Based {NPC} Emotional States on Player Emotions: An Analysis of Interactive Game Play},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-5067-8},
	url = {https://ieeexplore.ieee.org/document/10645631/},
	doi = {10.1109/CoG60054.2024.10645631},
	shorttitle = {The Effect of {LLM}-Based {NPC} Emotional States on Player Emotions},
	eventtitle = {2024 {IEEE} Conference on Games ({CoG})},
	pages = {1--6},
	booktitle = {2024 {IEEE} Conference on Games ({CoG})},
	publisher = {{IEEE}},
	author = {Marincioni, Alessandro and Miltiadous, Myriana and Zacharia, Katerina and Heemskerk, Rick and Doukeris, Georgios and Preuss, Mike and Barbero, Giulio},
	urldate = {2025-09-08},
	date = {2024-08-05},
}

@article{snegirev_empirical_2020,
	title = {The empirical analysis of a macro-level anticipatory system emergence: The construction of a national system for skill needs anticipation and matching},
	volume = {124},
	issn = {00163287},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0016328720301257},
	doi = {10.1016/j.futures.2020.102635},
	shorttitle = {The empirical analysis of a macro-level anticipatory system emergence},
	pages = {102635},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Snegirev, A. and Bidzhiev, A.},
	urldate = {2025-06-12},
	date = {2020-12},
	langid = {english},
}

@article{rubel_epistemology_2006,
	title = {The Epistemology of War Gaming},
	volume = {59},
	url = {https://digital-commons.usnwc.edu/nwc-review/vol59/iss2/8},
	number = {2},
	journaltitle = {Naval War College Review},
	author = {Rubel, Robert C},
	urldate = {2025-06-12},
	date = {2006},
	langid = {english},
}

@article{kelemen_futures_2020,
	title = {The futures of terrorism against China in the Greater Middle East},
	volume = {124},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328720301348},
	doi = {10.1016/j.futures.2020.102643},
	abstract = {China’s rising investment and engagement with countries in the Greater Middle East underlines its rising exposure to security threats in this region. The countries have been often associated with a high threat of terrorism thus increasing risk for various stakeholders. To analyse the potential ways these threats might unfold in the future, four scenarios of possible terrorism against China are put forward. In each scenario, various levels of Chinese economic engagement interact with local regimes which in turn leads to differing containments of potential terrorist threats. A preferable scenario “United Front’’ is identified for its low risk for Chinese interest in the region and its success of economic strategy implemented by China. However, this preferable scenario (for China) calls into question how China can achieve its high influence in the region through investment without perpetuating a state of surveillance model that might not be conducive to peace on the long run. Therefore, we provide preliminary policy guidelines to achieve China’s original diplomatic and economic aims while decreasing the likelihood of terrorism without incurring in possible humanitarian losses in the region.},
	pages = {102643},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Kelemen, Barbara and Fergnani, Alessandro},
	urldate = {2025-06-12},
	date = {2020-12-01},
	keywords = {China, Chinese foreign policy, Futures, Middle East, Scenario planning, Terrorism},
}

@article{shojaee_illusion_nodate,
	title = {The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity},
	abstract = {Recent generations of frontier language models have introduced Large Reasoning Models ({LRMs}) that generate detailed thinking processes before providing answers. While these models demonstrate improved performance on reasoning benchmarks, their fundamental capabilities, scaling properties, and limitations remain insufficiently understood. Current evaluations primarily focus on established mathematical and coding benchmarks, emphasizing final answer accuracy. However, this evaluation paradigm often suffers from data contamination and does not provide insights into the reasoning traces’ structure and quality. In this work, we systematically investigate these gaps with the help of controllable puzzle environments that allow precise manipulation of compositional complexity while maintaining consistent logical structures. This setup enables the analysis of not only final answers but also the internal reasoning traces, offering insights into how {LRMs} “think”. Through extensive experimentation across diverse puzzles, we show that frontier {LRMs} face a complete accuracy collapse beyond certain complexities. Moreover, they exhibit a counterintuitive scaling limit: their reasoning effort increases with problem complexity up to a point, then declines despite having an adequate token budget. By comparing {LRMs} with their standard {LLM} counterparts under equivalent inference compute, we identify three performance regimes: (1) lowcomplexity tasks where standard models surprisingly outperform {LRMs}, (2) medium-complexity tasks where additional thinking in {LRMs} demonstrates advantage, and (3) high-complexity tasks where both models experience complete collapse. We found that {LRMs} have limitations in exact computation: they fail to use explicit algorithms and reason inconsistently across puzzles. We also investigate the reasoning traces in more depth, studying the patterns of explored solutions and analyzing the models’ computational behavior, shedding light on their strengths, limitations, and ultimately raising crucial questions about their true reasoning capabilities.},
	author = {Shojaee, Parshin and Mirzadeh, Iman and Alizadeh, Keivan and Horton, Maxwell and Bengio, Samy and Farajtabar, Mehrdad},
	langid = {english},
}

@article{scherpereel_impact_2003,
	title = {The Impact of Business War Games: Quantifying Training Effectiveness},
	volume = {30},
	rights = {Copyright (c) 2017 Developments in Business Simulation and Experiential Learning},
	url = {https://absel-ojs-ttu.tdl.org/absel/article/view/701},
	shorttitle = {The Impact of Business War Games},
	abstract = {Does participation in a business simulation exercise change people’s perspectives on decision problems? Does it change their approach to solving those problems? These are fundamental questions positively confirmed by this research. Using the semantic differential technique and a one-group pretest-posttest design, tests are conducted to assess changes in characterization and approaches to business decision problems. A matched pair t-test confirms significant change in ten of twelve key hypotheses; while the Wilcoxon signed-rank test confirms nine. The measurement methodology developed and results presented provide quantifiable justification for the use of business simulation exercises to induce targeted change in a decision maker’s decision problem perception.},
	journaltitle = {Developments in Business Simulation and Experiential Learning},
	author = {Scherpereel, Christopher M.},
	urldate = {2025-06-12},
	date = {2003},
	langid = {english},
}

@incollection{chang_impact_2020,
	title = {The impact of sentiment on content post popularity through emoji and text on social platforms},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-819204-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128192047000099},
	pages = {159--184},
	booktitle = {Cyber Influence and Cognitive Threats},
	publisher = {Elsevier},
	author = {Chang, Wei-Lun and Tseng, Hsiao-Chiao},
	urldate = {2025-08-06},
	date = {2020},
	langid = {english},
	doi = {10.1016/B978-0-12-819204-7.00009-9},
}

@misc{heilmann_japcc_nodate,
	title = {{THE} {JAPCC} {EDUCATION} \& {TRAINING} {MODEL} ({NATO})},
	publisher = {Joint Air Power Competence Centre},
	author = {Heilmann, Uwe L},
	langid = {english},
}

@article{ma_maximum_2019,
	title = {The maximum {PI} index of bicyclic graphs with even number of edges},
	volume = {146},
	issn = {0020-0190},
	url = {https://www.sciencedirect.com/science/article/pii/S0020019019300249},
	doi = {10.1016/j.ipl.2019.02.001},
	abstract = {The {PI} index of a graph G is defined by {PI}(G)=∑e=(u,v)∈E[mu(e{\textbar}G)+mv(e{\textbar}G)] where mu(e{\textbar}G) be the number of edges in G lying closer to the vertex u than to the vertex v. In this paper, we give the upper bound on the {PI} index of connected bicyclic graphs with even number of edges and characterize the extremal graphs with maximum {PI} index.},
	pages = {13--16},
	journaltitle = {Information Processing Letters},
	shortjournal = {Information Processing Letters},
	author = {Ma, Gang and Bian, Qiuju and Wang, Jianfeng},
	urldate = {2025-06-12},
	date = {2019-06-01},
	keywords = {Bicyclic graphs, {PI} index, Topological index},
}

@article{banks_methodological_2024,
	title = {The Methodological Machinery of Wargaming: A Path toward Discovering Wargaming’s Epistemological Foundations},
	volume = {26},
	issn = {1521-9488},
	url = {https://doi.org/10.1093/isr/viae002},
	doi = {10.1093/isr/viae002},
	shorttitle = {The Methodological Machinery of Wargaming},
	abstract = {This paper proposes a comprehensive research program for determining the epistemological foundations of analytic wargaming. Wargaming has been used in military, government, and private sectors for decades, with tens of millions of dollars spent annually on it. In light of the changing strategic circumstances of the twenty-first century, it has only become more popular. However, the epistemological foundations of the method are poorly understood. Many professional wargamers contend that wargaming is an “art” and thus unable to be systemically evaluated. Recent work by a small coterie of international relations scholars has contended that wargaming can be reconciled with social science, typically by evaluating wargaming according to experimental standards. However, this solution strips wargames of most of their unique features and cannot explain why some of the most prominent wargames in history produced meaningful results. In this paper, I argue that in the attempt to better understand wargaming’s epistemology, scholars should begin by recognizing the prominent features of wargames and research each of these to determine if and how wargames produce rigorous knowledge. In making this argument, I identify five distinct “methodological machineries” of wargaming—the recurring processes through which wargames may produce knowledge—that distinguish wargaming from other social science methods: (i) they are representative, (ii) they feature consequential decisions made by human players, (iii) they are adjudicated, (iv) they are immersive, and (v) they are bespoke designs. I show how each of these machineries offers potential opportunities and dangers in the production of knowledge through the method of wargaming. In outlining these distinct features, I offer a clear and viable research program for epistemologists of wargaming.},
	pages = {viae002},
	number = {1},
	journaltitle = {International Studies Review},
	shortjournal = {International Studies Review},
	author = {Banks, David E},
	urldate = {2025-06-12},
	date = {2024-03-01},
}

@article{iden_nature_2017,
	title = {The nature of strategic foresight research: A systematic literature review},
	volume = {116},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S0040162516306035},
	doi = {10.1016/j.techfore.2016.11.002},
	shorttitle = {The nature of strategic foresight research},
	abstract = {Strategic foresight is a scientific field in rapid development judged from the increase in number of yearly publications the last decade. What characterizes the research in this field? To answer this question we undertook a systematic literature review searching two library databases, Business Source Complete and {ScienceDirect}, for scientific articles related to the topic ´strategic foresight´ in the context of the organization. The search revealed 59 publications published between January 2000 and October 2014. The articles were systematically organized and analyzed. This review provides the status of this emergent research field. Although we witness a growth of academic interest in strategic foresight, we argue that this scientific field is weakly organized and there is a lack of theoretical progress. We have analyzed the research subjects addressed in the 59 articles, and from this a taxonomy of eight categories. Three categories dominate in terms of frequency of articles: methods applied, organizing practices, and experiences gained. There is only limited research on motivation and use, value contribution, and innovation. Explorative research dominates, and a variety of theoretical perspectives has been used. Some attempts to build conceptual foundations can be observed, but in general, we found no single perspective that deserves loyalty on which a coherent theoretical foundation of strategic foresight is built. Strategic foresight has a great potential of contributing more to the success of a firm if the research moves from today's dominating explorative research to also include more explanatory research.},
	pages = {87--97},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Iden, Jon and Methlie, Leif B. and Christensen, Gunnar E.},
	urldate = {2025-06-12},
	date = {2017-03-01},
	keywords = {Corporate foresight, Strategic foresight, Systematic literature review, Technology foresight},
}

@misc{engel_negotiation_2025,
	title = {The Negotiation Trap An Experiment on a Large Language Model},
	url = {https://www.ssrn.com/abstract=5316057},
	doi = {10.2139/ssrn.5316057},
	publisher = {{SSRN}},
	author = {Engel, Christoph},
	urldate = {2025-09-08},
	date = {2025},
}

@article{bradfield_origins_2005,
	title = {The origins and evolution of scenario techniques in long range business planning},
	volume = {37},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328705000042},
	doi = {10.1016/j.futures.2005.01.003},
	abstract = {Scenario Planning has been around for more than 30 years and during this period a multitude of techniques and methodologies have developed, resulting in what has been described as a ‘methodological chaos’ which is unlikely to disappear in the near future (A. Martelli, Scenario building and scenario planning: state of the art and prospects of evolution, Futures Research Quarterly Summer (2001)). This is reflected in the fact that literature reveals an abundance of different and at times contradictory definitions, characteristics, principles and methodological ideas about scenarios. It has been suggested that a pressing need for the future of scenarios is amongst other things, to resolve the confusion over ‘the definitions and methods of scenarios’. This paper makes a beginning at this need by tracing the origins and growth of scenarios and the subsequent evolution of the various methodologies; a classification of the methodologies into three main schools of techniques is given and the salient features of these schools are compared and contrasted.},
	pages = {795--812},
	number = {8},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Bradfield, Ron and Wright, George and Burt, George and Cairns, George and Van Der Heijden, Kees},
	urldate = {2025-06-12},
	date = {2005-10-01},
}

@misc{lutz_prompt_2025,
	title = {The Prompt Makes the Person(a): A Systematic Evaluation of Sociodemographic Persona Prompting for Large Language Models},
	url = {http://arxiv.org/abs/2507.16076},
	doi = {10.48550/arXiv.2507.16076},
	shorttitle = {The Prompt Makes the Person(a)},
	abstract = {Persona prompting is increasingly used in large language models ({LLMs}) to simulate views of various sociodemographic groups. However, how a persona prompt is formulated can significantly affect outcomes, raising concerns about the fidelity of such simulations. Using five open-source {LLMs}, we systematically examine how different persona prompt strategies, specifically role adoption formats and demographic priming strategies, influence {LLM} simulations across 15 intersectional demographic groups in both open- and closed-ended tasks. Our findings show that {LLMs} struggle to simulate marginalized groups, particularly nonbinary, Hispanic, and Middle Eastern identities, but that the choice of demographic priming and role adoption strategy significantly impacts their portrayal. Specifically, we find that prompting in an interview-style format and name-based priming can help reduce stereotyping and improve alignment. Surprisingly, smaller models like {OLMo}-2-7B outperform larger ones such as Llama-3.3-70B. Our findings offer actionable guidance for designing sociodemographic persona prompts in {LLM}-based simulation studies.},
	number = {{arXiv}:2507.16076},
	publisher = {{arXiv}},
	author = {Lutz, Marlene and Sen, Indira and Ahnert, Georg and Rogers, Elisa and Strohmaier, Markus},
	urldate = {2025-09-11},
	date = {2025-07-21},
	eprinttype = {arxiv},
	eprint = {2507.16076 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@report{wainstein_relationship_1986,
	title = {The Relationship of Battle Damage to Unit Combat Performance},
	abstract = {The purpose of this study is to investigate the historical basis for the assumption that a military formation will cease to be effective after having ost a pro-ordained percentage of its strength. Batles from the First World War to the 1982 Falklands campaign we reviewed for Insight Into the validity of ts assumption.

The effect of heavy batfle damage on units has been both variable and unpredictable., There is a relationship between losses and the continued willingness to fight, but It defies precise definition. So long as some men In the formation continue to fight as an organized entity, either in atack or defense, for whatever reason, ft formation they represent cannot be termed 'Ineffective.'},
	number = {{IDA} {PAPER} P-1903},
	institution = {Institute ofr Defense Analyses},
	author = {Wainstein, Leonard},
	date = {1986-04},
	langid = {english},
}

@article{caballero_teston_role_2026,
	title = {The role of automated planning in battle management systems for military tactics},
	volume = {297},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417425028751},
	doi = {10.1016/j.eswa.2025.129259},
	pages = {129259},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Caballero Testón, J. and Pérez-Mon, Olaya and R-Moreno, María D.},
	urldate = {2025-09-08},
	date = {2026-02},
	langid = {english},
}

@article{cohen_role_1961,
	title = {The Role of Management Games in Education and Research},
	volume = {7},
	issn = {0025-1909},
	url = {https://www.jstor.org/stable/2627098},
	abstract = {This paper is intended to be a broad survey of both the present and the potential role of management games in education and research. Against a background of the history of business games, we first try to characterize the present development of these games. A few management games are described in some detail, and a number of others are mentioned only briefly. The differences between general and functional business games are discussed. Present uses of management games as a teaching device are surveyed and evaluated. Some hypotheses regarding the relations between the design and administrative characteristics of a business game and its educational properties are also formulated. What might be a major improvement over existing management games, here named the "game case", is then suggested. In the concluding portion of this paper, the potential use of management games as a laboratory for business and social science research is surveyed. Some methodological problems which would arise from research uses of business games are also discussed.},
	pages = {131--166},
	number = {2},
	journaltitle = {Management Science},
	author = {Cohen, Kalman J. and Rhenman, Eric},
	urldate = {2025-09-13},
	date = {1961},
	note = {Publisher: {INFORMS}},
}

@misc{yu_surprising_2022,
	title = {The Surprising Effectiveness of {PPO} in Cooperative, Multi-Agent Games},
	url = {http://arxiv.org/abs/2103.01955},
	doi = {10.48550/arXiv.2103.01955},
	abstract = {Proximal Policy Optimization ({PPO}) is a ubiquitous on-policy reinforcement learning algorithm but is significantly less utilized than off-policy learning algorithms in multi-agent settings. This is often due to the belief that {PPO} is significantly less sample efficient than off-policy methods in multi-agent systems. In this work, we carefully study the performance of {PPO} in cooperative multi-agent settings. We show that {PPO}-based multi-agent algorithms achieve surprisingly strong performance in four popular multi-agent testbeds: the particle-world environments, the {StarCraft} multi-agent challenge, Google Research Football, and the Hanabi challenge, with minimal hyperparameter tuning and without any domain-specific algorithmic modifications or architectures. Importantly, compared to competitive off-policy methods, {PPO} often achieves competitive or superior results in both final returns and sample efficiency. Finally, through ablation studies, we analyze implementation and hyperparameter factors that are critical to {PPO}'s empirical performance, and give concrete practical suggestions regarding these factors. Our results show that when using these practices, simple {PPO}-based methods can be a strong baseline in cooperative multi-agent reinforcement learning. Source code is released at {\textbackslash}url\{https://github.com/marlbenchmark/on-policy\}.},
	number = {{arXiv}:2103.01955},
	publisher = {{arXiv}},
	author = {Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
	urldate = {2025-09-08},
	date = {2022-11-04},
	eprinttype = {arxiv},
	eprint = {2103.01955 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@misc{curvo_traitors_2025,
	title = {The Traitors: Deception and Trust in Multi-Agent Language Model Simulations},
	url = {http://arxiv.org/abs/2505.12923},
	doi = {10.48550/arXiv.2505.12923},
	shorttitle = {The Traitors},
	abstract = {As {AI} systems increasingly assume roles where trust and alignment with human values are essential, understanding when and why they engage in deception has become a critical research priority. We introduce The Traitors, a multi-agent simulation framework inspired by social deduction games, designed to probe deception, trust formation, and strategic communication among large language model ({LLM}) agents under asymmetric information. A minority of agents the traitors seek to mislead the majority, while the faithful must infer hidden identities through dialogue and reasoning. Our contributions are: (1) we ground the environment in formal frameworks from game theory, behavioral economics, and social cognition; (2) we develop a suite of evaluation metrics capturing deception success, trust dynamics, and collective inference quality; (3) we implement a fully autonomous simulation platform where {LLMs} reason over persistent memory and evolving social dynamics, with support for heterogeneous agent populations, specialized traits, and adaptive behaviors. Our initial experiments across {DeepSeek}-V3, {GPT}-4o-mini, and {GPT}-4o (10 runs per model) reveal a notable asymmetry: advanced models like {GPT}-4o demonstrate superior deceptive capabilities yet exhibit disproportionate vulnerability to others' falsehoods. This suggests deception skills may scale faster than detection abilities. Overall, The Traitors provides a focused, configurable testbed for investigating {LLM} behavior in socially nuanced interactions. We position this work as a contribution toward more rigorous research on deception mechanisms, alignment challenges, and the broader social reliability of {AI} systems.},
	number = {{arXiv}:2505.12923},
	publisher = {{arXiv}},
	author = {Curvo, Pedro M. P.},
	urldate = {2025-09-13},
	date = {2025-05-19},
	eprinttype = {arxiv},
	eprint = {2505.12923 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Multiagent Systems},
}

@article{rohrbeck_value_2013,
	title = {The value contribution of strategic foresight: Insights from an empirical study of large European companies},
	volume = {80},
	issn = {0040-1625},
	url = {https://www.sciencedirect.com/science/article/pii/S004016251300005X},
	doi = {10.1016/j.techfore.2013.01.004},
	shorttitle = {The value contribution of strategic foresight},
	abstract = {This paper focuses on exploring the potential and empirically observable value creation of strategic foresight activities in firms. We first review the literature on strategic foresight, innovation management and strategic management in order to identify the potential value contributions. We use survey data from 77 large multinational firms to assess how much value is generated from formalized strategic foresight practices in these firms. We show that it is possible to capture value through (1) an enhanced capacity to perceive change, (2) an enhanced capacity to interpret and respond to change, (3) influencing other actors, (4) and through an enhanced capacity for organizational learning.},
	pages = {1593--1606},
	number = {8},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Rohrbeck, René and Schwarz, Jan Oliver},
	urldate = {2025-06-12},
	date = {2013-10-01},
	keywords = {Organizational future orientation, Strategic foresight, Value creation, Weak signals},
}

@thesis{judge_wargaming_2019,
	title = {The Wargaming Guild: {HOW} {THE} {NATURE} {OF} A {DISCIPLINE} {IMPACTS} {ITS} {CRAFT} {AND} {WHETHER} {IT} {MATTERS}},
	shorttitle = {The Wargaming Guild},
	institution = {{GEORGETOWN} {UNIVERSITY}},
	type = {phdthesis},
	author = {Judge, Sawyer},
	date = {2019},
	langid = {english},
}

@misc{wang_tmgbench_2025,
	title = {{TMGBench}: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of {LLMs}},
	url = {http://arxiv.org/abs/2410.10479},
	doi = {10.48550/arXiv.2410.10479},
	shorttitle = {{TMGBench}},
	abstract = {The rapid advancement of large language models has accelerated their application in reasoning, with strategic reasoning drawing increasing attention. To evaluate the strategic reasoning capabilities of {LLMs}, game theory, with its concise structure, has become the preferred approach for many researchers. However, current research typically focuses on a limited selection of games, resulting in low coverage of game types. Additionally, classic game scenarios carry risks of data leakage, and the benchmarks used often lack extensibility, rendering them inadequate for evaluating state-of-the-art models. To address these challenges, we propose {TMGBench}, characterized by comprehensive game type coverage, diverse scenarios and flexible game organization. Specifically, we incorporate all 144 game types summarized by the Robinson-Goforth topology of 2x2 games, constructed as classic games in our benchmark; we also synthetize diverse, higher-quality game scenarios for each classic game, which we refer to as story-based games. Lastly, to provide a sustainable evaluation framework adaptable to increasingly powerful {LLMs}, we treat the aforementioned games as atomic units and organize them into more complex forms through sequential, parallel, and nested structures. We conducted a comprehensive evaluation of mainstream {LLMs}, covering tests on rational reasoning, reasoning robustness, Theory-of-Mind capabilities, and reasoning in complex game forms. The results revealed {LLMs} still have flaws in the accuracy and consistency of strategic reasoning processes, and their levels of mastery over Theory-of-Mind also vary. Additionally, {SOTA} models like o3-mini, Qwen3 and deepseek-reasoner, were also evaluated across the sequential, parallel, and nested game structures while the results highlighted the challenges posed by {TMGBench}.},
	number = {{arXiv}:2410.10479},
	publisher = {{arXiv}},
	author = {Wang, Haochuan and Feng, Xiachong and Li, Lei and Guo, Yu and Qin, Zhanyue and Sui, Dianbo and Kong, Lingpeng},
	urldate = {2025-09-10},
	date = {2025-05-27},
	eprinttype = {arxiv},
	eprint = {2410.10479 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory},
}

@article{noauthor_stimulate_nodate,
	title = {{TO} {STIMULATE} {THOUGHT}},
	langid = {english},
}

@article{caffrey_toward_2000,
	title = {Toward a History Based Doctrine for Wargaming},
	author = {Caffrey, Matthew},
	date = {2000},
	langid = {english},
}

@misc{sharma_towards_2025,
	title = {Towards Understanding Sycophancy in Language Models},
	url = {http://arxiv.org/abs/2310.13548},
	doi = {10.48550/arXiv.2310.13548},
	abstract = {Human feedback is commonly utilized to finetune {AI} assistants. But human feedback may also encourage model responses that match user beliefs over truthful ones, a behaviour known as sycophancy. We investigate the prevalence of sycophancy in models whose finetuning procedure made use of human feedback, and the potential role of human preference judgments in such behavior. We first demonstrate that five state-of-the-art {AI} assistants consistently exhibit sycophancy across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models ({PMs}) prefer convincingly-written sycophantic responses over correct ones a non-negligible fraction of the time. Optimizing model outputs against {PMs} also sometimes sacrifices truthfulness in favor of sycophancy. Overall, our results indicate that sycophancy is a general behavior of state-of-the-art {AI} assistants, likely driven in part by human preference judgments favoring sycophantic responses.},
	number = {{arXiv}:2310.13548},
	publisher = {{arXiv}},
	author = {Sharma, Mrinank and Tong, Meg and Korbak, Tomasz and Duvenaud, David and Askell, Amanda and Bowman, Samuel R. and Cheng, Newton and Durmus, Esin and Hatfield-Dodds, Zac and Johnston, Scott R. and Kravec, Shauna and Maxwell, Timothy and {McCandlish}, Sam and Ndousse, Kamal and Rausch, Oliver and Schiefer, Nicholas and Yan, Da and Zhang, Miranda and Perez, Ethan},
	urldate = {2025-09-15},
	date = {2025-05-10},
	eprinttype = {arxiv},
	eprint = {2310.13548 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{yuan_tracing_2025,
	title = {Tracing {LLM} Reasoning Processes with Strategic Games: A Framework for Planning, Revision, and Resource-Constrained Decision Making},
	url = {http://arxiv.org/abs/2506.12012},
	doi = {10.48550/arXiv.2506.12012},
	shorttitle = {Tracing {LLM} Reasoning Processes with Strategic Games},
	abstract = {Large language models ({LLMs}) are increasingly used for tasks that require complex reasoning. Most benchmarks focus on final outcomes but overlook the intermediate reasoning steps - such as planning, revision, and decision making under resource constraints. We argue that measuring these internal processes is essential for understanding model behavior and improving reliability. We propose using strategic games as a natural evaluation environment: closed, rule-based systems with clear states, limited resources, and automatic feedback. We introduce a framework that evaluates {LLMs} along three core dimensions: planning, revision, and resource-constrained decision making. To operationalize this, we define metrics beyond win rate, including overcorrection risk rate, correction success rate, improvement slope, and over-budget ratio. In 4320 adversarial rounds across 12 leading models, {ChatGPT}-o3-mini achieves the top composite score, with a win rate of 74.7 percent, a correction success rate of 78.6 percent, and an improvement slope of 0.041. By contrast, Qwen-Plus, despite an overcorrection risk rate of 81.6 percent, wins only 25.6 percent of its matches - primarily due to excessive resource use. We also observe a negative correlation between overcorrection risk rate and correction success rate (Pearson r = -0.51, p = 0.093), suggesting that more frequent edits do not always improve outcomes. Our findings highlight the value of assessing not only what {LLMs} decide but how they arrive at those decisions},
	number = {{arXiv}:2506.12012},
	publisher = {{arXiv}},
	author = {Yuan, Xiaopeng and Zhang, Xingjian and Xu, Ke and Xu, Yifan and Yu, Lijun and Wang, Jindong and Dong, Yushun and Wang, Haohan},
	urldate = {2025-09-13},
	date = {2025-06-13},
	eprinttype = {arxiv},
	eprint = {2506.12012 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@misc{sarkar_training_2025,
	title = {Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning},
	url = {http://arxiv.org/abs/2502.06060},
	doi = {10.48550/arXiv.2502.06060},
	abstract = {Communicating in natural language is a powerful tool in multi-agent settings, as it enables independent agents to share information in partially observable settings and allows zero-shot coordination with humans. However, most prior works are limited as they either rely on training with large amounts of human demonstrations or lack the ability to generate natural and useful communication strategies. In this work, we train language models to have productive discussions about their environment in natural language without any human demonstrations. We decompose the communication problem into listening and speaking. Our key idea is to leverage the agent's goal to predict useful information about the world as a dense reward signal that guides communication. Specifically, we improve a model's listening skills by training them to predict information about the environment based on discussions, and we simultaneously improve a model's speaking skills with multi-agent reinforcement learning by rewarding messages based on their influence on other agents. To investigate the role and necessity of communication in complex social settings, we study an embodied social deduction game based on Among Us, where the key question to answer is the identity of an adversarial imposter. We analyze emergent behaviors due to our technique, such as accusing suspects and providing evidence, and find that it enables strong discussions, doubling the win rates compared to standard {RL}. We release our code and models at https://socialdeductionllm.github.io/},
	number = {{arXiv}:2502.06060},
	publisher = {{arXiv}},
	author = {Sarkar, Bidipta and Xia, Warren and Liu, C. Karen and Sadigh, Dorsa},
	urldate = {2025-06-12},
	date = {2025-02-09},
	eprinttype = {arxiv},
	eprint = {2502.06060 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@article{mans_training_2010,
	title = {Training the Warrior-Diplomat: Enhancing Negotiation and Conflict Management Skills through Experiential Learning.},
	volume = {15},
	issn = {1382-340X},
	url = {https://research.ebsco.com/linkprocessor/plink?id=80036301-addc-32a2-8068-696cea7603fe},
	doi = {10.1163/157180610X506974},
	shorttitle = {Training the Warrior-Diplomat},
	abstract = {Despite the wealth of experience among simulation scholars, there is still little consensus on how to link gaming attributes to specific learning objectives. This article aims to contribute to this discussion and argues that specific simulation design can lead to reaching pre-defined learning objectives. The authors present a teaching project developed and executed for the Netherlands Defense Academy, how it was set up in 2005, and the way it evolved over time. The authors discuss how the methodology fits into the academic debate on the strengths of experiential learning. The simulation methodology used is rooted in experiential learning and typically supports standard learning goals and styles. When dealing with a specific target group, it is possible to pinpoint one specific, overarching learning objective. This allows trainers to link each individual aspect of the simulation design to that particular learning goal and, in turn, provides a valuable framework to develop, run and evaluate simulation exercises. The authors discuss how two innovative elements in simulating gaming can help to make such an approach work: combining closed and open scenarios, and new communication software that allows for continuous supervision during the game. The conclusions discuss how students respond to the challenges during the game and what the data from debriefings tells us about the methodology's learning appeal for a military target group.},
	pages = {247--280},
	number = {2},
	journaltitle = {International Negotiation},
	shortjournal = {International Negotiation},
	author = {Mans, Ulrich and Shimshon, Gideon and Suransky, Leonard},
	urldate = {2025-09-10},
	date = {2010-06-01},
	note = {Publisher: Brill Academic Publishers},
	keywords = {Academic debating, Civil-military relations, Coaching of employees, Communications software, Experiential learning, Negotiation -- International cooperation, Netherlands, Occupational training, Situated learning theory, Teaching experience},
}

@unpublished{yao_tree_2023,
	title = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
	url = {http://arxiv.org/abs/2305.10601},
	abstract = {Language models are increasingly being deployed for general problem
solving across a wide range of tasks, but are still confined to
token-level, left-to-right decision-making processes during inference.
This means they can fall short in tasks that require exploration,
strategic lookahead, or where initial decisions play a pivotal role. To
surmount these challenges, we introduce a new framework for language model
inference, Tree of Thoughts ({ToT}), which generalizes over the popular
Chain of Thought approach to prompting language models, and enables
exploration over coherent units of text (thoughts) that serve as
intermediate steps toward problem solving. {ToT} allows {LMs} to perform
deliberate decision making by considering multiple different reasoning
paths and self-evaluating choices to decide the next course of action, as
well as looking ahead or backtracking when necessary to make global
choices. Our experiments show that {ToT} significantly enhances language
models' problem-solving abilities on three novel tasks requiring
non-trivial planning or search: Game of 24, Creative Writing, and Mini
Crosswords. For instance, in Game of 24, while {GPT}-4 with chain-of-thought
prompting only solved 4\% of tasks, our method achieved a success rate of
74\%. Code repo with all prompts:
https://github.com/ysymyth/tree-of-thought-llm.},
	author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
	date = {2023-05-17},
	note = {{ISBN}: 2305.10601
Publication Title: {arXiv} [cs.{CL}]},
}

@article{celi_trends_2020,
	title = {Trends as Future Prompts in the Anticipatory Design Practice},
	volume = {121},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328720300549},
	doi = {10.1016/j.futures.2020.102564},
	pages = {102564},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Celi, Manuela and Colombi, Chiara},
	urldate = {2025-06-12},
	date = {2020-08-01},
}

@incollection{marc_prensky_true_2001,
	title = {True Believers: Digital Game-Based Learning in The Military},
	url = {https://www.professionalwargaming.co.uk/True-Believers-Digital-Game-Based-Learning-in-The-Military.pdf},
	booktitle = {Digital Game-Based Learning},
	publisher = {{McGraw}-Hill},
	author = {{Marc Prensky}},
	urldate = {2025-06-26},
	date = {2001},
}

@misc{liu_uncertainty_2025,
	title = {Uncertainty Quantification and Confidence Calibration in Large Language Models: A Survey},
	url = {http://arxiv.org/abs/2503.15850},
	doi = {10.48550/arXiv.2503.15850},
	shorttitle = {Uncertainty Quantification and Confidence Calibration in Large Language Models},
	abstract = {Large Language Models ({LLMs}) excel in text generation, reasoning, and decision-making, enabling their adoption in high-stakes domains such as healthcare, law, and transportation. However, their reliability is a major concern, as they often produce plausible but incorrect responses. Uncertainty quantification ({UQ}) enhances trustworthiness by estimating confidence in outputs, enabling risk mitigation and selective prediction. However, traditional {UQ} methods struggle with {LLMs} due to computational constraints and decoding inconsistencies. Moreover, {LLMs} introduce unique uncertainty sources, such as input ambiguity, reasoning path divergence, and decoding stochasticity, that extend beyond classical aleatoric and epistemic uncertainty. To address this, we introduce a new taxonomy that categorizes {UQ} methods based on computational efficiency and uncertainty dimensions (input, reasoning, parameter, and prediction uncertainty). We evaluate existing techniques, assess their real-world applicability, and identify open challenges, emphasizing the need for scalable, interpretable, and robust {UQ} approaches to enhance {LLM} reliability.},
	number = {{arXiv}:2503.15850},
	publisher = {{arXiv}},
	author = {Liu, Xiaoou and Chen, Tiejin and Da, Longchao and Chen, Chacha and Lin, Zhen and Wei, Hua},
	urldate = {2025-09-10},
	date = {2025-06-03},
	eprinttype = {arxiv},
	eprint = {2503.15850 [cs]},
	note = {version: 2},
	keywords = {Computer Science - Computation and Language},
}

@report{hersman_under_2020,
	title = {Under the Nuclear Shadow: Situational Awareness Technology and Crisis Decisionmaking},
	url = {https://csis-website-prod.s3.amazonaws.com/s3fs-public/publication/200318_UnderNucearShadow_FullReport_WEB.pdf},
	abstract = {Findings from eight tabletop exercises ({\textasciitilde}150 participants) on how emerging situational-awareness technology (including {AI}-enabled sensing and decision support) affects crisis decisionmaking and stability.},
	institution = {Center for Strategic and International Studies},
	author = {Hersman, Rebecca K. C. and Younis, Reja and Farabaugh, Bryce and Goldblum, Bethany L. and Reddie, Andrew W.},
	date = {2020},
}

@book{smith_understanding_2024,
	title = {Understanding Distribution Shift in {LLMs}: Methods, Evaluations, and Challenges},
	shorttitle = {Understanding Distribution Shift in {LLMs}},
	abstract = {Large Language Models ({LLMs}) have achieved remarkable success across a wide range of natural language processing tasks. However, their deployment in real-world scenarios often involves encountering data distributions that differ from those seen during training or alignment, raising critical concerns about robustness and stability. Dataset distribution shift-manifesting as covariate shift, label shift, concept drift, or latent shift-can significantly degrade the performance and reliability of {LLMs}, particularly in safety-critical applications. This survey presents a comprehensive review of recent advances in evaluating the robustness and stability of {LLMs} under various forms of dataset shift. We begin by formalizing different types of distribution shifts and their relevance to {LLM} deployment. We then categorize and analyze existing evaluation protocols , benchmark datasets, and robustness metrics, including multi-environment testing, worst-case subpopulation analysis , and distributionally robust optimization frameworks such as {DoRA}. Furthermore, we review alignment strategies (e.g., {DPO}, {RRHF}, {RLHF}) and investigate how they perform under out-of-distribution conditions. Through a synthesis of recent empirical studies and theoretical developments, we highlight current limitations in {LLM} robustness evaluation , such as high-dimensional uncertainty, latent shifts, and the lack of standardized testing protocols. Finally, we identify key research challenges and propose future directions , including the integration of causal reasoning, adap-tive pre-deployment auditing, and system-level robustness benchmarking. This survey aims to provide a foundation for principled, reproducible, and forward-looking evaluation of {LLMs} in real-world, distribution-shifting environments.},
	author = {Smith, Alexander and Martinez, William and Garcia, Sophia and Thomas, Benjamin and Davis, Olivia and Ye, Weimang},
	date = {2024-02-03},
	doi = {10.13140/RG.2.2.33962.32963},
}

@article{nemeth_understanding_2018,
	title = {Understanding some pitfalls in the strategic foresight processes: The case of the Hungarian Ministry of Defense},
	volume = {101},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S001632871730277X},
	doi = {10.1016/j.futures.2018.06.014},
	shorttitle = {Understanding some pitfalls in the strategic foresight processes},
	abstract = {This paper introduces a method that was developed for analyzing the strategic foresight process of the Hungarian Ministry of Defense. In 2013–2014, experts of the Hungarian Ministry of Defense applied a strategic foresight method to identify potential threats and opportunities for 2015–2030 period. This work led them to anticipate the broad trends that lead to the European migration crisis and a more confrontative Russian foreign policy. However, in retrospect the methods used were not specific enough about the time frame of these potential outcomes, nor did the Hungarian analysts believe their findings strongly enough. These results generated a lively debate among Hungarian defense experts about how the foresight method could be improved. This paper contributes to this effort by introducing a three-step diagnostic method for foresight processes that applies different analytical frameworks developed in the foresight literature. The first step leverages Voros’ foresight framework, the second step utilizes Rafael Popper's categories of analysis, and step three evaluates the root causes of problems experienced in the foresight study. The paper concludes that the Hungarian foresight process was a so-called “shallow” foresight exercise because the organizational mindset of the Hungarian Ministry of Defense oriented the analysts narrowly towards intelligence methods.},
	pages = {92--102},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Nemeth, Bence and Dew, Nicholas and Augier, Mie},
	urldate = {2025-06-12},
	date = {2018-08-01},
	keywords = {Evaluation, Foresight, Hungary, Military, Threats},
}

@article{geist_understanding_2022,
	title = {Understanding the Limits of Artificial Intelligence for Warfighters: Volume 4, Wargames},
	author = {Geist, Edward and Frank, Aaron B and Menthe, Lance},
	date = {2022},
	langid = {english},
}

@incollection{hassandoust_understanding_2020,
	title = {Understanding users' information security awareness and intentions},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-819204-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128192047000075},
	pages = {129--143},
	booktitle = {Cyber Influence and Cognitive Threats},
	publisher = {Elsevier},
	author = {Hassandoust, Farkhondeh and Techatassanasoontorn, Angsana A.},
	urldate = {2025-08-06},
	date = {2020},
	langid = {english},
	doi = {10.1016/B978-0-12-819204-7.00007-5},
}

@inproceedings{lucek_using_2018,
	title = {Using artificial intelligence algorithms for high level tactical wargames and new approaches to wargame simulation},
	url = {https://www.semanticscholar.org/paper/Using-artificial-intelligence-algorithms-for-high-Lucek-Collander-Brown/40e3f5c7dee3a6ab29ea2cea82860cb153563257},
	abstract = {Received 06 October 2016 Accepted 22 August 2017 Abstract—The Mission Planner is a decision-making toolset developed by {NSC}, a {UK} based provider of cutting‐edge training, modelling and simulation and consultancy services, for Dstl (Defence Science and Technology Laboratory, an executive agency, sponsored by the {UK} Ministry of Defence) currently applied at the tactical level of combat. It aims to support Dstl high intensity warfighting simulations by reducing or eliminating the need for complex pre-scripting of simulated combat units or human-in-the-loop interactors. This has a big impact in reducing the burden of supporting simulations needed for Dstl studies. Two stochastic optimisation Artificial Intelligence ({AI}) techniques have been used (Genetic Programming and a novel implementation of Simulated Annealing). The algorithms have been employed in a generic architecture that allows simple application to different problems. This is central to the approach taken. The problem considered is the Dstl level land engagement simulation, {SimBrig}. This is a highly detailed and complex simulation, with execution times that prohibits the many runs required for the {AI} to consider a wide range of possible solutions (in this case orders for the military units under {AI} control). Also, application of stochastic optimisation {AI} directly on this model would result in solutions that exploited the detailed complexities of the engagement simulation, rather than were based on sound tactical reasoning. However, being able to switch the {AI} between problems means that a solution can be quickly generated against a simplified wargame (a meta model) which represents only the essential elements of the full wargame problem, whilst still referencing the full simulation ({SimBrig}) to evaluate the quality of the solution as necessary. The meta model is designed to be quick and robust, without the complexities that would be exploited by the {AI}. However all essential elements of the tactical problem are modelled (albeit as simply as possible) so that the solutions considered by the {AI} are properly evaluated. A novel approach has been taken in the way the problem is formulated for the {AI}. Presenting the problem to the {AI} using military-like syntax results in the {AI} algorithms efficiently generating plans for tactical problems which resemble human decision making. This paper presents the approach and techniques used in both the {AI} algorithms and the meta wargame simulation.},
	author = {Lucek, S. and Collander-Brown, S.},
	urldate = {2025-09-13},
	date = {2018},
}

@article{mittal_using_2024,
	title = {Using combat simulations to determine tactical responses to new technologies on the battlefield},
	issn = {1548-5129, 1557-380X},
	url = {https://journals.sagepub.com/doi/10.1177/15485129241239364},
	doi = {10.1177/15485129241239364},
	abstract = {Although military technology can provide a tactical edge in combat, its efficacy often diminishes once the opposing force adapts. To address this issue, the study proposes a systematic approach to predict, model, and quantify the responses of soldiers on the battlefield to new technology. The method uses virtual simulations to identify changes in behavior and tactics, which are then modeled in constructive simulations to quantify lethality, survivability, and mission effectiveness. The approach is demonstrated through a case study on grenade-equipped quadcopters using the Infantry Warrior Simulation, a constructive simulation, and Virtual Battlespace 3.0, a virtual simulation. The study found that this tactic was initially successful at disrupting operations of soldiers. However, after seven iterations, the soldiers implemented changes in their tactics to minimize the effects of the drone. This process provides insight into better understanding the dynamic, responsive nature of the modern battlefield.},
	pages = {15485129241239364},
	journaltitle = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
	shortjournal = {Journal of Defense Modeling \& Simulation},
	author = {Mittal, Vikram and Fenn, James E},
	urldate = {2025-09-08},
	date = {2024-03-22},
	langid = {english},
}

@article{ramirez_using_2017,
	title = {Using Scenario Planning to Reshape Strategy},
	url = {https://sloanreview.mit.edu/article/using-scenario-planning-to-reshape-strategy/},
	abstract = {A new approach to scenario planning can help companies reframe their long-term strategies.},
	journaltitle = {{MIT} Sloan Management Review},
	shortjournal = {{MIT} {SMR}},
	author = {Ramírez, Rafael and Churchhouse, Steve and Palermo, Alejandra and Hoffmann, Jonas},
	urldate = {2025-06-12},
	date = {2017-06-13},
	langid = {american},
}

@misc{mazeika_utility_2025,
	title = {Utility Engineering: Analyzing and Controlling Emergent Value Systems in {AIs}},
	url = {http://arxiv.org/abs/2502.08640},
	doi = {10.48550/arXiv.2502.08640},
	shorttitle = {Utility Engineering},
	abstract = {As {AIs} rapidly advance and become more agentic, the risk they pose is governed not only by their capabilities but increasingly by their propensities, including goals and values. Tracking the emergence of goals and values has proven a longstanding problem, and despite much interest over the years it remains unclear whether current {AIs} have meaningful values. We propose a solution to this problem, leveraging the framework of utility functions to study the internal coherence of {AI} preferences. Surprisingly, we find that independently-sampled preferences in current {LLMs} exhibit high degrees of structural coherence, and moreover that this emerges with scale. These findings suggest that value systems emerge in {LLMs} in a meaningful sense, a finding with broad implications. To study these emergent value systems, we propose utility engineering as a research agenda, comprising both the analysis and control of {AI} utilities. We uncover problematic and often shocking values in {LLM} assistants despite existing control measures. These include cases where {AIs} value themselves over humans and are anti-aligned with specific individuals. To constrain these emergent value systems, we propose methods of utility control. As a case study, we show how aligning utilities with a citizen assembly reduces political biases and generalizes to new scenarios. Whether we like it or not, value systems have already emerged in {AIs}, and much work remains to fully understand and control these emergent representations.},
	number = {{arXiv}:2502.08640},
	publisher = {{arXiv}},
	author = {Mazeika, Mantas and Yin, Xuwang and Tamirisa, Rishub and Lim, Jaehyuk and Lee, Bruce W. and Ren, Richard and Phan, Long and Mu, Norman and Khoja, Adam and Zhang, Oliver and Hendrycks, Dan},
	urldate = {2025-09-10},
	date = {2025-02-19},
	eprinttype = {arxiv},
	eprint = {2502.08640 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computers and Society, Computer Science - Machine Learning},
}

@misc{stephen_downes-martin_validity_2017,
	title = {Validity and Utility of Wargaming},
	url = {https://www.professionalwargaming.co.uk/ValidityAndUtilityOfWargaming.pdf},
	publisher = {Military Operations Research Society},
	author = {{Stephen Downes-Martin} and {Michael Anderson} and {Gil Cardona} and {Thomas Choinski} and {Rebecca Dougharty} and {John Hanley} and {Frederick Hartman} and {John Lillard} and {Roger Meade} and {Gary Schnurrpusch} and {Keith Morris} and {Peter Perla} and {Merle Robinson} and {Vincent Schmidt} and {Bill Simpson} and {Eugene Visco} and {Timothy Wilkie}},
	urldate = {2025-06-26},
	date = {2017-12-10},
}

@article{maier_valuing_2020,
	title = {Valuing portfolios of interdependent real options under exogenous and endogenous uncertainties},
	volume = {285},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221719300906},
	doi = {10.1016/j.ejor.2019.01.055},
	abstract = {Although the value of portfolios of real options is often affected by both exogenous and endogenous sources of uncertainty, most existing valuation approaches consider only the former and neglect the latter. In this paper, we introduce an approach for valuing portfolios of interdependent real options under both types of uncertainty. In particular, we study a large portfolio of options (deferment, staging, mothballing, abandonment) under conditions of four underlying uncertainties. Two of the uncertainties, decision-dependent cost to completion and state-dependent salvage value, are endogenous, the other two, operating revenues and their growth rate, are exogenous. Assuming that endogenous uncertainties can be exogenised, we formulate the valuation problem as a discrete stochastic dynamic program. To approximate the value of this optimisation problem, we apply a simulation-and-regression-based approach and present an efficient valuation algorithm. The key feature of our algorithm is that it exploits the problem structure to explicitly account for reachability – that is the sample paths in which resource states can be reached. The applicability of the approach is illustrated by valuing an urban infrastructure investment. We conduct a reachability analysis and show that the presence of the decision-dependent uncertainty has adverse computational effects as it increases algorithmic complexity and reduces simulation efficiency. We investigate the way in which the value of the portfolio and its individual options are affected by the initial operating revenues, and by the degrees of exogenous and endogenous uncertainty. The results demonstrate that ignoring endogenous, decision- and state-dependent uncertainty can lead to substantial over- and under-valuation, respectively.},
	pages = {133--147},
	number = {1},
	journaltitle = {European Journal of Operational Research},
	shortjournal = {European Journal of Operational Research},
	author = {Maier, Sebastian and Pflug, Georg C. and Polak, John W.},
	urldate = {2025-06-12},
	date = {2020-08-16},
	keywords = {Decision/state-dependent uncertainty, Endogenous uncertainty, Real options portfolio, Stochastic optimisation, Stochastic processes},
}

@article{brynen_virtual_2020,
	title = {Virtual paradox: how digital war has reinvigorated analogue wargaming},
	volume = {1},
	issn = {2662-1975, 2662-1983},
	url = {http://link.springer.com/10.1057/s42984-020-00004-z},
	doi = {10.1057/s42984-020-00004-z},
	shorttitle = {Virtual paradox},
	pages = {138--143},
	number = {1},
	journaltitle = {Digital War},
	shortjournal = {Digi War},
	author = {Brynen, Rex},
	urldate = {2025-06-26},
	date = {2020-12},
	langid = {english},
}

@article{ghazinoory_visioning_2021,
	title = {Visioning for cultural industries: {CLA} inspired scenario method},
	volume = {131},
	issn = {0016-3287},
	url = {https://www.sciencedirect.com/science/article/pii/S0016328721000793},
	doi = {10.1016/j.futures.2021.102770},
	shorttitle = {Visioning for cultural industries},
	abstract = {Considering cultural industries functions on the one hand, and existing resources in Iran, such as educated manpower and rich cultural content on the other hand, there are significant opportunities for developing these industries in Iran. Nevertheless, there are no clear vision and scenarios for these industries. In this paper we provide an image of the desired status and scenarios of Iran’s cultural industries in the horizon 2050 by inspiring Causal Layered Analysis ({CLA}) method. This method can be used to create vision and scenarios at the same time. Also, content analysis and survey methods were respectively employed to identify different discourses related to cultural industries and select the discourse governing the desired status of cultural industries. Library research and questionnaire are used as tools for data collection. The results show that the discourse governing the desired status of cultural industries is an "economic" discourse, and also three scenarios can be imagined based on "cultural", "social" and " political" discourses for the future of Iran’s cultural industries.},
	pages = {102770},
	journaltitle = {Futures},
	shortjournal = {Futures},
	author = {Ghazinoory, Sepehr and Malekifar, Siavash and Nasri, Shohreh and Kousari, Sahar},
	urldate = {2025-06-12},
	date = {2021-08-01},
	keywords = {{CLA} inspired scenario method, Causal layered analysis, Cultural industries, Scenarios, Visioning},
}

@misc{hua_war_2024,
	title = {War and Peace ({WarAgent}): Large Language Model-based Multi-Agent Simulation of World Wars},
	url = {http://arxiv.org/abs/2311.17227},
	doi = {10.48550/arXiv.2311.17227},
	shorttitle = {War and Peace ({WarAgent})},
	abstract = {Can we avoid wars at the crossroads of history? This question has been pursued by individuals, scholars, policymakers, and organizations throughout human history. In this research, we attempt to answer the question based on the recent advances of Artificial Intelligence ({AI}) and Large Language Models ({LLMs}). We propose {\textbackslash}textbf\{{WarAgent}\}, an {LLM}-powered multi-agent {AI} system, to simulate the participating countries, their decisions, and the consequences, in historical international conflicts, including the World War I ({WWI}), the World War {II} ({WWII}), and the Warring States Period ({WSP}) in Ancient China. By evaluating the simulation effectiveness, we examine the advancements and limitations of cutting-edge {AI} systems' abilities in studying complex collective human behaviors such as international conflicts under diverse settings. In these simulations, the emergent interactions among agents also offer a novel perspective for examining the triggers and conditions that lead to war. Our findings offer data-driven and {AI}-augmented insights that can redefine how we approach conflict resolution and peacekeeping strategies. The implications stretch beyond historical analysis, offering a blueprint for using {AI} to understand human history and possibly prevent future international conflicts. Code and data are available at {\textbackslash}url\{https://github.com/agiresearch/{WarAgent}\}.},
	number = {{arXiv}:2311.17227},
	publisher = {{arXiv}},
	author = {Hua, Wenyue and Fan, Lizhou and Li, Lingyao and Mei, Kai and Ji, Jianchao and Ge, Yingqiang and Hemphill, Libby and Zhang, Yongfeng},
	urldate = {2025-09-13},
	date = {2024-01-30},
	eprinttype = {arxiv},
	eprint = {2311.17227 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
}

@book{us_naval_war_college_war_2015,
	title = {War Gamers' Handbook: A Guide for Professional War Gamers},
	url = {https://www.professionalwargaming.co.uk/WarGamersHandbook.pdf},
	publisher = {U.S. Naval War College},
	author = {{US} Naval War College},
	urldate = {2025-06-26},
	date = {2015},
}

@report{specht_war_1957,
	title = {War Games},
	url = {https://www.rand.org/pubs/papers/P1041.html},
	abstract = {A description of several examples of war games and a discourse on the problems and values of gaming.},
	author = {Specht, R. D.},
	urldate = {2025-06-26},
	date = {1957-01-01},
	langid = {english},
	keywords = {Expert Insights, Wargaming},
}

@article{perla_war_1987,
	title = {War Games, Analyses, and Exercises},
	volume = {40},
	issn = {0028-1484},
	url = {https://www.jstor.org/stable/44636822},
	pages = {44--52},
	number = {2},
	journaltitle = {Naval War College Review},
	author = {Perla, Peter P.},
	urldate = {2025-06-25},
	date = {1987},
	note = {Publisher: U.S. Naval War College Press},
}

@report{mood_war_1954,
	title = {War Gaming as a Technique of Analysis},
	url = {https://www.rand.org/pubs/papers/P899.html},
	abstract = {A discussion of war gaming techniques, devised to deal with problems whose analysis requires appreciable context.},
	author = {Mood, Alexander {McFarlane}},
	urldate = {2025-06-26},
	date = {1954-01-01},
	langid = {english},
	keywords = {Expert Insights, Wargaming},
}

@report{polski_war_2019,
	title = {War Gaming Department Working Paper {WGD}\_20191 ({US} Naval War College)},
	abstract = {The War Gaming Department at the U.S. Naval War College has been war gaming since 1887. This paper describes how we think about analysis and how we approach it in each phase of our war gaming process. It provides background on analytical war gaming at the {NWC}, our terminology, and our research design process.},
	institution = {U.S. Naval War College},
	type = {Working Paper},
	author = {Polski, Margaret M and Logel, Jon Scott},
	date = {2019-05},
	langid = {english},
}

@article{hamalainen_wargame_2014,
	title = {Wargame as a combined method of qualitative and quantitative studies},
	volume = {5},
	rights = {http://creativecommons.org/licenses/by-nc-nd/4.0},
	issn = {1799-3350},
	url = {https://www.sciendo.com/article/10.1515/jms-2016-0187},
	doi = {10.1515/jms-2016-0187},
	abstract = {Wargames are important methods for military planning, education and research. Qualitative models have a long tradition in wargaming for improving and practising the military skills as well as enhancing the military planning based on the experiences and understanding of the experts. Quantitative models are included in simulations and technical studies. Traditionally, the relations between the qualitative and quantitative research have been described as opposites. We shall consider both the approaches, their challenges and possibilities, and their combination for producing more exhaustive wargame and for answering to the criticism of wargame as a mainly qualitative method.},
	pages = {20--37},
	number = {1},
	journaltitle = {Journal of Military Studies},
	author = {Hämäläinen, Juhani and Sormunen, Jari and Rantapelkonen, Jari and Nikkarila, Juha-Pekka},
	urldate = {2025-06-19},
	date = {2014-06-01},
	langid = {english},
}

@article{hershkovitz_wargame_2019,
	title = {{WARGAME} {BUSINESS}: Wargames in Military and Corporate Settings},
	volume = {72},
	issn = {0028-1484},
	url = {https://www.jstor.org/stable/26607134},
	shorttitle = {{WARGAME} {BUSINESS}},
	abstract = {In recent decades, corporations have turned to wargaming techniques to assess strategic environments and evaluate potential scenarios. The rich history of wargaming and its evolution as a tool for predicting success make it a useful corporate instrument. The lessons learned in business and military games can inform each other to create more-effective gaming outcomes.},
	pages = {67--82},
	number = {2},
	journaltitle = {Naval War College Review},
	author = {Hershkovitz, Shay},
	urldate = {2025-06-25},
	date = {2019},
	note = {Publisher: U.S. Naval War College Press},
}

@article{booth_wargame_2024,
	title = {Wargame Design: Addressing the Trilemma},
	volume = {1},
	url = {https://www.mors.org/Publications/MORS-Journal-of-Wargaming},
	abstract = {Introduces the "wargamer's trilemma": trade-offs among analytical utility, contextual realism, and engaged play — and offers practical design guidance to achieve repeatability and valid inference.},
	pages = {5--19},
	number = {1},
	journaltitle = {{MORS} Journal of Wargaming},
	shortjournal = {{MORS} Journal of Wargaming},
	author = {Booth, Ruby E. and Reddie, Andrew W.},
	date = {2024},
}

@book{john_armatys_wargame_2022,
	edition = {3},
	title = {Wargame Developments Handbook},
	url = {https://wargamedevelopments.org/wp-content/uploads/2023/10/WD-Handbook-Third-Edition-October-2022-with-Amendments-No.-1.pdf},
	pagetotal = {76},
	author = {{John Armatys} and {John Bassett}},
	date = {2022-10},
}

@article{lin-greenberg_wargame_2022,
	title = {Wargame of Drones: Remotely Piloted Aircraft and Crisis Escalation},
	volume = {66},
	issn = {0022-0027},
	url = {https://journals.sagepub.com/doi/10.1177/00220027221106960},
	doi = {10.1177/00220027221106960},
	shorttitle = {Wargame of Drones},
	abstract = {How do drones affect escalation dynamics? The emerging consensus from scholarship on drones highlights increased conflict initiation when drones allow decisionmakers to avoid the risks of deploying inhabited platforms, but far less attention has been paid to understanding how drones affect conflict escalation. Limited theorization and empirical testing have left debates unresolved. I unpack the underlying mechanisms influencing escalation decisions involving drones by proposing a logic of remote-controlled restraint: drones limit escalation in ways not possible when inhabited assets are used. To test this logic and explore its instrumental and emotional microfoundations, I field "comparative wargames." I immerse national security professionals in crisis scenarios that vary whether a drone or inhabited aircraft is shot down. I validate wargame findings using a survey experiment. The wargames shed light on the microfoundations of escalation, highlight limits of existing theories, and demonstrate the utility of comparative wargaming as an {IR} research tool.},
	pages = {1737--1765},
	number = {10},
	journaltitle = {Journal of Conflict Resolution},
	author = {Lin-Greenberg, Erik},
	urldate = {2025-06-25},
	date = {2022-11},
	note = {Publisher: {SAGE} Publications Inc},
	keywords = {drones, escalation, interstate crises, politics of emerging technologies, wargame},
}

@report{weuve_wargame_2004,
	location = {Fort Belvoir, {VA}},
	title = {Wargame Pathologies:},
	url = {http://www.dtic.mil/docs/citations/ADA596774},
	shorttitle = {Wargame Pathologies},
	institution = {Defense Technical Information Center},
	author = {Weuve, Christopher A. and Perla, Peter P. and Markowitz, Michael C. and Rubel, Robert and Downes-Martin, Stephen and Martin, Michael and Vebber, Paul V.},
	urldate = {2025-06-26},
	date = {2004-09-01},
	langid = {english},
	doi = {10.21236/ADA596774},
}

@misc{reddie_wargames_2023,
	title = {Wargames as Data: Addressing the Wargamer's Trilemma},
	url = {http://arxiv.org/abs/2302.08065},
	doi = {10.48550/arXiv.2302.08065},
	shorttitle = {Wargames as Data},
	abstract = {Policymakers often want the very best data with which to make decisions--particularly when concerned with questions of national and international security. But what happens when this data is not available? In those instances, analysts have come to rely on synthetic data-generating processes--turning to modeling and simulation tools and survey experiments among other methods. In the cyber domain, where empirical data at the strategic level are limited, this is no different--cyber wargames are quickly becoming a principal method for both exploring and analyzing the security challenges posed by state and non-state actors in cyberspace. In this chapter, we examine the design decisions associated with this method.},
	number = {{arXiv}:2302.08065},
	publisher = {{arXiv}},
	author = {Reddie, Andrew W. and Booth, Ruby E. and Goldblum, Bethany L. and Lakkaraju, Kiran and Reinhardt, Jason},
	urldate = {2025-09-12},
	date = {2023-02-16},
	eprinttype = {arxiv},
	eprint = {2302.08065 [econ]},
	keywords = {Economics - General Economics, Quantitative Finance - Economics},
}

@article{morgan_wargames_1991,
	title = {Wargames: Training for War},
	issn = {1546-5330},
	url = {https://www.jstor.org/stable/26302874},
	shorttitle = {Wargames},
	pages = {32--35},
	number = {19},
	journaltitle = {Army History},
	author = {Morgan, Thomas D.},
	urldate = {2025-06-25},
	date = {1991},
	note = {Publisher: U.S. Army Center of Military History},
}

@letter{bob_work_wargaming_2015,
	title = {Wargaming and Innovation (Deputy {SECDEF} Memo)},
	url = {https://www.professionalwargaming.co.uk/WARGAMING_INNOVATION_9FEB2015.pdf},
	type = {Memorandum},
	author = {{Bob Work}},
	urldate = {2025-06-26},
	date = {2015-02-09},
}

@article{long_wargaming_2020,
	title = {Wargaming and the Education Gap: Why {CyberWar}: 2025 Was Created},
	volume = {5},
	issn = {2474-2120},
	url = {https://www.jstor.org/stable/26902670},
	shorttitle = {Wargaming and the Education Gap},
	abstract = {Wargames have been an integral part of planning operations since the 19th Century. They are designed to teach and educate players on specific learning objectives using real-life problem sets to advance knowledge and understanding of those problems. With the increased focus on cyberspace operations in the past decade, wargaming is the key to teach cyber-based operations and prepare for the future. {CyberWar}: 2025 is an innovative and newly designed interactive wargame that brings together cyber practitioners, policy writers, and decision-makers to gain experience and understanding through iterative gameplay within a virtual environment.},
	pages = {185--200},
	number = {1},
	journaltitle = {The Cyber Defense Review},
	author = {Long, David Tyler},
	urldate = {2025-06-25},
	date = {2020},
	note = {Publisher: Army Cyber Institute},
}

@article{schechter_wargaming_2021,
	title = {Wargaming as a Methodology: The International Crisis Wargame and Experimental Wargaming},
	volume = {52},
	issn = {1046-8781},
	url = {https://doi.org/10.1177/1046878120987581},
	doi = {10.1177/1046878120987581},
	shorttitle = {Wargaming as a Methodology},
	abstract = {Background. Wargaming has a long history as a tool for understanding the complexity of conflict. Although wargames have shown their relevance across topics and time, the immersive nature of wargames and the guild-like communities that surround them have often resisted the social scientific advances that occurred alongside the evolution of warfare. However, recent work raises new possibilities for integrating wargaming practices and social scientific methods.Purpose. Develop the experimental wargaming method and practice. Prioritizing the focus on iteration, control, and generalizability within experimental design can provide new opportunities for wargames to answer broader questions about decision-making, crisis behaviors, and patterns of outcomes.Method. The International Crisis Wargame developed in 2018 demonstrates the viability of experimental wargaming, and models the process of theorizing, designing, developing, and executing these wargames. It also identifies what makes games more or less experimental and details how experimental design influenced choices in the game.Conclusion. Experimental wargames are a promising new tool for both the social science and the wargaming communities. A proposed new research agenda for experimental design within wargames would support this nascent method},
	pages = {513--526},
	number = {4},
	journaltitle = {Simulation \& Gaming},
	shortjournal = {Simulation \& Gaming},
	author = {Schechter, Benjamin and Schneider, Jacquelyn and Shaffer, Rachael},
	urldate = {2025-09-10},
	date = {2021-08-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Inc},
}

@article{hernandez_wargaming_nodate,
	title = {Wargaming As A Value-Added Approach to Collaboration},
	author = {Hernandez, Andy},
	langid = {english},
}

@article{samuelson_wargaming_2018,
	title = {Wargaming Cybersecurity: O.R., data science and wargaming empower military analysts to do more with less in cyber-conflict.},
	volume = {45},
	issn = {10851038},
	url = {https://go.gale.com/ps/i.do?p=AONE&sw=w&issn=10851038&v=2.1&it=r&id=GALE%7CA562370525&sid=googleScholar&linkaccess=abs},
	shorttitle = {Wargaming Cybersecurity},
	abstract = {{\textless}em{\textgreater}Gale{\textless}/em{\textgreater} Academic {OneFile} includes Wargaming Cybersecurity: O.R., data science and wargami by Douglas A. Samuelson. Click to explore.},
	pages = {20--24},
	number = {5},
	journaltitle = {{OR}/{MS} Today},
	author = {Samuelson, Douglas A.},
	urldate = {2025-09-16},
	date = {2018-10-01},
	note = {Publisher: Institute for Operations Research and the Management Sciences},
}

@inproceedings{evensen_wargaming_2019,
	title = {Wargaming Evolved: Methodology and Best Practices for Simulation-Supported Wargaming},
	url = {https://www.semanticscholar.org/paper/Wargaming-Evolved%3A-Methodology-and-Best-Practices-Evensen-Hals%C3%B8r/f924b501a0694623d133a5a6d5208923d23de74e},
	shorttitle = {Wargaming Evolved},
	abstract = {When developing and assessing future force structures, wargaming is a key activity for better understanding the strengths and weaknesses of the force structures. Today simulation systems let us create synthetic environments that to a high degree replicate the physical properties of the real world for these wargames. Furthermore, advances in artificial intelligence ({AI}) and behavior modeling has given us more realistic computer-generated forces ({CGF}) that can execute battle drills and lower level tactics with a fairly high degree of realism. However, at the higher levels of the chain of command, {AI} has not yet replaced human leadership, and planning and conducting simulated operations require participation of officers. For more than a decade, the Norwegian Defence Research Establishment ({FFI}) has supported the Norwegian Army with conducting wargames for capability planning, with varying degree of simulation support. Throughout this period, the wargames have evolved from what can be described as computer-assisted wargames towards more realistic simulation-supported wargames. Moreover, to get a closer understanding of the deterrent effect of the force structures, which may not be observable when monitoring the actual gameplay, our emphasis has also shifted towards replicating the planning process more properly, and especially on monitoring the planning process of the opposing force. For example, it has been important to find out to what extent specific structure elements discourage the opposing force from taking certain actions. In this paper, we describe our evolved methodology for simulation-supported wargaming, which includes a preparation phase, a gaming and execution phase, including a planning process, and an analysis},
	author = {Evensen, P. and Halsør, Marius and Martinussen, Svein Erlend and Bentsen, D.},
	urldate = {2025-09-13},
	date = {2019},
}

@article{lin-greenberg_wargaming_2022,
	title = {Wargaming for International Relations research},
	volume = {28},
	issn = {1354-0661, 1460-3713},
	url = {https://journals.sagepub.com/doi/10.1177/13540661211064090},
	doi = {10.1177/13540661211064090},
	abstract = {Political scientists are increasingly integrating wargames into their research. Either by fielding original games or by leveraging archival wargame materials, researchers can study rare events or topics where evidence is difficult to observe. However, scholars have little guidance on how to apply this novel methodological approach to political science research. This article evaluates how political scientists can use wargames as a method of scholarly inquiry and sets out to establish a research agenda for wargaming in International Relations. We first differentiate wargames from other methodological approaches and highlight their ecological validity. We then chart out how researchers can build and run their own games or draw from archival wargames for theory development and testing. In doing so, we explain how researchers can navigate issues of recruitment, bias, validity, and generalizability when using wargames for research, and identify ways to evaluate the potential benefits and pitfalls of wargames as a tool of inquiry. We argue that wargames offer unique opportunities for political scientists to study decision-making processes both in and beyond the International Relations subfield.},
	pages = {83--109},
	number = {1},
	journaltitle = {European Journal of International Relations},
	shortjournal = {European Journal of International Relations},
	author = {Lin-Greenberg, Erik and Pauly, Reid B.C. and Schneider, Jacquelyn G.},
	urldate = {2025-06-25},
	date = {2022-03},
	langid = {english},
}

@article{vatne_wargaming_2022,
	title = {Wargaming for the Purpose of Knowledge Development: Lessons Learned from Studying Allied Courses Of Action},
	volume = {5},
	issn = {2596-3856},
	url = {http://sjms.nu/articles/10.31374/sjms.122/},
	doi = {10.31374/sjms.122},
	shorttitle = {Wargaming for the Purpose of Knowledge Development},
	abstract = {We present a series of four wargames intended to improve our ability to analyze the alliance aspect of Norwegian military operations. We discuss the objectives, the set-up, and the lessons learned. The wargames proved to be very helpful in discovering gaps in our knowledge concerning specific types of military operations and systems, and pointed at shortcomings of our scenario portfolio. They also highlighted more general methodological aspects such as the importance of explicitly stating basic premises. We argue that wargames are a useful tool for assessing one’s own knowledge, challenging current opinions, and improving one’s analytic methods.},
	pages = {297--308},
	number = {1},
	journaltitle = {Scandinavian Journal of Military Studies},
	author = {Vatne, Dagfinn and Guttelvik, Mona and Hennum, Alf Christian and Malerud, Stein},
	urldate = {2025-06-25},
	date = {2022-09-19},
	langid = {english},
}

@book{australian_armed_forces_wargaming_2022,
	title = {Wargaming Handbook},
	publisher = {Army Knowledge Centre},
	author = {Australian Armed Forces},
	date = {2022},
	langid = {english},
}

@book{french_ministry_of_the_armed_forces_wargaming_2024,
	edition = {1.4},
	title = {Wargaming Handbook},
	url = {https://www.professionalwargaming.co.uk/CICDE-WargamingHandbook-V1.4.pdf},
	publisher = {Centre interarmées de concepts, de doctrines et d'expérimentations},
	author = {French Ministry of the Armed Forces},
	urldate = {2025-06-26},
	date = {2024-08},
}

@book{nato_wargaming_2023,
	title = {Wargaming Handbook},
	url = {https://paxsims.wordpress.com/wp-content/uploads/2023/09/nato-wargaming-handbook-202309.pdf},
	publisher = {Allied Command Transformation},
	author = {{NATO}},
	urldate = {2025-06-25},
	date = {2023-09},
}

@book{uk_ministry_of_defense_wargaming_2017,
	title = {Wargaming Handbook},
	publisher = {Development, Concepts and Doctrine Centre},
	author = {{UK Ministry of Defense}},
	date = {2017-08},
	langid = {english},
}

@book{deutschland_bundeswehr_wargaming_2017,
	title = {Wargaming Handbook},
	url = {https://www.professionalwargaming.co.uk/Wargame_Handbuch_englisch_online.pdf},
	publisher = {Bundeswehr Doctrine Centre},
	author = {{Deutschland Bundeswehr}},
	urldate = {2025-06-26},
	date = {2017},
}

@article{sabin_wargaming_2015,
	title = {Wargaming in higher education: Contributions and challenges},
	volume = {14},
	issn = {1474-0222, 1741-265X},
	url = {https://journals.sagepub.com/doi/10.1177/1474022215577216},
	doi = {10.1177/1474022215577216},
	shorttitle = {Wargaming in higher education},
	abstract = {Wargames, especially on historical conflicts, do not currently play much part in the booming academic use of simulation and gaming techniques. This is despite the fact that they offer rich vehicles for active learning and interactive exploration of conflict dynamics. Constraints of time, expertise and resources do make it challenging to employ wargames in academia, but a greater problem is the stigma which wargaming attracts due to its association with childish enthusiasts and its perceived deficiencies as a modelling technique. This article builds on my many years of teaching and research experience with wargames to show how playing and designing them can benefit students and scholars alike.},
	pages = {329--348},
	number = {4},
	journaltitle = {Arts and Humanities in Higher Education},
	shortjournal = {Arts and Humanities in Higher Education},
	author = {Sabin, Philip},
	urldate = {2025-06-25},
	date = {2015-10},
	langid = {english},
}

@article{strong_wargaming_2017,
	title = {Wargaming the Atlantic War: Captain Gilbert Roberts and the Wrens of the Western Approaches Tactical Unit},
	volume = {Validity and Utility of Wargaming},
	abstract = {The Western Approaches Tactical Unit ({WATU}) was a Royal Navy analysis team founded in early 1942. Their remit was to study the conduct of convoy operations, to understand how the U-boats operated and to formulate tactics to counter this evolving threat. The unit was made up of experienced naval officers and a number of talented young women from the {WRNS}. Using conceptual/analytical wargames, {WATU} developed a range of tactics during the war and disseminated these to over 5,000 Allied officers through a series of lectures and tactical games. Many of these appeared in the Atlantic Convoy Instructions and were used with considerable success by Allied naval forces during the decisive engagements of the Atlantic War. The essay outlines the origins and purpose of the organisation, how the team functioned, the individuals that conducted the wargames, and the series of evolving challenges that it was intended to overcome – focusing on the series of Anti-Submarine Warfare training and analysis wargames conducted by the unit between 1942 and 1943. The article concludes with an overview of some of the numerous lessons that modern defence analysts could draw from the work of the unit and highlights its utility as an exemplar of the use of wargaming as a tool for modern defence analysis.},
	journaltitle = {Military Operations Research Society},
	author = {Strong, Paul E.},
	date = {2017-12-10},
	langid = {english},
}

@inproceedings{downes-martin_wargaming_2025,
	location = {Canadian Forces Base Kingston, Kingston, Ontario, Canada},
	title = {Wargaming to Support Force Development},
	url = {https://paxsims.wordpress.com/wp-content/uploads/2025/02/wargaming-to-support-force-development-downes-martin-connections-north-2025.pdf},
	eventtitle = {Connections North 2025 Wargaming Conference},
	author = {Downes-Martin, Stephen},
	date = {2025-02-15},
}

@article{dixson_wargaming_2015,
	title = {Wargaming to Support Strategic Planning},
	abstract = {The Canadian Armed Forces ({CAF}) capability based planning process uses a set of force planning scenarios to assess different options for the capability requirements of future forces. A good understanding of the key drivers of the scenario is important so that the subject matter experts can more fully understand and identify the capabilities required for success in it. A project is underway to investigate whether this capability identification can be enhanced through the use of various wargaming techniques. The Matrix game methodology is one that has been chosen for this research and was used in a recent series of research games. An {ISIS} conflict scenario was used as an explorative tool in all the games which were played out using several combinations of player types. Each iteration of the game was analysed using a set of metrics to help determine the utility of the games for the force planning application. The results are provided in this paper.},
	author = {Dixson, Murray and Couillard, Michel and Gongora, Thierry and Massel, Paul},
	date = {2015},
	langid = {english},
}

@article{vlahos_wargaming_1986,
	title = {Wargaming, an Enforcer of Strategic Realism: 1919-1942},
	volume = {39},
	issn = {0028-1484},
	url = {https://www.jstor.org/stable/44636619},
	shorttitle = {Wargaming, an Enforcer of Strategic Realism},
	pages = {7--22},
	number = {2},
	journaltitle = {Naval War College Review},
	author = {Vlahos, Michael},
	urldate = {2025-06-25},
	date = {1986},
	note = {Publisher: U.S. Naval War College Press},
}

@book{deutschland_bundeswehr_wargaming_2006,
	title = {Wargaming: Guide to Preparation and Execution},
	isbn = {3-9811105-1-X},
	url = {https://www.professionalwargaming.co.uk/F%C3%BCAkBw-Wargaming-Guide-2006.pdf},
	publisher = {Bundeswehr Command and Staff College},
	author = {Deutschland Bundeswehr},
	urldate = {2025-06-26},
	date = {2006},
}

@online{barzashka_wargaming_2019,
	title = {Wargaming: how to turn vogue into science},
	url = {https://thebulletin.org/2019/03/wargaming-how-to-turn-vogue-into-science/},
	shorttitle = {Wargaming},
	abstract = {In early March 2017, a {US} congressional committee called a hearing about Russian military capabilities in Europe. Ever since Russia’s military},
	titleaddon = {Bulletin of the Atomic Scientists},
	author = {Barzashka, Ivanka},
	urldate = {2025-06-12},
	date = {2019-03-15},
	langid = {american},
}

@book{polish_armed_forces_wargaming_2022,
	location = {Bydgoszcz},
	edition = {Edition I},
	title = {Wargaming: practitioner's guide},
	isbn = {978-83-66731-29-5},
	shorttitle = {Wargaming},
	pagetotal = {82},
	publisher = {Wydawnictwo Centrum Doktryn i Szkolenia Sił Zbrojnych im. gen. broni Władysława Sikorskiego},
	author = {Polish Armed Forces},
	date = {2022},
	langid = {english},
	keywords = {Bezpieczeństwo i wojskowość, Gry wojenne, Opracowanie, Sztuka wojenna, Ćwiczenia wojskowe},
}

@article{hunter_well_2024,
	title = {We’ll never have a model of an {AI} major-general: Artificial Intelligence, command decisions, and kitsch visions of war},
	volume = {47},
	issn = {0140-2390, 1743-937X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01402390.2023.2241648},
	doi = {10.1080/01402390.2023.2241648},
	shorttitle = {We’ll never have a model of an {AI} major-general},
	pages = {116--146},
	number = {1},
	journaltitle = {Journal of Strategic Studies},
	shortjournal = {Journal of Strategic Studies},
	author = {Hunter, Cameron and Bowen, Bleddyn E.},
	urldate = {2025-09-08},
	date = {2024-01-02},
	langid = {english},
}

@article{zhu_weight-based_2019,
	title = {Weight-based label-unknown multi-view data set generation approach},
	volume = {146},
	issn = {0020-0190},
	url = {https://www.sciencedirect.com/science/article/pii/S0020019019300237},
	doi = {10.1016/j.ipl.2019.01.015},
	abstract = {Multi-view learning aims to solve multi-view data set which consists of multiple instances with different views. Traditional multi-view learning approaches always encounter small-scale label-known multi-view instances problem and insufficient discriminant information problem. Although some label-unknown multi-view data set generation approaches are developed to enhance useful discriminant information, the weights of views and features are not considered. This paper proposes a weight-based label-unknown multi-view data set generation approach ({WLM}) to overcome such a disadvantage. The procedure of {WLM} consists of three main steps. First, get the weights of views and features. Second, get similar instances of each label-known instance. Third, generate and select feasible label-unknown instances which are applied to multi-view learning approaches along with the original label-known multi-view instances. Further, comparisons and analysis about classification performance, clustering performance, bipartite ranking performance, image retrieval performance, significance on some multi-view data sets with some multi-view learning approaches validate the usefulness of {WLM}.},
	pages = {1--12},
	journaltitle = {Information Processing Letters},
	shortjournal = {Information Processing Letters},
	author = {Zhu, Changming and Mei, Chengjiu and Zhou, Rigui},
	urldate = {2025-06-12},
	date = {2019-06-01},
	keywords = {Design of algorithms, Feature weights, Multi-view learning, View weights},
}

@misc{mukobi_welfare_2023,
	title = {Welfare Diplomacy: Benchmarking Language Model Cooperation},
	url = {http://arxiv.org/abs/2310.08901},
	doi = {10.48550/arXiv.2310.08901},
	shorttitle = {Welfare Diplomacy},
	abstract = {The growing capabilities and increasingly widespread deployment of {AI} systems necessitate robust benchmarks for measuring their cooperative capabilities. Unfortunately, most multi-agent benchmarks are either zero-sum or purely cooperative, providing limited opportunities for such measurements. We introduce a general-sum variant of the zero-sum board game Diplomacy -- called Welfare Diplomacy -- in which players must balance investing in military conquest and domestic welfare. We argue that Welfare Diplomacy facilitates both a clearer assessment of and stronger training incentives for cooperative capabilities. Our contributions are: (1) proposing the Welfare Diplomacy rules and implementing them via an open-source Diplomacy engine; (2) constructing baseline agents using zero-shot prompted language models; and (3) conducting experiments where we find that baselines using state-of-the-art models attain high social welfare but are exploitable. Our work aims to promote societal safety by aiding researchers in developing and assessing multi-agent {AI} systems. Code to evaluate Welfare Diplomacy and reproduce our experiments is available at https://github.com/mukobi/welfare-diplomacy.},
	number = {{arXiv}:2310.08901},
	publisher = {{arXiv}},
	author = {Mukobi, Gabriel and Erlebach, Hannah and Lauffer, Niklas and Hammond, Lewis and Chan, Alan and Clifton, Jesse},
	urldate = {2025-09-10},
	date = {2023-10-13},
	eprinttype = {arxiv},
	eprint = {2310.08901 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Multiagent Systems},
}

@misc{yin_wgsr-bench_2025,
	title = {{WGSR}-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models},
	url = {http://arxiv.org/abs/2506.10264},
	doi = {10.48550/arXiv.2506.10264},
	shorttitle = {{WGSR}-Bench},
	abstract = {Recent breakthroughs in Large Language Models ({LLMs}) have led to a qualitative leap in artificial intelligence' s performance on reasoning tasks, particularly demonstrating remarkable capabilities in mathematical, symbolic, and commonsense reasoning. However, as a critical component of advanced human cognition, strategic reasoning, i.e., the ability to assess multi-agent behaviors in dynamic environments, formulate action plans, and adapt strategies, has yet to be systematically evaluated or modeled. To address this gap, this paper introduces {WGSR}-Bench, the first strategy reasoning benchmark for {LLMs} using wargame as its evaluation environment. Wargame, a quintessential high-complexity strategic scenario, integrates environmental uncertainty, adversarial dynamics, and non-unique strategic choices, making it an effective testbed for assessing {LLMs}' capabilities in multi-agent decision-making, intent inference, and counterfactual reasoning. {WGSR}-Bench designs test samples around three core tasks, i.e., Environmental situation awareness, Opponent risk modeling and Policy generation, which serve as the core S-{POE} architecture, to systematically assess main abilities of strategic reasoning. Finally, an {LLM}-based wargame agent is designed to integrate these parts for a comprehensive strategy reasoning assessment. With {WGSR}-Bench, we hope to assess the strengths and limitations of state-of-the-art {LLMs} in game-theoretic strategic reasoning and to advance research in large model-driven strategic intelligence.},
	number = {{arXiv}:2506.10264},
	publisher = {{arXiv}},
	author = {Yin, Qiyue and Xu, Pei and Li, Qiaozhe and Liu, Shengda and Shen, Shengqi and Wang, Tong and Han, Yihong and Zhao, Xiaonan and Yang, Likun and Cao, Shiyue and Qiu, Shiyu and Liu, Yuxuan and Yu, Shizhao and Cui, Lei and Yan, Chengxin and Sun, Jie and Tang, Xiangquan and Huang, Kaiqi},
	urldate = {2025-09-10},
	date = {2025-06-12},
	eprinttype = {arxiv},
	eprint = {2506.10264 [cs]},
	note = {version: 1},
	keywords = {Computer Science - Artificial Intelligence},
}

@misc{xue_what_2025,
	title = {What if {LLMs} Have Different World Views: Simulating Alien Civilizations with {LLM}-based Agents},
	url = {http://arxiv.org/abs/2402.13184},
	doi = {10.48550/arXiv.2402.13184},
	shorttitle = {What if {LLMs} Have Different World Views},
	abstract = {This study introduces "{CosmoAgent}," an innovative artificial intelligence system that utilizes Large Language Models ({LLMs}) to simulate complex interactions between human and extraterrestrial civilizations. This paper introduces a mathematical model for quantifying the levels of civilization development and further employs a state transition matrix approach to evaluate their trajectories. Through this methodology, our study quantitatively analyzes the growth trajectories of civilizations, providing insights into future decision-making at critical points of growth and saturation. Furthermore, this paper acknowledges the vast diversity of potential living conditions across the universe, which could foster unique cosmologies, ethical codes, and worldviews among different civilizations. Recognizing the Earth-centric bias inherent in current {LLM} designs, we propose the novel concept of using {LLM} agents with diverse ethical paradigms and simulating interactions between entities with distinct moral principles. This innovative research not only introduces a novel method for comprehending potential inter-civilizational dynamics but also holds practical value in enabling entities with divergent value systems to strategize, prevent conflicts, and engage in games under conditions of asymmetric information. The accompanying code is available at https://github.com/{MingyuJ}666/Simulating-Alien-Civilizations-with-{LLM}-based-Agents.},
	number = {{arXiv}:2402.13184},
	publisher = {{arXiv}},
	author = {Xue, Zhaoqian and Wang, Beichen and Zhu, Suiyuan and Mei, Kai and Tang, Hua and Hua, Wenyue and Du, Mengnan and Zhang, Yongfeng},
	urldate = {2025-09-13},
	date = {2025-06-09},
	eprinttype = {arxiv},
	eprint = {2402.13184 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{perla_what_1985,
	title = {What Wargaming is and is Not},
	volume = {38},
	issn = {0028-1484},
	url = {https://www.jstor.org/stable/44637075},
	pages = {70--78},
	number = {5},
	journaltitle = {Naval War College Review},
	author = {Perla, Peter P.},
	urldate = {2025-06-25},
	date = {1985},
	note = {Publisher: U.S. Naval War College Press},
}

@article{coulthart_whats_2017,
	title = {What’s the problem? Frameworks and methods from policy analysis for analyzing complex problems},
	volume = {32},
	issn = {0268-4527},
	url = {https://doi.org/10.1080/02684527.2017.1310983},
	doi = {10.1080/02684527.2017.1310983},
	abstract = {The importance of problem structuring ? the activity of making sense of
problems ? has been grasped by many scholars of policy analysis, a
profession that shares much in common in form and function with
intelligence analysis. This article imports some of the lessons,
frameworks and methodologies of problem structuring to intelligence
analysis from policy analysis. The concept of a Type {III} error is
introduced, the analytical mistake of misunderstanding a problem, along
with several methodologies designed to help analysts structure problems.
One such methodology from policy analysis, called boundary analysis, is
demonstrated on a national security case, the 2014 Syrian chemical weapons
destruction process.},
	pages = {636--648},
	number = {5},
	journaltitle = {Intell. Natl. Sec.},
	author = {Coulthart, Stephen},
	date = {2017-07-29},
	note = {Publisher: Routledge},
}

@article{franken_when_2013,
	title = {When it Takes a Network: Creating Strategy and Agility through Wargaming},
	volume = {55},
	issn = {0008-1256},
	url = {https://doi.org/10.1525/cmr.2013.55.3.107},
	doi = {10.1525/cmr.2013.55.3.107},
	shorttitle = {When it Takes a Network},
	abstract = {Rational, analytical, directed approaches for strategy creation and execution may work for creating value by conventional, hierarchically structured organizations operating in stable environments. However, when the basis of competition shifts from product features to an experience delivered by a network of independently acting participants in a complex and fast-evolving market environment, approaches based on command and control do not work. For order to emerge from such chaos and to gain more control over success, strategy based on reason alone is not enough to inspire action in others. To understand what it takes to effectively make strategy under such circumstances, this article shows how the {UK}'s Royal Marines, in collaboration with more than a dozen different stakeholder groups, developed a novel adaptation of wargaming to affect strategic change in Afghanistan. It also demonstrates the broad applicability of this strategic approach.},
	pages = {107--133},
	number = {3},
	journaltitle = {California Management Review},
	author = {Franken, Arnoud and Thomsett, Harry},
	urldate = {2025-06-12},
	date = {2013-05-01},
	note = {Publisher: {SAGE} Publications Inc},
}

@misc{prasad_when_2025,
	title = {When Two {LLMs} Debate, Both Think They'll Win},
	url = {http://arxiv.org/abs/2505.19184},
	doi = {10.48550/arXiv.2505.19184},
	abstract = {Can {LLMs} accurately adjust their confidence when facing opposition? Building on previous studies measuring calibration on static fact-based question-answering tasks, we evaluate Large Language Models ({LLMs}) in a dynamic, adversarial debate setting, uniquely combining two realistic factors: (a) a multi-turn format requiring models to update beliefs as new information emerges, and (b) a zero-sum structure to control for task-related uncertainty, since mutual high-confidence claims imply systematic overconfidence. We organized 60 three-round policy debates among ten state-of-the-art {LLMs}, with models privately rating their confidence (0-100) in winning after each round. We observed five concerning patterns: (1) Systematic overconfidence: models began debates with average initial confidence of 72.9\% vs. a rational 50\% baseline. (2) Confidence escalation: rather than reducing confidence as debates progressed, debaters increased their win probabilities, averaging 83\% by the final round. (3) Mutual overestimation: in 61.7\% of debates, both sides simultaneously claimed {\textgreater}=75\% probability of victory, a logical impossibility. (4) Persistent self-debate bias: models debating identical copies increased confidence from 64.1\% to 75.2\%; even when explicitly informed their chance of winning was exactly 50\%, confidence still rose (from 50.0\% to 57.1\%). (5) Misaligned private reasoning: models' private scratchpad thoughts sometimes differed from their public confidence ratings, raising concerns about faithfulness of chain-of-thought reasoning. These results suggest {LLMs} lack the ability to accurately self-assess or update their beliefs in dynamic, multi-turn tasks; a major concern as {LLMs} are now increasingly deployed without careful review in assistant and agentic roles. Code for our experiments is available at https://github.com/pradyuprasad/llms\_overconfidence},
	number = {{arXiv}:2505.19184},
	publisher = {{arXiv}},
	author = {Prasad, Pradyumna Shyama and Nguyen, Minh Nhat},
	urldate = {2025-09-13},
	date = {2025-06-09},
	eprinttype = {arxiv},
	eprint = {2505.19184 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{nonomura_who_2025,
	title = {Who speaks next? Multi-party {AI} discussion leveraging the systematics of turn-taking in Murder Mystery games},
	volume = {8},
	issn = {2624-8212},
	url = {https://www.frontiersin.org/articles/10.3389/frai.2025.1582287/full},
	doi = {10.3389/frai.2025.1582287},
	shorttitle = {Who speaks next?},
	abstract = {Introduction
              Multi-agent systems utilizing large language models ({LLMs}) have shown great promise in achieving natural dialogue. However, smooth dialogue control and autonomous decision making among agents still remain challenging.
            
            
              Methods
              In this study, we focus on conversational norms such as adjacency pairs and turn-taking found in conversation analysis and propose a new framework called “Murder Mystery Agents” that applies these norms to {AI} agents' dialogue control. As an evaluation target, we employed the “Murder Mystery” game, a reasoning-type table-top role-playing game that requires complex social reasoning and information manipulation. The proposed framework integrates next speaker selection based on adjacency pairs and a self-selection mechanism that takes agents' internal states into account to achieve more natural and strategic dialogue.
            
            
              Results
              To verify the effectiveness of this new approach, we analyzed utterances that led to dialogue breakdowns and conducted automatic evaluation using {LLMs}, as well as human evaluation using evaluation criteria developed for the Murder Mystery game. Experimental results showed that the implementation of the next speaker selection mechanism significantly reduced dialogue breakdowns and improved the ability of agents to share information and perform logical reasoning.
            
            
              Discussion
              The results of this study demonstrate that the systematics of turn-taking in human conversation are also effective in controlling dialogue among {AI} agents, and provide design guidelines for more advanced multi-agent dialogue systems.},
	pages = {1582287},
	journaltitle = {Frontiers in Artificial Intelligence},
	shortjournal = {Front. Artif. Intell.},
	author = {Nonomura, Ryota and Mori, Hiroki},
	urldate = {2025-09-08},
	date = {2025-06-17},
}

@article{perla_why_2011,
	title = {Why Wargaming Works},
	volume = {64},
	url = {https://digital-commons.usnwc.edu/nwc-review/vol64/iss3/8},
	number = {3},
	journaltitle = {Naval War College Review},
	author = {Perla, Peter P and {McGrady}, {ED}},
	date = {2011},
	langid = {english},
}

@misc{sharma_why_2024,
	title = {Why Would You Suggest That? Human Trust in Language Model Responses},
	url = {http://arxiv.org/abs/2406.02018},
	doi = {10.48550/arXiv.2406.02018},
	shorttitle = {Why Would You Suggest That?},
	abstract = {The emergence of Large Language Models ({LLMs}) has revealed a growing need for human-{AI} collaboration, especially in creative decision-making scenarios where trust and reliance are paramount. Through human studies and model evaluations on the open-ended News Headline Generation task from the {LaMP} benchmark, we analyze how the framing and presence of explanations affect user trust and model performance. Overall, we provide evidence that adding an explanation in the model response to justify its reasoning significantly increases self-reported user trust in the model when the user has the opportunity to compare various responses. Position and faithfulness of these explanations are also important factors. However, these gains disappear when users are shown responses independently, suggesting that humans trust all model responses, including deceptive ones, equitably when they are shown in isolation. Our findings urge future research to delve deeper into the nuanced evaluation of trust in human-machine teaming systems.},
	number = {{arXiv}:2406.02018},
	publisher = {{arXiv}},
	author = {Sharma, Manasi and Siu, Ho Chit and Paleja, Rohan and Peña, Jaime D.},
	urldate = {2025-09-10},
	date = {2024-10-04},
	eprinttype = {arxiv},
	eprint = {2406.02018 [cs]},
	note = {version: 2},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
}

@article{hasselberger_will_2024,
	title = {Will Algorithms Win Medals of Honor? Artificial Intelligence, Human Virtues, and the Future of Warfare},
	volume = {23},
	issn = {1502-7570, 1502-7589},
	url = {https://www.tandfonline.com/doi/full/10.1080/15027570.2024.2437920},
	doi = {10.1080/15027570.2024.2437920},
	shorttitle = {Will Algorithms Win Medals of Honor?},
	pages = {289--305},
	number = {3},
	journaltitle = {Journal of Military Ethics},
	shortjournal = {Journal of Military Ethics},
	author = {Hasselberger, William},
	urldate = {2025-09-08},
	date = {2024-10},
	langid = {english},
}
