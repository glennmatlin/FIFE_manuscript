#import "../config.typ":num_papers
#import "@preview/tracl:0.6.1": *

= Wargames <sec:wargames>
== Selected Wargame Papers
#include "tables/table_wargames.typ" 

== Domains in Wargames
This section synthesizes key design principles for developing and evaluating LM-driven agents in open-ended wargames. Drawing from our comprehensive survey, we distill a set of core methodological considerations—such as turn structure, evidence requirements, human facilitation, and adjudication protocols—that influence the validity and analytical utility of language-based strategic simulations @robinson_stride_2018. We then contextualize these principles within specific domains to provide actionable guidance for researchers.

=== Military and National Security
AI offers militaries and national security establishments several new training and planning methodologies. Multiple defense organizations are actively exploring how to use AI to provide experiential learning and establish strategic advantage through superior decision-making and judgement @black_scaling_2024. 

Because wargames offer humans a simplified mental model that allows them to abstract away particulars and navigate decision-making and analyze the results @us_naval_war_college_fundamentals_1966 @us_army_war_college_strategic_2015, they have been used in education and training, particularly in military contexts @us_naval_war_college_war_2015 @deutschland_bundeswehr_wargaming_2017 @uk_ministry_of_defense_wargaming_2017 @uk_ministry_of_defense_wargaming_2017 @croatian_military_academy_introduction_2019 @australian_armed_forces_wargaming_2022 @polish_armed_forces_wargaming_2022 @us_army_how_2023 @nato_wargaming_2023 @french_ministry_of_the_armed_forces_wargaming_2024.

We have observed how both military SMEs and academic researchers are currently investigating how LMs can be used to help AI act as players and adjudicators in open-ended wargames @black_mastering_2024 @griffin_matrix_2024. This news comes at a time when the safety-critical nature of these systems is of high importance and is receiving considerable attention. However, there is not currently a resource to help bridge the understanding gap between AI researchers and SMEs for this domain. We believe that non-military scientists and academics have a major role to play in the effectiveness and alignment of AI systems, particularly those in safety-critical settings.

Finally, we have identified several examples of opportunities to infuse LMs into new and existing wargaming activities. 
At the tactical level, wargames primarily serve as individual, small unit, and command and staff training experiences. While LMs are unlikely to take to the battlefield as an opposing force, LM wargaming software could be connected with existing battle command systems to increase staff engagement during field training exercises. 
At the operational level, staff wargaming activities (i.e., to evaluate plans) could be greatly enhanced with an LM agent playing the role of the opposing forces commander, LM agent adjudicators, and LM agents that play out branches and sequels from decision points that the human players do not explore themselves. 
This LM-powered exploration of branches and sequels provides significant value for planners at the strategic level, enabling the rapid exploration of the possible to identify the probable. Stepping up from the strategic level to grand strategic, the use of LM agents to explore plans and policy outcomes could provide significant advantages to decisionmakers compared to allies, adversaries, and other parties that perhaps do not have similar capabilities.


// [battlefield/material focused wargames vs diplomacy we can leave diplomatic aspects of military wargames to next section to avoid overlap, can mention] - isaac
// At the time of writing, numerous national military and security organizations are actively exploring how they can use AI to provide experiential learning and potentially establish a strategic advantage through superior decision-making and judgment 

==== Cybersecurity
While cybersecurity is a distinct domain from military and national security, it is inherrently adversarial. Cybersecurity wargames are easily separated into technical, operational, and policy issues @samuelson_wargaming_2018.
Technical wargames test the knowledge and skills of a limited number of hands-on-keyboard operators against some type of problem, such as solving a technical problem or searching for vulnerabilities in a  system. At this level, LMs provide value as AI teammates or adversaries, or as adjudicators for inputs beyond on-network or on-system computer commands.
Operational wargames serve two audiences: technical teams and organizations, and non-technical organizations that include or work with technical teams and organizations. 
Technical teams use operational wargames as an extension of technical wargames, but with a larger group of players, longer time horizons, higher-level stakes, organizational context and impact, etc. Given the larger team size and the potential integration of skilled team members who are not on keyboard, LMs can extend the on-network narrative to include, for example, security and threat analysts, by generating digital content to represent or react to on-net activity. 
Non-technical organizations use operational cybersecurity wargames for business purposes such as testing, training, and evaluating operating procedures and incident response plans. These wargames face limitations from the challenges of generating meaningful wargame content at scale for all players. Organizations either must hire 


Technical teams use operational wargames as an extension of technical wargames on a larger scale, such as integrating hands-on operators with security and threat analysts and technical leadership, or 


=== International Relations
International Relations (IR) wargaming centers on language, signaling, and credibility rather than material force, and is used for communication, negotiation, and diplomacy. Open‑ended, argument‑driven formats (seminar, matrix) capture how positions evolve through persuasion, norm invocation, and threat–promise exchanges across multiple stakeholders (e.g., national states, non-government or industrial organizations) @mans_training_2010 @schechter_wargaming_2021 @lin-greenberg_wargaming_2022. When LMs participate, their value is in maintaining coherent narratives over long horizons, proposing plausible options under contested facts, helping surface implicit assumptions in briefs and communiqués, processing scenarios, and aiding with adjudication on non-analytical rubrics and procedures.
In a similar manner to how wargames are used extensively by the officer corps of a military, wargames are commonplace among IR professionals. Wargames present an opportunity for experiential learning for diplomatic training. Wargames are used both to support training and development, and to analyze and gain a deeper understanding of diplomatic crises that were previously unseen or extremely infrequent (i.e., nuclear crises). @hersman_under_2020 @lin-greenberg_wargaming_2022 @reddie_evidence_2023 @worman_designing_2023

Compared with military applications, diplomatic games emphasize incomplete and asymmetric information, face‑saving, issue linkage (security tied to trade, technology, or climate), and a shift away from material forces towards abstracted interests. Facilitation and adjudication must account for audience costs, domestic politics, and path dependence across rounds. LMs can assist by drafting position papers, back‑channel messages, or press releases in different registers, while humans retain control of red lines, escalation ladders, and legitimacy constraints.
Practical design choices that matter include: clear turn structure (front‑channel vs. back‑channel), explicit rules for information sharing and leaks, and rubrics that reward consistency and coalition‑building rather than only “wins.” Artifact capture (transcripts, proposals, dissent notes) is crucial for after‑action learning. Reproducibility improves when scenarios, prompts, and adjudication criteria are shared alongside model/version information.
IR professionals in particular benefit from wargaming because of its creative and non-analytical structure. With subjective rubrics and emphasis on cooperation and social interactions, innovative players and adjudications are nearly necessary and alleviate human cost from traditional executions of diplomatic wargames with human players and computers, whether it is through fully autonomous or human-aided.

=== Social Games
While wargames may contain elements of social reasoning or deception, they differ fundamentally from social deduction games in that deception is not the objective but a component of broader strategic reasoning. Wargames require agents to pursue defined goals through planning and decision-making within a structured conflict environment. In contrast, social deduction games are centered around identity discovery and psychological misdirection, making them categorically distinct. This distinction is critical for evaluating LMs in open-ended scenarios, as social deduction games test their ability to navigate dynamic, multi-agent interactions involving trust and deception @chi_amongagents_2024.

Psychological misdirection is prolific in warfare, however, and history is rife with examples of cunning tacticians using it with great success. As the Chinese military strategist Sun Tzu famously wrote, _"All warfare is based on deception,"_ exemplified by tactics like the Trojan Horse, the Empty Fort Strategy, and Hannibal’s crossing of the Alps to outmaneuver Roman forces through strategic diversions. For this literature review, social deduction games represent a complementary effort to wargames, as their focus on harnessing psychological misdirection in game scenarios can enhance LMs’ performance in real-life contexts where information may be unreliable, mislabeled, or intentionally deceptive @maggio_game_2024 @lamparth_human_2024. By studying LMs in these settings, researchers can improve their adaptability to ambiguous, deception‑heavy scenarios critical to both wargaming and broader AI applications.


=== Economics and Business
// BUSINESS CITATIONS (preserved):
// @scherpereel_decision_2005 @bradfield_origins_2005 @chussil_learning_2007 @coyne_predicting_2009
// @hamel_competing_1994 @hershkovitz_wargame_2019 @kurtz_business_2003 @oliverschwarz_ex_2011 @oliver_schwarz_ex_2011
// @resende_critical_2018 @scherpereel_changing_2005 @scherpereel_decision_2005 @scherpereel_impact_2003
// @schwarz_business_2013 @schwarz_combining_2019
In business and organizational contexts, wargaming draws on competitive strategy and scenario planning to stress‑test hypotheses under adversarial dynamics, market shifts, and policy shocks @hamel_competing_1994 @bradfield_origins_2005 @schwarz_combining_2019. Seminar‑style sessions often combine narrative role‑play (competitor, regulator, customer) with structured turns where teams propose moves (pricing, product launch, alliances) and facilitators adjudicate based on feasibility and consistency @kurtz_business_2003 @hershkovitz_wargame_2019 @coyne_predicting_2009. Unlike fully quantitative simulators, these games emphasize qualitative reasoning, internal alignment, and the articulation of assumptions @scherpereel_changing_2005 @schwarz_business_2013. When LMs participate, their value is speed and breadth in ideation (enumerating strategic options), drafting memos in given styles, and probing counterfactuals (“what would a rational competitor do if…”) @chussil_learning_2007. Because ungrounded extrapolations are a risk, prompts should enforce evidence requirements—claims cite assumptions, external signals, or benchmarks @scherpereel_decision_2005 @wheaton_making_2020. Adjudication blends simple quantitative checks (unit economics, capacity) with narrative plausibility; human facilitators keep realism and ethics in scope @oliver_schwarz_ex_2011. Empirical studies show these simulations reshape decision framing and yield measurable training gains @scherpereel_changing_2005 @scherpereel_impact_2003. For organizational adoption, reproducibility and governance are key: keep minimal artifacts (scenario text, prompts, seeds, facilitation script), log model/version and tool use (e.g., RAG, calculators), and separate confidential data from public scaffolds @resende_critical_2018. Evaluation rubrics emphasize clarity of reasoning, sensitivity analysis, and decision traceability.

Wargames also model economic systems directly. Titles like Civilization IV require resource allocation, city management, and balancing short‑term needs against long‑term growth. Decisions operationalize core concepts—opportunity cost, inflation, deficit spending—while interactions among human and AI players produce emergent market behavior. Finance is likewise strategic: firms compete for share, policymakers set monetary regimes, and traders act under limited information. In‑game markets, trade routes, and investment choices mirror commodity dominance and bilateral contracts. Deploying AI agents as firms, governments, or traders enables study of collusion, innovation, shocks, and equilibria under controlled yet dynamic conditions.

Concretely, resource scarcity and specialization drive negotiation and trade (comparative advantage, transaction costs). Budget constraints and inflation impose discipline on expansion, surfacing scaling frictions and the need for hedging. Investment in infrastructure illustrates opportunity cost and delayed returns: capital committed to growth trades off with readiness elsewhere. Settlers of Catan provides a compact testbed for these dynamics under uncertainty: dice and development cards force risk management and adaptation; multi‑party negotiation (offers, counteroffers, acceptance/refusal) elicits strategic communication and deception. Evaluating reinforcement‑learning agents in such settings goes beyond win rate to include diversity of behavior, skill expression, and rare or emergent strategies @alabdulkarim_goal-directed_2021, which are useful for playtesting, balancing, and policy analysis.

Taken together, economics‑ and business‑oriented wargames provide an experimental platform for testing assumptions, measuring policy interventions, and examining second‑order effects, while LM assistance supports scale and reproducibility. Clear evidence requirements and artifact capture (transcripts, proposals, dissent notes) make results auditable and comparable across runs.

=== Medicine and Public Health
Wargaming is not limited to military and geopolitical conflicts. It has also been used to great effect in the fields of medicine and public health to prepare for and respond to health crises. A prominent example is the "Dark Winter" exercise, a 2001 simulation of a smallpox attack on the United States, which highlighted critical deficiencies in the nation's preparedness for a bioterrorist attack.

Following the precedent of "Dark Winter", numerous other wargames and simulation exercises have been conducted to address a variety of public health challenges. These exercises, often referred to as tabletop exercises (TTXs) or drills, are crucial tools for testing emergency plans, training personnel, and improving coordination between different agencies. For instance, "Event 201" simulated a global pandemic to identify and address the economic and societal challenges it would pose. These simulations have proven invaluable in preparing for real-world events like the COVID-19 pandemic, allowing policymakers and healthcare professionals to rehearse their responses in a controlled environment @smith_serious_2020.


== Human-Agent Interactions (HAI) vs Agent-Agent Interactions (A2A) 
Especially in negotiation‑centric settings and highly creative agents, previous research leans toward Human–Agent Interactions (HAI) with emphasis on emulating or integrating with human diplomatic behavior. Often it is a single AI agent interacting with a group of human players, as seen typically in AI research with negotiation‑centric board games. With diplomacy and collaboration being the focus, the state of the game strongly encourages AI agents to adopt the social language of the rest of the players. Such research is often conducted through random games on online platforms with text‑based communications, and mostly without the human users being strongly informed of the presence of the AI agent on the platform, let alone that they are playing against an AI agent @meta_fundamental_ai_research_diplomacy_team_human-level_2022. The focus is often on how AI interacts compared to human diplomatic strategies as the primary benchmark, with the target of human‑like behavior, and evaluated on performance against humans. 

However, agent–agent interaction (A2A) is increasingly important as agentic AI proliferates in practice, including organizational and enterprise contexts. Conflicts between multiple agentic systems will differ from HAI dynamics. Much prior work studies cooperative tasks or MoE coordination; competitive diplomatic A2A remains sparse. Human‑likeness, a common HAI benchmark, may not translate to A2A settings with different equilibria and strategies.
